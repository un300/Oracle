# 빅콘테스트

## date : 2020.09.27

## output : html_document





##  목차

> 1. 데이터 불러오기 및 데이터 정제
> 2. 외부 데이터를 활용한 Feature engineering
> 3. 데이터 탐색 및 Feature engineering

```R
{
  if(!require(readxl)){install.packages("readxl"); library(readxl)}
  if(!require(dplyr)){install.packages("dplyr"); library(dplyr)}
  if(!require(ggplot2)){install.packages("ggplot2"); library(ggplot2)}
  if(!require(stringr)){install.packages("stringr"); library(stringr)}
  if(!require(tm)){install.packages("tm"); library(tm)}
  if(!require(lubridate)){install.packages("lubridate"); library(lubridate)}
  if(!require(rcompanion)){install.packages("rcompanion"); library(rcompanion)}
  if(!require(MASS)){install.packages("MASS"); library(MASS)}
  if(!require(reshape2)){install.packages("reshape2"); library(reshape2)}
}
```





##  데이터 불러오기

>"2020 빅콘테스트 데이터분석분야-챔피언리그_2019년 실적데이터.xlsx"
>
>"2020 빅콘테스트 데이터분석분야-챔피언리그_시청률 데이터.xlsx"

```R
# 원본 train
train_rawdata <- read_xlsx('C:\\Users\\user\\Desktop\\빅콘테스트\\문제데이터(데이터분석분야-챔피언리그)\\01_제공데이터\\2020 빅콘테스트 데이터분석분야-챔피언리그_2019년 실적데이터.XLSX',skip=1)
# 원본 test
test_rawdata <- read_xlsx('C:\\Users\\user\\Desktop\\빅콘테스트\\문제데이터(데이터분석분야-챔피언리그)\\02_평가데이터\\2020 빅콘테스트 데이터분석분야-챔피언리그_2020년 6월 판매실적예측데이터(평가데이터).XLSX',skip=1)
str(train_rawdata) #(38309,8)
str(test_rawdata) #(2891,8)



## train과 test셋 합치기
rawdata <- as.data.frame(rbind(train_rawdata, test_rawdata)); str(rawdata) #(41200,8)
d1 <- rawdata
```





## 1. 데이터 정제



> ### **(1) `노출(분)` 결측치처리**
>
> * 결측치처리   : 한 방송에서 2가지 이상의 상품을 판매하는 경우, 하나의 상품에만 `노출(분)`이 존재하고, 나머지 상품에는 `노출(분)`이 결측이 발견되었다. 그러므로, 모든 결측치를 같은 방송의 `노출(분)`으로 대체한다.

```R
# train과 test셋 합쳐서 전처리
# 원데이터 탐색으로 인한 변수 탐색 및 생성 


## 1. 노출(분)

### 노출(분) 결측치 17895개
table(is.na(d1$'노출(분)'))

### 노출(분) 결측치 처리
for (i in 2:nrow(d1)) {
  if (is.na(d1$`노출(분)`[i])) {
    d1$`노출(분)`[i] = d1$`노출(분)`[i-1]
  }
}
d1$`노출(분)` <- round(d1$`노출(분)`,3)
```



> ### **(2) `방송일시` 관련 칼럼 정제**
>
> - 관련 칼럼 생성 : 월 / 일 / 요일 / 상,하반기 / 분기 / 365일별 / 53주차 / 날짜시간 / 시간 / 168시간(일주일) / 휴일을 생성한다.

```R
# 2. 방송일시

# 월, 일, 요일 변수 생성
d1$월 <- month(d1$방송일시)
d1$일 <- day(d1$방송일시)
d1$요일 <- weekdays(d1$방송일시)

# 상/하반기, 분기, 365일별, 53주차 단위 변수 생성
d1$반기 <- semester(d1$방송일시)
d1$분기 <- quarters(d1$방송일시)
d1$'365일' <- yday(d1$방송일시)
d1$'53주차' <- week(d1$방송일시)


# 날짜시간, 시간, 계절, 일주일을 168시간 변수 생성
방송일시_split <- strsplit(as.character(d1$방송일시),' ')
for (i in 1:nrow(d1)) {
  
  d1$년월일[i] <- 방송일시_split[[i]][1]
  d1$시간[i] <- 방송일시_split[[i]][2]
  d1$시간hour[i] <- substr(d1$시간[i],1,2) 
  d1$날짜[i] <- str_replace_all(방송일시_split[[i]][1],'-','')
  d1$날짜시간[i] = str_c(d1$날짜[i],d1$시간hour[i])
  
  if (d1$월[i]==3 | d1$월[i]==4 | d1$월[i]==5) {
    d1$계절[i] <- '봄'
  } else if (d1$월[i]==6 | d1$월[i]==7 | d1$월[i]==8) {
    d1$계절[i] <- '여름'
  } else if (d1$월[i]==9 | d1$월[i]==10 | d1$월[i]==11) {
    d1$계절[i] <- '가을'
  } else {
    d1$계절[i] <- '겨울'
  }
  
  if (d1$요일[i]=='월요일') {
    d1$`168시간`[i] <- (0*24)+as.integer(d1$시간hour[i])+1
  } else if (d1$요일[i]=='화요일') {
    d1$`168시간`[i] <- (1*24)+as.integer(d1$시간hour[i])+1
  } else if(d1$요일[i]=='수요일') {
    d1$`168시간`[i] <- (2*24)+as.integer(d1$시간hour[i])+1
  } else if(d1$요일[i]=='목요일') {
    d1$`168시간`[i] <- (3*24)+as.integer(d1$시간hour[i])+1
  } else if(d1$요일[i]=='금요일') {
    d1$`168시간`[i] <- (4*24)+as.integer(d1$시간hour[i])+1
  } else if(d1$요일[i]=='토요일') {
    d1$`168시간`[i] <- (5*24)+as.integer(d1$시간hour[i])+1
  } else {
    d1$`168시간`[i] <- (6*24)+as.integer(d1$시간hour[i])+1
  }
}


# 휴일 변수 생성
species1 <- c('0101','0301','0505','0512','0606','0815','1003','1009','1225')
for (i in 1:nrow(d1)) {
  if (d1$요일[i]=='토요일' | d1$요일[i] == '일요일' | substr(d1$날짜시간[i],5,8) %in% species1) {
    d1$휴일[i] <- 1
  } else {
    d1$휴일[i] <- 0
  }
}
```



> ### **(3) 방송시간 이상치 처리 및 `방송시간` 관련 칼럼 정제**
>
> - `방송시간` 이상치 처리 : 편성 듀레이션은  10분 ~ 60분 내외 이기에  60분 초과된 편성 시간은 조정해준다. 또한 매주 토요일  18:00~18:20은 정보방송시간으로 추정에서 제외한다.
>
> - 관련 칼럼 생성 : 앞서 전처리한 방송시간 변수를 노출(분)과 비교해 방송시간보다 노출(분)이 짧은 경우는 매진이라고 판단해 변수를생성한다

```R
# 방송시간 변수 전처리, 매진 변수 생성
d2 <- d1
for (i in 1:nrow(d2)) {
  d2$방송시간[i] = round(difftime(d2$방송일시[i+1],d2$방송일시[i]),3)
}
for (i in (nrow(d2)-1):1) {
  if (d2$방송시간[i]==0) {
    d2$방송시간[i] = d2$방송시간[i+1]
  }
}

table(d2$방송시간)

# 방송시간 이상치 처리
# 1) 방송시간 1:30:00~02:10:00 노출을 따르게한다
d2[d2$시간 == '01:30:00',]$방송시간 <- d2[d2$시간 == '01:30:00',]$'노출(분)'
d2[d2$시간 == '01:40:00',]$방송시간 <- d2[d2$시간 == '01:40:00',]$'노출(분)'
d2[d2$시간 == '01:50:00',]$방송시간 <- d2[d2$시간 == '01:50:00',]$'노출(분)'
d2[d2$시간 == '02:00:00',]$방송시간 <- d2[d2$시간 == '02:00:00',]$'노출(분)'
d2[d2$시간 == '02:10:00',]$방송시간 <- d2[d2$시간 == '02:10:00',]$'노출(분)'
# 2) 방송시간 1 => 60
index2 <- d2[d2$방송시간==1,] %>% na.omit() %>% rownames()
index2 <- as.integer(index2)
d2[index2,]$방송시간 <- 20
# 3) 방송시간 1.333 => 20
index3 <- d2[d2$방송시간==1.333,] %>% na.omit() %>% rownames()
index3 <- as.integer(index3)
d2[index3,]$방송시간<- 20
# 4) 방송시간 40,50 이면서 토요일 노출을 따르게한다
d2[d2$방송시간==40 & d2$요일=='토요일',]$방송시간 <- d2[d2$방송시간==40 & d2$요일=='토요일',]$'노출(분)'
d2[d2$방송시간==50 & d2$요일=='토요일',]$방송시간 <- d2[d2$방송시간==50 & d2$요일=='토요일',]$'노출(분)'

# 매진변수 생성 (방송시간>노출)
table(d2[d2$방송시간 > d2$'노출(분)',]$방송시간)
d2$매진여부 <- ifelse(d2$방송시간 > d2$'노출(분)', 1, 0)

# 방송끝나는시간변수 생성
d2$방송끝나는시간 <- d2$방송일시 + dminutes(d2$방송시간)

d3 <- d2
```



> ### **(4) `상품명` 칼럼 정제**
>
> - `sale단어` Feature 생성    : `초특가`, `파격가`, `가격인하`,`세일`, `할인` 등 세일을 포함하는 상품명을 더미화한다.
>
> - `결제수단` Feature 생성    : `무이자`, `일시불` 등 결제수단을 나타내는 상품명을 더미화한다.
>
> - `판매상품수` Feature 생성  : 하나의 방송 편성에서 판매하는 상품의 종류를 센다.

```R
# 상품명 sale단어 노출 여부 변수 생성
d3$sale단어 <- ''
d3[grep('초특가|파격가|가격인하|삼성카드|세일|할인' , d3$상품명), ]$sale단어 <- 1
d3[d3$sale단어=='',]$sale단어 <- 0


# 상품명 결제1/결제2_일시불/결제2_무이자 변수 생성
d3$결제수단 <- ''
d3[grep('무)|무이자' , d3$상품명), ]$결제수단 <- '결제2_무이자'
d3[grep('일)|일시불' , d3$상품명), ]$결제수단 <- '결제2_일시불'
d3[d3$결제수단=='',]$결제수단 <- '결제1'

# 상품명 결제수단 무시하고 방송시간별 판매상품수 count 변수 생성
d3$상품명change <- d3$상품명
d3$상품명change <- str_replace_all(d3$상품명change,'무이자','')
d3$상품명change <- str_replace_all(d3$상품명change,'일시불','')
d3$상품명change[grep('무)' , d3$상품명)] <- str_replace_all(d3[grep('무)' , d3$상품명),]$상품명,'무','')
d3$상품명change[grep('일)' , d3$상품명)] <- str_replace_all(d3[grep('일)' , d3$상품명),]$상품명,'일','')

d3_c1 <- d3 %>% dplyr::select(방송일시, 상품명change) %>% unique() %>% group_by(방송일시) %>% summarise(count=n())
d3 <- left_join(d3, d3_c1)

```



> ### **(5) `중분류` / `소분류` 칼럼 생성**
>
> - NS SHOP+ 홈페이지( http://www.nsmall.com/ )에서 `상품 카테고리`를 Python으로 크롤링 하여 중분류, 소분류 카테고리 데이터를 수집해온다.
>
> - 원데이터의 상품군 `무형`을 제외한 11개의 상품군을 36개의 중분류로, 133개의 소분류로 세분화한 칼럼을 생성한다.
>
> - 중분류, 소분류 칼럼은 2019년 1월 ~ 12월의 Train data와 2020년 6월의 Test Data를 비슷한 상품으로 묶어주는 중요한 역할을 한다.

```R
d4 <- d3
category <- as.data.frame(read_xlsx('C:\\Users\\user\\Desktop\\빅콘테스트\\문제데이터(데이터분석분야-챔피언리그)\\외부데이터\\대중소_분류_최종.XLSX'))
cg1 <- unique(category[,c(1,3,4)])
d5 <- left_join(d4, cg1)
str(d5)
colSums(is.na(d5))
```





## 2. 외부 데이터를 활용한 Feature engineering



> ### (1) 날씨데이터 
>
> - 기상청 홈페이지(https://data.kma.go.kr/data/grnd/selectAsosRltmList.do?pgmNo=36 )에서  전국 일자시간별 날씨 데이터를 수집해온다.
>
> - 전국의 `기온`, `강수량`, `풍속`, `습도`, `적설`, `전운량` 수치를 평균화한다.
> (이때 결측치는 제외하고 계산에 처리한다.)

```R
dd1 <- d5
# 기상청 2019
weather19 <- read.csv('C:\\Users\\user\\Desktop\\빅콘테스트\\문제데이터(데이터분석분야-챔피언리그)\\외부데이터\\2019기상청.csv')
# 기상청 2020
weather20 <- read.csv('C:\\Users\\user\\Desktop\\빅콘테스트\\문제데이터(데이터분석분야-챔피언리그)\\외부데이터\\2020기상청.csv')
weather <- rbind(weather19, weather20)
colnames(weather) <- c('지점','지점명','방송일시','기온','강수량','풍속','습도','적설','전운량')
colSums(is.na(weather)); colSums(weather==0,na.rm=TRUE);

# 기상청 강수량과 적설 0은 0.02로 결측치는 0으로 처리
weather[!is.na(weather$강수량) & weather$강수량==0,]$강수량  <- 0.02
weather[is.na(weather$강수량),]$강수량 <- 0
weather[!is.na(weather$적설) & weather$적설==0,]$적설  <- 0.02
weather[is.na(weather$적설),]$적설 <- 0
weather$방송일시 <- as.POSIXct(weather$방송일시)

w1 <- weather %>% group_by(방송일시) %>% dplyr::summarise(기온 = mean(기온, na.rm=TRUE),
                                                        강수량 = mean(강수량, na.rm=TRUE),
                                                        풍속 = mean(풍속, na.rm=TRUE),
                                                        습도 = mean(습도, na.rm=TRUE),
                                                        적설 = mean(적설, na.rm=TRUE),
                                                        전운량 = mean(전운량, na.rm=TRUE))
w1$비눈여부 <- as.factor(ifelse(w1$강수량==0 & w1$적설==0, 0, 1))
w1$비눈여부_평균이상 <- as.factor(ifelse(w1$강수량>mean(w1$강수량) | w1$적설>mean(w1$적설), 1, 0))
colSums(is.na(w1)); w1[is.na(w1$전운량),]$전운량 <- 0

dd2 <- left_join(dd1, w1)
str(dd2)
for (i in 2:nrow(dd2)) {
  if (is.na(dd2[i,c('기온','강수량','풍속','습도','적설','전운량','비눈여부','비눈여부_평균이상')])) {
    dd2[i,c('기온','강수량','풍속','습도','적설','전운량','비눈여부','비눈여부_평균이상')] <- dd2[(i-1),c('기온','강수량','풍속','습도','적설','전운량','비눈여부','비눈여부_평균이상')]
  }
}

colSums(is.na(dd2))
```



> ### **(2) 미세먼지**
>
> - 에어코리아 홈페이지(https://www.airkorea.or.kr/web/last_amb_hour_data?pMENU_NO=123)에서 일자별 전국 미세먼지 데이터를 수집해온다.
>
> - 전국의 `미세먼지`, `초미세먼지` 수치를 평균화한다.

```R
dd3 <- dd2

# 미세먼지 2019
dust1 <- read.csv('C:\\Users\\user\\Desktop\\빅콘테스트\\문제데이터(데이터분석분야-챔피언리그)\\외부데이터\\2019미세먼지.csv')
colnames(dust1) <- c("날짜시간", "미세먼지", "초미세먼지")
dust1$날짜시간 <- as.character(as.integer(dust1$날짜시간)-1)
# 미세먼지 2020
dust2 <- read.csv('C:\\Users\\user\\Desktop\\빅콘테스트\\문제데이터(데이터분석분야-챔피언리그)\\외부데이터\\2020미세먼지.csv')
colnames(dust2) <- c("날짜","미세먼지","초미세먼지")
dust2$날짜 <- as.character(dust2$날짜)

a1 <- dd3[,c('날짜시간','날짜')]
a2 <- left_join(a1, dust1, by='날짜시간')
a3 <- left_join(a1, dust2, by='날짜')

for (i in 1:nrow(dd3)) {
  if (!is.na(a2$미세먼지[i])) {
    dd3$미세먼지[i] <- a2$미세먼지[i]
    dd3$초미세먼지[i] <- a2$초미세먼지[i] 
  } else {
    dd3$미세먼지[i] <- a3$미세먼지[i]
    dd3$초미세먼지[i] <- a3$초미세먼지[i]
  }
}

```



> ## 3. 데이터 탐색 및 Feature engineering
>
> ### (1) Mean Encoding 작업을 위한 준비 / 예측대상 아닌 행 제외
>
> - Mean Encoding 작업을 위해 Train set과 Test set을 나누어 준다. 
> (후에 `그룹코드_대박횟수`, `그룹코드_쪽박횟수` 등을 만들때 사용된다.)
>
> - 예측 대상이 아닌 `무형`인 `상품군`과 취급액이 `50,000`만원인 데이터를 제거한다. 

```R
dd4 <- dd3
str(dd4)
colSums(is.na(dd4))

# train데이터 : 2019년 1~12월
train_rawdata1 <- dd4[(dd4$`날짜시간`<'2020010105'), ]
# test데이터 : 2020년 6월
test_rawdata1 <- dd4[(dd4$`날짜시간`>'2020010105'), ]

str(train_rawdata1) #(38309,43)
str(test_rawdata1) #(2891,43)


### train 데이터 전처리

# 취급액 전처리

# 상품군이 "무형" 인 경우 937개
table(train_rawdata1$상품군 == "무형")
# 취급액 결측치 937개
sum(is.na(train_rawdata1$취급액))
# 취급액 50000 이상치 1993개
table(train_rawdata1$취급액 == 50000)

#train_rawdata1 <- train_rawdata1 %>% filter(`상품군` != '무형')
#str(train_rawdata1)

train_rawdata1 = train_rawdata1[(train_rawdata1$상품군!="무형") & (train_rawdata1$취급액!= 50000), ]
str(train_rawdata1) #(35379,43)
rownames(train_rawdata1) <- NULL


### test 데이터 전처리

# 취급액 전처리

# 상품군이 "무형" 인 경우 175개
table(test_rawdata1$상품군 == "무형")
test_rawdata1 = test_rawdata1[(test_rawdata1$상품군!="무형"),]
str(test_rawdata1) #(2716,43)
rownames(test_rawdata1) <- NULL


d6 <- rbind(train_rawdata1, test_rawdata1)
colSums(is.na(d6))
```



> ### (2) `판매상품종류수`, `판매상품종류비율` Feature 생성
>
> -`판매상품종류수`   : 하나의 방송 편성에서 여러가지 상품을 판매하는 경우, 잘팔리는 상품이 있는 반면 잘 팔리지 않는 상품이 존재한다. 그러므로 상품의 종류간에 미치는 영향을 고려하기 위해 `판매상품종류수` Feature를 생성한다.
>
> `판매상품종류수`는 후에 `그룹코드` 칼럼을 생성하는데 활용된다. 활용법은 추후에 자세히 설명한다.
>
> -`판매상품종류비율` : `판매상품종류수`의 역수이다.

``` R

# 판매상품종류수 / 판매상품종류비율

temp_df <- d6 %>% group_by(`방송일시`) %>% summarise(`판매상품종류수` = n())
temp_df$`판매상품종류비율` <- 1/temp_df$`판매상품종류수`
t_df <- left_join(d6, temp_df, by='방송일시')

d7 <- t_df
```



>### (3) `그룹코드` 칼럼 생성
>
>- `그룹코드` : 주최측의 설명에 의하면 '예측 상품 중 과거 실적이 없는 경우는 유사 카테고리 혹은 동일머더코드로 예측함'이라고 하였음으로, Train set의 상품과 Test set의 상품을 나름의 철저한 기준으로 연결시키는 코드번호를 만들어 각 상품에 부여하였다. 그룹코드가 만들어지는 기준은 다음과 같다.
>
>
>1) Train set의 상품명을 unique한 dataframe으로 만들어 새로운 번호인 `그룹코드`를 생성한다.
>2) unique한 dataframe의 상품명과 Test set의 상품명이 동일하다면, 동일한 `그룹코드`를 부여한다.
>3) 상품명이 동일하지 않을 시, 동일한 머더코드가 존재한다면 같은 `그룹코드`를 부여한다.
>4) 상품명, 머더코드 모두 동일하지 않을 시, 동일한 상품코드가 존재한다면 같은 `그룹코드`를 부여한다.
>5) 상품명, 머더코드, 상품코드 모두 동일하지 않을시, 아래와 같은 기준으로 `그룹코드`를 부여한다
>1. `소분류`와 `판매상품종류수`가 같은 상품 중에서, `판매단가` 차이가 가장 작은 상품의 `그룹코드`를 부여한다.
>2. 위 조건에 부합하는 데이터가 존재하지 않는다면, `중분류`와 `판매상품종류수`가 같은 상품 중에서, `판매단가` 차이가 가장 작은 상품의 `그룹코드`를 부여한다.
>3. 위 조건에 부합하는 데이터가 존재하지 않는다면, `상품군`과 `판매상품종류수`가 같은 상품 중에서, `판매단가` 차이가 가장 작은 상품의 `그룹코드`를 부여한다.
>
>
>위와 같이 `그룹코드`기준을 정한 이유는 최대한 사람의 주관적이 판단을 배제하기 위해서이다.

```R
# 5. 그룹코드 생성
d7$마더코드 <- as.character(d7$마더코드)

colnames(train_rawdata1)

# 그룹코드 뽑아낼 그룹 dataframe 생성
gdf <- data.frame()
for (i in 1:nrow(train_rawdata1)) {
  if (!(train_rawdata1$상품명[i] %in% gdf$상품명)) {
    gdf <- rbind(gdf, train_rawdata1[i,c("노출(분)","마더코드","상품코드","상품명","판매단가","소분류")])
  }
}
row.names(gdf) <- NULL


for (i in 1:nrow(d7)) {
  if( d7$상품명[i] %in% gdf$상품명 ) {
    d7$그룹코드[i] <- row.names(gdf[d7$상품명[i]==gdf$상품명,])
  } else if ( d7$마더코드[i] %in% gdf$마더코드 ){
    d7$그룹코드[i] <- row.names(gdf[d7$마더코드[i]==gdf$마더코드,])
  }else if( d7$상품코드[i] %in% gdf$상품코드 ) {
    d7$그룹코드[i] <- row.names(gdf[d7$상품코드[i]==gdf$상품코드,])
  } else{
    d7$그룹코드[i] <- NA
  }
}

d7[is.na(d7$`그룹코드`), ]


gijun <- unique(d7[!is.na(d7$그룹코드), c('마더코드', '상품코드', '그룹코드', '상품명', '상품군', '중분류', '소분류', '판매상품종류수', '판매단가')]) %>% arrange(`판매단가`)


for(k in 1:nrow(d7[is.na(d7$`그룹코드`), ])){
  temp_df <- gijun %>% filter(`소분류`         == d7[is.na(d7$`그룹코드`), ][1, ]$`소분류` &
                                `판매상품종류수` == d7[is.na(d7$`그룹코드`), ][1, ]$`판매상품종류수`)
  
  if( nrow(temp_df)==0 ){
    temp_df <- gijun %>% filter(`중분류`         == d7[is.na(d7$`그룹코드`), ][1, ]$`중분류` &
                                  `판매상품종류수` == d7[is.na(d7$`그룹코드`), ][1, ]$`판매상품종류수`)
    if( nrow(temp_df)==0 ){
      temp_df <- gijun %>% filter(`상품군`         == d7[is.na(d7$`그룹코드`), ][1, ]$`상품군` &
                                    `판매상품종류수` == d7[is.na(d7$`그룹코드`), ][1, ]$`판매상품종류수`)
      if( nrow(temp_df)==0 ){
        temp_df <- gijun %>% filter(`판매상품종류수` == d7[is.na(d7$`그룹코드`), ][1, ]$`판매상품종류수`)
      }
    }
  }
  
  temp_df$`diff` <- abs(temp_df$`판매단가` - d7[is.na(d7$`그룹코드`), ][1, ]$`판매단가`)
  arrnage_temp_df <- temp_df %>% arrange(`diff`)
  d7[is.na(d7$`그룹코드`), ][1, ]$`그룹코드` <- arrnage_temp_df[1,]$`그룹코드`
}

d8 <- d7

```



> ### (4) `판매단가`별 순위형 칼럼 생성
>
> - `전체 판매단가별 순위형 변수` : 전체 데이터에서 `판매단가`별 평균 취급액을 비교하면, 각 `판매단가`가 얼마만큼의 실적을 내는지 알 수 있다.
> 실적 값을 정렬한 후  5등분화하여 서열 척도로 변수를 생성한다.
>
> - `상품군별 판매단가별 순위형 변수` : 전체 데이터에서 `상품군`별로 `판매단가`별 평균 취급액을 비교하면, 각 상품군 마다의 `판매단가`가 얼마만큼의 실적을 내는지 알 수 있다.
> 그 실적값을 정렬한 후 5등분화하여 서열 척도로 변수를 생성한다.

```R
# 7. 판매단가

d9 <- d8
colnames(d9); str(d9)


# 1) 전체 판매단가별 순위형 변수

unique_판매단가_sort <- train_rawdata1 %>% group_by(판매단가) %>%
  summarize(mean_sales = mean(취급액, na.rm = TRUE)) %>% arrange(-mean_sales)

div_value=floor(nrow(unique_판매단가_sort)/5)
판매단가순위1<-unique_판매단가_sort$판매단가[1:div_value]
판매단가순위2<-unique_판매단가_sort$판매단가[(div_value+1):(div_value*2)]
판매단가순위3<-unique_판매단가_sort$판매단가[(div_value*2+1):(div_value*3)]
판매단가순위4<-unique_판매단가_sort$판매단가[(div_value*3+1):(div_value*4)]
판매단가순위5<-unique_판매단가_sort$판매단가[(div_value*4+1):nrow(unique_판매단가_sort)]

for (i in 1:nrow(d9)) {
  if (d9$판매단가[i] %in% 판매단가순위1) {
    d9$판매단가순위[i] <- 1
  } else if (d9$판매단가[i] %in% 판매단가순위2) {
    d9$판매단가순위[i] <- 2
  } else if (d9$판매단가[i] %in% 판매단가순위3) {
    d9$판매단가순위[i] <- 3
  } else if (d9$판매단가[i] %in% 판매단가순위4) {
    d9$판매단가순위[i] <- 4
  } else if (d9$판매단가[i] %in% 판매단가순위5) {
    d9$판매단가순위[i] <- 5
  } else {
    d9$판매단가순위[i] <-3
  }
}
table(d9$판매단가순위)

# 2) 상품군별 판매단가별 순위형 변수

d9$상품군판매단가순위 <- 0

for (j in 1:length(unique(d9$상품군))) {
  
  a1 <-  train_rawdata1 %>% group_by(상품군,판매단가) %>% filter(상품군==unique(d7$상품군)[j]) %>%
    summarize(mean_sales = mean(취급액, na.rm = TRUE)) %>% arrange(-mean_sales)
  
  div_value=floor(nrow(a1)/5)
  판매단가순위1<-a1$판매단가[1:div_value]
  판매단가순위2<-a1$판매단가[(div_value+1):(div_value*2)]
  판매단가순위3<-a1$판매단가[(div_value*2+1):(div_value*3)]
  판매단가순위4<-a1$판매단가[(div_value*3+1):(div_value*4)]
  판매단가순위5<-a1$판매단가[(div_value*4+1):nrow(a1)]
  
  for (i in 1:nrow(d7)) {
    if (d9$상품군[i]==unique(d9$상품군)[j]){
      if (d9$판매단가[i] %in% 판매단가순위1) {
        d9$상품군판매단가순위[i] <- 1
      } else if (d9$판매단가[i] %in% 판매단가순위2) {
        d9$상품군판매단가순위[i] <- 2
      } else if (d9$판매단가[i] %in% 판매단가순위3) {
        d9$상품군판매단가순위[i] <- 3
      } else if (d9$판매단가[i] %in% 판매단가순위4) {
        d9$상품군판매단가순위[i] <- 4
      } else if (d9$판매단가[i] %in% 판매단가순위5) {
        d9$상품군판매단가순위[i] <- 5
      } else{
        d9$상품군판매단가순위[i] <- 3
      }
    }
  }
}
table(d9$상품군판매단가순위)
```



> ### (5) 집단별 시간별 순위형 칼럼 생성 : 
>
> 전체 데이터에서 집단별로 시간별 평균 취급액을 비교하면, 각 집단별 시간 마다 얼마만큼의 실적을 내는지 알 수 있다.
> 그 실적값을 정렬한 후 5등분화하여 서열 척도로 변수를 생성한다.
>
> * 상품군별
> - `상품군요일순위`
> - `상품군24시간순위`
> - `상품군168시간순위`
>
> * 중분류별
> - `중분류요일순위`
> - `중분류24시간순위`
> - `중분류168시간순위`

```R
# 8. 취급액 + 프라임 변수

d12 <- d9

### 상품군

# 1) 상품군 요일별 평균 취급액 순위형 DF 생성함수

d12_c1 <- train_rawdata1 %>% group_by(상품군,요일) %>%
  summarize(mean_sales = mean(취급액, na.rm = TRUE)) %>% arrange(-mean_sales) 
d12_c1 <- acast(data=d12_c1, 상품군~요일, value.var='mean_sales', fill=0)

n = floor(ncol(d12_c1)/5)
for (i in 1:nrow(d12_c1)) {
  d12_c11 <- sort(-d12_c1[i,]) %>% names
  순위1 <- d12_c11[1:n]
  순위2 <- d12_c11[(n+1):(n*2)]
  순위3 <- d12_c11[(n*2+1):(n*3)]
  순위4 <- d12_c11[(n*3+1):(n*4)]
  순위5 <- d12_c11[(n*4+1):ncol(d12_c1)]
  d12_c1[i,순위1] <- 1
  d12_c1[i,순위2] <- 2
  d12_c1[i,순위3] <- 3
  d12_c1[i,순위4] <- 4
  d12_c1[i,순위5] <- 5
}  
table_large_yoill <- d12_c1

# 2) 상품군 24시간별 평균 취급액 순위형 DF 생성함수

d12_c2 <- train_rawdata1 %>% group_by(상품군,시간hour) %>%
  summarize(mean_sales = mean(취급액, na.rm = TRUE)) %>% arrange(-mean_sales) 
d12_c2 <- acast(data=d12_c2, 상품군~시간hour, value.var='mean_sales', fill=0)

for (i in 1:nrow(d12_c2)) {
  n = floor(sum(d12_c2[i,]!=0)/5)
  d12_c21 <- sort(-d12_c2[i,d12_c2[i,]!=0]) %>% names
  순위1 <- d12_c21[1:n]
  순위2 <- d12_c21[(n+1):(n*2)]
  순위3 <- d12_c21[(n*2+1):(n*3)]
  순위4 <- d12_c21[(n*3+1):(n*4)]
  순위5 <- d12_c21[(n*4+1):sum(d12_c2[i,]!=0)]
  d12_c2[i,순위1] <- 1
  d12_c2[i,순위2] <- 2
  d12_c2[i,순위3] <- 3
  d12_c2[i,순위4] <- 4
  d12_c2[i,순위5] <- 5
  d12_c2[i,d12_c2[i,]==0] <- 6
} 
table_large_hour24 <- d12_c2

# 3) 상품군 168시간별 평균 취급액 순위형 DF 생성함수

d12_c3 <- train_rawdata1 %>% group_by(상품군,`168시간`) %>%
  summarize(mean_sales = mean(취급액, na.rm = TRUE)) %>% arrange(-mean_sales) 
d12_c3 <- acast(data=d12_c3, 상품군~`168시간`, value.var='mean_sales', fill=0)

for (i in 1:nrow(d12_c3)) {
  n = floor(sum(d12_c3[i,]!=0)/5)
  d12_c31 <- sort(-d12_c3[i,d12_c3[i,]!=0]) %>% names
  순위1 <- d12_c31[1:n]
  순위2 <- d12_c31[(n+1):(n*2)]
  순위3 <- d12_c31[(n*2+1):(n*3)]
  순위4 <- d12_c31[(n*3+1):(n*4)]
  순위5 <- d12_c31[(n*4+1):sum(d12_c3[i,]!=0)]
  d12_c3[i,순위1] <- 1
  d12_c3[i,순위2] <- 2
  d12_c3[i,순위3] <- 3
  d12_c3[i,순위4] <- 4
  d12_c3[i,순위5] <- 5
  d12_c3[i,d12_c3[i,]==0] <- 6
} 
table_large_hour168 <- d12_c3

### 중분류

# 4) 중분류 요일별 평균 취급액 순위형 DF 생성함수

d12_c4 <- train_rawdata1 %>% group_by(중분류,요일) %>%
  summarize(mean_sales = mean(취급액, na.rm = TRUE)) %>% arrange(-mean_sales) 
d12_c4 <- acast(data=d12_c4, 중분류~요일, value.var='mean_sales', fill=0)

n = floor(ncol(d12_c4)/5)
for (i in 1:nrow(d12_c4)) {
  d12_c41 <- sort(-d12_c4[i,]) %>% names
  순위1 <- d12_c41[1:n]
  순위2 <- d12_c41[(n+1):(n*2)]
  순위3 <- d12_c41[(n*2+1):(n*3)]
  순위4 <- d12_c41[(n*3+1):(n*4)]
  순위5 <- d12_c41[(n*4+1):ncol(d12_c4)]
  d12_c4[i,순위1] <- 1
  d12_c4[i,순위2] <- 2
  d12_c4[i,순위3] <- 3
  d12_c4[i,순위4] <- 4
  d12_c4[i,순위5] <- 5
}  
table_middle_yoill <- d12_c4

# 5) 중분류 24시간별 평균 취급액 순위형 DF 생성함수

d12_c5 <- train_rawdata1 %>% group_by(중분류,시간hour) %>%
  summarize(mean_sales = mean(취급액, na.rm = TRUE)) %>% arrange(-mean_sales) 
d12_c5 <- acast(data=d12_c5, 중분류~시간hour, value.var='mean_sales', fill=0)

for (i in 1:nrow(d12_c5)) {
  n = floor(sum(d12_c5[i,]!=0)/5)
  d12_c51 <- sort(-d12_c5[i,d12_c5[i,]!=0]) %>% names
  순위1 <- d12_c51[1:n]
  순위2 <- d12_c51[(n+1):(n*2)]
  순위3 <- d12_c51[(n*2+1):(n*3)]
  순위4 <- d12_c51[(n*3+1):(n*4)]
  순위5 <- d12_c51[(n*4+1):sum(d12_c5[i,]!=0)]
  d12_c5[i,순위1] <- 1
  d12_c5[i,순위2] <- 2
  d12_c5[i,순위3] <- 3
  d12_c5[i,순위4] <- 4
  d12_c5[i,순위5] <- 5
  d12_c5[i,d12_c5[i,]==0] <- 6
} 
table_middle_hour24 <- d12_c5

# 6) 중분류 168시간별 평균 취급액 순위형 DF 생성함수

d12_c6 <- train_rawdata1 %>% group_by(중분류,`168시간`) %>%
  summarize(mean_sales = mean(취급액, na.rm = TRUE)) %>% arrange(-mean_sales) 
d12_c6 <- acast(data=d12_c6, 중분류~`168시간`, value.var='mean_sales', fill=0)

for (i in 1:nrow(d12_c6)) {
  n = floor(sum(d12_c6[i,]!=0)/5)
  d12_c61 <- sort(-d12_c6[i,d12_c6[i,]!=0]) %>% names
  순위1 <- d12_c61[1:n]
  순위2 <- d12_c61[(n+1):(n*2)]
  순위3 <- d12_c61[(n*2+1):(n*3)]
  순위4 <- d12_c61[(n*3+1):(n*4)]
  순위5 <- d12_c61[(n*4+1):sum(d12_c6[i,]!=0)]
  d12_c6[i,순위1] <- 1
  d12_c6[i,순위2] <- 2
  d12_c6[i,순위3] <- 3
  d12_c6[i,순위4] <- 4
  d12_c6[i,순위5] <- 5
  d12_c6[i,d12_c6[i,]==0] <- 6
} 
table_middle_hour168 <- d12_c6


for (i in (1:nrow(d12_c6))) {
  focus_large <- d12$상품군[i]
  focus_middle <- d12$중분류[i]  
  
  focus_yoill <- d12$요일[i]
  focus_hour24 <- d12$시간hour[i]
  focus_hour168 <- d12$`168시간`[i]
  
  
  d12$상품군요일순위[i]    <- table_large_yoill[focus_large,     focus_yoill]
  d12$상품군24시간순위[i]  <- table_large_hour24[focus_large,    focus_hour24]
  #d12$상품군168시간순위[i] <- table_large_hour168[focus_large,   focus_hour168]
  
  d12$중분류요일순위[i]    <- table_middle_yoill[focus_middle,   focus_yoill]
  d12$중분류24시간순위[i]  <- table_middle_hour24[focus_middle,  focus_hour24]
  #d12$중분류168시간순위[i] <- table_middle_hour168[focus_middle, focus_hour168]
}

for (i in (1:nrow(d12_c6))) {
  focus_large <- d12$상품군[i]
  focus_middle <- d12$중분류[i]  
  
  focus_yoill <- d12$요일[i]
  focus_hour24 <- d12$시간hour[i]
  focus_hour168 <- d12$`168시간`[1]
  
  d12$상품군168시간순위[i] <- table_large_hour168[focus_large,   focus_hour168]
  d12$중분류168시간순위[i] <- table_middle_hour168[focus_middle, focus_hour168]
}
```



> ### (6) `판매단가` boxplot 순위형 변수 생성
>
> - `판매단가rank` : `판매단가`가 내포하는 분포를 순위형 변수로 생성한다.

```R
# 9. 판매단가 boxplot

d11 <- d12

a <- boxplot(d11$판매단가)$stat
for ( i in 1:nrow(d11)) {
  if(d11$판매단가[i] >= a[5]) {
    d11$판매단가rank[i] <- 1
  } else if(d11$판매단가[i] > a[4] & d11$판매단가[i] < a[5]) {
    d11$판매단가rank[i] <- 2
  } else if(d11$판매단가[i] > a[3] & d11$판매단가[i] < a[4]) {
    d11$판매단가rank[i] <- 3
  } else if(d11$판매단가[i] > a[2] & d11$판매단가[i] < a[3]) {
    d11$판매단가rank[i] <- 4
  } else if(d11$판매단가[i] > a[1] & d11$판매단가[i] < a[2]) {
    d11$판매단가rank[i] <- 5
  } else {
    d11$판매단가rank[i] <- 6
  }
}
table(d11$판매단가rank)
```



> ### (7) 범주형 변수 재범주화
>
> - onehotencoding을 하기에 각 변수 마다 범주형 속성이 너무 많아서 이 특성을 순위형 변수로 재범주화를 실시한다.
> -전체 데이터에서 평균 취급액을 비교하면, 각 범주형 속성이 얼마만큼의 실적을 내는지 알 수 있다.
> 실적 값을 정렬한 후  5등분화하여 서열 척도로 변수를 생성한다.
>
> - `시간hour`
> - `168시간`
> - `브랜드`
> - `중분류`
> - `소분류`

```R
# 10. 범주형 변수 순위형 변수로 재범주화

d12 <- d11

# 1) 시간hour

d12$시간순위 <- 0
unique_시간순위_sort <- train_rawdata1 %>% group_by(시간hour) %>%
  summarize(mean_sales = mean(취급액, na.rm = TRUE)) %>% arrange(-mean_sales)

div_value=floor(nrow(unique_시간순위_sort)/5)
시간순위1<-unique_시간순위_sort$시간hour[1:div_value]
시간순위2<-unique_시간순위_sort$시간hour[(div_value+1):(div_value*2)]
시간순위3<-unique_시간순위_sort$시간hour[(div_value*2+1):(div_value*3)]
시간순위4<-unique_시간순위_sort$시간hour[(div_value*3+1):(div_value*4)]
시간순위5<-unique_시간순위_sort$시간hour[(div_value*4+1):nrow(unique_시간순위_sort)]

for (i in 1:nrow(d12)) {
  if (d12$시간hour[i] %in% 시간순위1) {
    d12$시간순위[i] <- 1
  } else if (d12$시간hour[i] %in% 시간순위2) {
    d12$시간순위[i] <- 2
  } else if (d12$시간hour[i] %in% 시간순위3) {
    d12$시간순위[i] <- 3
  } else if (d12$시간hour[i] %in% 시간순위4) {
    d12$시간순위[i] <- 4
  } else if (d12$시간hour[i] %in% 시간순위5) {
    d12$시간순위[i] <- 5
  } else {
    d12$시간순위[i] <- 3
  }
}
table(d12$시간순위)

# 2) 168시간

d12$시간순위168 <- 0
unique_시간순위168_sort <- train_rawdata1 %>% group_by(`168시간`) %>%
  summarize(mean_sales = mean(취급액, na.rm = TRUE)) %>% arrange(-mean_sales)

div_value=floor(nrow(unique_시간순위168_sort)/5)
시간순위1681<-unique_시간순위168_sort$`168시간`[1:div_value]
시간순위1682<-unique_시간순위168_sort$`168시간`[(div_value+1):(div_value*2)]
시간순위1683<-unique_시간순위168_sort$`168시간`[(div_value*2+1):(div_value*3)]
시간순위1684<-unique_시간순위168_sort$`168시간`[(div_value*3+1):(div_value*4)]
시간순위1685<-unique_시간순위168_sort$`168시간`[(div_value*4+1):nrow(unique_시간순위168_sort)]

for (i in 1:nrow(d12)) {
  if (d12$`168시간`[i] %in% 시간순위1681) {
    d12$시간순위168[i] <- 1
  } else if (d12$`168시간`[i] %in% 시간순위1682) {
    d12$시간순위168[i] <- 2
  } else if (d12$`168시간`[i] %in% 시간순위1683) {
    d12$시간순위168[i] <- 3
  } else if (d12$`168시간`[i] %in% 시간순위1684) {
    d12$시간순위168[i] <- 4
  } else if (d12$`168시간`[i] %in% 시간순위1685) {
    d12$시간순위168[i] <- 5
  } else {
    d12$시간순위168[i] <- 3
  }
}
table(d12$시간순위168)

# 3) 중분류

d12$중분류순위 <- 0
unique_중분류순위_sort <- train_rawdata1 %>% group_by(중분류) %>%
  summarize(mean_sales = mean(취급액, na.rm = TRUE)) %>% arrange(-mean_sales)

div_value=floor(nrow(unique_중분류순위_sort)/5)
중분류순위1<-unique_중분류순위_sort$중분류[1:div_value]
중분류순위2<-unique_중분류순위_sort$중분류[(div_value+1):(div_value*2)]
중분류순위3<-unique_중분류순위_sort$중분류[(div_value*2+1):(div_value*3)]
중분류순위4<-unique_중분류순위_sort$중분류[(div_value*3+1):(div_value*4)]
중분류순위5<-unique_중분류순위_sort$중분류[(div_value*4+1):nrow(unique_중분류순위_sort)]

for (i in 1:nrow(d12)) {
  if (d12$중분류[i] %in% 중분류순위1) {
    d12$중분류순위[i] <- 1
  } else if (d12$중분류[i] %in% 중분류순위2) {
    d12$중분류순위[i] <- 2
  } else if (d12$중분류[i] %in% 중분류순위3) {
    d12$중분류순위[i] <- 3
  } else if (d12$중분류[i] %in% 중분류순위4) {
    d12$중분류순위[i] <- 4
  } else if (d12$중분류[i] %in% 중분류순위5) {
    d12$중분류순위[i] <- 5
  } else {
    d12$중분류순위[i] <- 3
  }
}
table(d12$중분류순위)

# 5) 소분류

d12$소분류순위 <- 0
unique_소분류순위_sort <- train_rawdata1 %>% group_by(소분류) %>%
  summarize(mean_sales = mean(취급액, na.rm = TRUE)) %>% arrange(-mean_sales)

div_value=floor(nrow(unique_소분류순위_sort)/5)
소분류순위1<-unique_소분류순위_sort$소분류[1:div_value]
소분류순위2<-unique_소분류순위_sort$소분류[(div_value+1):(div_value*2)]
소분류순위3<-unique_소분류순위_sort$소분류[(div_value*2+1):(div_value*3)]
소분류순위4<-unique_소분류순위_sort$소분류[(div_value*3+1):(div_value*4)]
소분류순위5<-unique_소분류순위_sort$소분류[(div_value*4+1):nrow(unique_소분류순위_sort)]

for (i in 1:nrow(d12)) {
  if (d12$소분류[i] %in% 소분류순위1) {
    d12$소분류순위[i] <- 1
  } else if (d12$소분류[i] %in% 소분류순위2) {
    d12$소분류순위[i] <- 2
  } else if (d12$소분류[i] %in% 소분류순위3) {
    d12$소분류순위[i] <- 3
  } else if (d12$소분류[i] %in% 소분류순위4) {
    d12$소분류순위[i] <- 4
  } else if (d12$소분류[i] %in% 소분류순위5) {
    d12$소분류순위[i] <- 5
  } else {
    d12$소분류순위[i] <- 3
  }
}
table(d12$소분류순위)

str(d12)
```



> ### (11) Feature Engineering : `24시간_COS` / `24시간_SIN` / `168시간_COS` / `168시간_SIN`
>
> - 시간에 따른 시각화 결과, 24시간 주기로 주기성을 보였고, 168시간(1주일단위) 주기로도 주기성을 보였다. 그러므로 주기함수인 `COS`, `SIN` 함수를 이용해 데이터의 주기성을 나타내는 Feature를 만들었다.

```R
# 11. 주기를 고려한 변수 COS / SIN

df6$`분` <- substr(df6$`시간`, 4, 5)


# 월
df6$`월_COS` <- cos(( 2*pi*as.numeric(df6$`월`) ) / 12)
df6$`월_SIN` <- sin(( 2*pi*as.numeric(df6$`월`) ) / 12)


# 168시간 : 일주일
df6$`168시간_COS` <- cos(( 2*pi*as.numeric(df6$`168시간`) ) / 168) + cos(( 2*pi*as.numeric(df6$`분`) ) / 60)
df6$`168시간_SIN` <- sin(( 2*pi*as.numeric(df6$`168시간`) ) / 168) + sin(( 2*pi*as.numeric(df6$`분`) ) / 60)

# 24시간 : 하루
df6$`24시간_COS` <- cos(( 2*pi*as.numeric(df6$`시간hour`) ) / 24) + cos(( 2*pi*as.numeric(df6$`분`) ) / 60)
df6$`24시간_SIN` <- sin(( 2*pi*as.numeric(df6$`시간hour`) ) / 24) + sin(( 2*pi*as.numeric(df6$`분`) ) / 60)

df6$`분` <- NULL


df7 <- df6


colSums(is.na(df7))
```



```R
df6 <- d12
# 24시간 평균 취급액 추이 그래프
b <- df6 %>% group_by(`시간hour`) %>% summarise(`취급액평균` = mean(`취급액`, na.rm=TRUE))

ggplot(data = b,
       aes(x = `시간hour`,
           y = `취급액평균`)) +
  geom_line(col='red')+
  ggtitle('24시간 취급액 추이 그래프')



# 168시간 평균 취급액 추이 그래프
a <- df6 %>% group_by(`168시간`) %>% summarise(`취급액평균` = mean(`취급액`, na.rm=TRUE))

ggplot(data = a,
       aes(x = `168시간`,
           y = `취급액평균`)) +
  geom_line(col = 'red') +
  ggtitle('168시간(1주일) 취급액 추이 그래프')
```



>### (12) Feature Engineering : `방송내_상품종류별점수`, `방송내_상품선호도`
>
>- 아래의 시각화를 보게되면, 한 방송 편성에서 하나의 상품이 존재하는 경우보다는 상품의 종류가 많을수록 선호하는 상품이 두드러자개 나타나는 등 상품 종류의 수가 서로 영향을 미칠것이다라고 생각하였다.

```R
d10 <- df7
## MAPE가 높은 상품군

# 가전 마더코드 = 100577
data <- d10 %>% filter(`마더코드` == 100577, `날짜` < '20200101') %>% group_by(마더코드, 상품명) %>% summarise(`취급액평균` = mean(`취급액`, na.rm=T))
ggplot(data = data,
       aes(x = `취급액평균`,
           y = `상품명`,
           fill = `상품명`)) +
  geom_bar(stat='identity') +
  theme(legend.position = 'none')
```

> 그래서 다음과 같은 Feature를 생성하였다.
>
> - `방송내_상품종류별점수` : 그룹코드마다 평균 취급액을 구하고, 구한 평균 취급액을 이용해 boxplot을 그린후, boxplot의 IQR과 이상치 upper bound / lower bound를 이용하여 6구간으로 나누어 점수를 부여하였다.
> - `방송내_상품선호도`     : 모든 행을 대상으로 '취급액'을 '판매단가'로 나누어 '최소판매수량'을 구한다. 그리고 그룹코드를 기준으로 모든 '최소판매수량'을 더해 '그룹코드별_최소판매수량합'을 구한다. 마지막으로 모든 방송편성을 기준으로 '방송내_최소판매수량합'을 구하여 '그룹코드별_최소판매수량합'으로 나눈다.

```R

train_rawdata1 <- df7[df7$`날짜시간` < '2020010105',]
# 12. 방송내_상품종류별점수

d <- train_rawdata1 %>% 
  group_by(`마더코드`, `그룹코드`) %>% 
  summarise(`취급액평균` = mean(`취급액`)) %>% 
  arrange(`그룹코드`, `취급액평균`)

b <- boxplot(d$`취급액평균`)


d$방송내_상품종류별_점수 <- 1
d[d$`취급액평균` > b$stats[1,], ]$방송내_상품종류별_점수 <- 2
d[d$`취급액평균` > b$stats[2,], ]$방송내_상품종류별_점수 <- 3
d[d$`취급액평균` > b$stats[3,], ]$방송내_상품종류별_점수 <- 4
d[d$`취급액평균` > b$stats[4,], ]$방송내_상품종류별_점수 <- 5
d[d$`취급액평균` > b$stats[5,], ]$방송내_상품종류별_점수 <- 6
str(d)
d$`그룹코드` <- as.character(d$`그룹코드`)

df8 <- left_join(df7, d[, c('그룹코드', '마더코드', '방송내_상품종류별_점수')], by = c('마더코드', '그룹코드'))
#str(df8)
for (i in 1:nrow(df8)) {
  if(is.na(df8$방송내_상품종류별_점수[i])) {
    df8$방송내_상품종류별_점수[i] <- d[d$그룹코드 == df8$그룹코드[i],]$방송내_상품종류별_점수
  }
}
str(df8)
df9 <- df8


nrow(df9)

colSums(is.na(df9))


# 13. 방송내_상품선호도
df10 <- df9

str(df10)
train_rawdata1 <- df10 %>% filter(`날짜시간` < '2020010105')

train_rawdata1$`전체편성비율` <- train_rawdata1$`그룹코드_전체횟수` / nrow(train_rawdata1)


train_rawdata1$`그룹코드` <- as.numeric(train_rawdata1$`그룹코드`)
train_rawdata1$최소판매수량 <- floor(train_rawdata1$`취급액` / train_rawdata1$`판매단가`)


cnt_amount_df <- train_rawdata1 %>% group_by(`그룹코드`) %>% summarise(`그룹코드별_최소판매수량합` = sum(`최소판매수량`))
cnt_amount_df$`그룹코드` <- as.character(cnt_amount_df$`그룹코드`)

df <- left_join(df10, cnt_amount_df, by='그룹코드')

hap_df <- unique(df[, c('마더코드', '그룹코드', '상품명', '그룹코드별_최소판매수량합')])




hap_df$`방송내_최소판매수량합` <- -999
hap <- hap_df[1,]$`그룹코드별_최소판매수량합`
idx <- c(1)
for(i in 1:(nrow(hap_df) - 1)){
  if(hap_df[i, ]$`마더코드` == hap_df[i+1, ]$`마더코드`){
    idx <- c(idx, i+1)
    hap <- hap + hap_df[i+1, ]$그룹코드별_최소판매수량합
  }
  else{
    hap_df[idx,]$`방송내_최소판매수량합` <- hap
    idx <- c(i+1)
    hap <- hap_df[i+1, ]$`그룹코드별_최소판매수량합`
  }
}


hap_df$방송내_상품선호도 <- hap_df$`그룹코드별_최소판매수량` / hap_df$`방송내_최소판매수량합`
hap_df[hap_df$`방송내_상품선호도` == 1, ]$`방송내_상품선호도` <- 1/2



df11 <- left_join(df10, hap_df[,c('마더코드', '그룹코드', '상품명', '방송내_상품선호도')], by=c('마더코드', '그룹코드', '상품명'))


nrow(df11)
colSums(is.na(df11))
d10 <- df11

```



### 취급액 Boxcox 생성 및 CSV 파일 생성

* 우선 train set과 test set으로 나눈다

```R
### train test 분리
# train데이터 : 2019년 1~12월(6월제외)
train1 <- d10[(d10$`날짜시간`<'2020010105'),]
# test데이터 : 2019년 6월
test1 <- d10[(d10$`날짜시간`>'2020010105'),]
```



- 다음으로 `취급액`을 활용하여 `취급액boxcox`를 만든다.

```R
### train 전처리

# 취급액 분포
boxplot(train1$취급액)
#install.packages('rcompanion')
library(rcompanion)
# 취급액의 분포가 왼쪽으로 치우쳐져 있다
plotNormalHistogram(train1$취급액)

# 정규 변환 - boxcox
#install.packages('MASS')
library(MASS)
Box = boxcox(lm(train1$취급액 ~ 1))
Cox = data.frame(Box$x, Box$y)          
Cox2 = Cox[with(Cox, order(-Cox$Box.y)),] 
lambda = Cox2[1, 'Box.x'] #lambda = 0.22
y2 = (train1$취급액 ^ lambda - 1)/lambda
plotNormalHistogram(y2)
qqnorm(y2); qqline(y2)

# 취급액 boxcox로 변환한 변수 생성
train1['취급액boxcox'] <- y2
summary(train1['취급액boxcox'])
colSums(is.na(train1))

# test 박스콕스
test1$취급액boxcox <- (test1$취급액 ^ lambda - 1)/lambda
colSums(is.na(test1))
```



* 마지막으로 최종 CSV 파일을 생성한다.

```R
nrow(test1)
write.csv(train1, file='2020train.csv')
write.csv(test1, file='2020test.csv')
```

