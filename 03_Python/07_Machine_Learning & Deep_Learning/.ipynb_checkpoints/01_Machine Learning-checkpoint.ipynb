{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_Machine Learning\n",
    "   - Machine Learning(기계학습)이란?\n",
    "       - 사람의 학습방식을 기계에 적용시킨 방법이다.\n",
    "       - 수능의 예를 들어 사람의 학습방식을 설명하겠다\n",
    "       - 수능을 잘 보기위해 정답이 존재하는 수많은 모의고사와 수많은 학습지를 통해 학습하여 수능을 치르는것 처럼, 기계에게도 사람이 학습하는 것 처럼 예측하고자 하는 분야를 학습시키고 예측을 수행하는 방법을 뜻한다 (이해가 될까유..?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 목차\n",
    "\n",
    "#### 1. Machine Learning 체험 (Hold Out Validation)\n",
    "\n",
    "#### 2. K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Machine Learning 체험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris   # iris 데이터셋을 가져오겠다\n",
    "from sklearn.tree import DecisionTreeClassifier   # DecisionTree의 모듈을 가져오겠다\n",
    "from sklearn.model_selection import train_test_split    # train / test 를 분리해주는 함수\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "# scikit-learn 버전확인\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 간단한 머신러닝을 구현하여 실습해보자\n",
    "   - DesicionTree를 사용할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - scikit-learn으로 부터 불러들인 'iris'데이터는 DataFrame형태가 아닌 Bunch형태이다.\n",
    " - 그러므로 데이터의 타입을 확인하는 작업이 항상 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "print(type(iris))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - scikit-learn으로 부터 불러들인 Bunch는 key값들을 가지고 있다.\n",
    "     - data : X 변수들 (설명변수)\n",
    "     - target : Y 변수 (종속변수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "keys = iris.keys()\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - iris의 key값들에 접근해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "\n",
      "key target\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "\n",
      "key feature_names\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "\n",
      "key target_names\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "\n",
      "key DESCR\n",
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('key data')\n",
    "display( iris.data[0:10] )\n",
    "print('*' * 100)\n",
    "print()\n",
    "\n",
    "print('key target')\n",
    "display( iris.target[0:10] )\n",
    "print('*' * 100)\n",
    "print()\n",
    "\n",
    "print('key feature_names')\n",
    "display( iris.feature_names )\n",
    "print('*' * 100)\n",
    "print()\n",
    "\n",
    "print('key target_names')\n",
    "display( iris.target_names )\n",
    "print('*' * 100)\n",
    "print()\n",
    "\n",
    "print('key DESCR')\n",
    "print( iris.DESCR )\n",
    "print('*' * 100)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Feature data set을 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = iris.data\n",
    "iris_data[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### label (target) data set을 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_label = iris.target\n",
    "iris_label[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 위의 `iris_data`와 `iris_label`을 이용하여 `iris_df` DataFrame으로 만들어보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "0       0                5.1               3.5                1.4   \n",
       "1       0                4.9               3.0                1.4   \n",
       "2       0                4.7               3.2                1.3   \n",
       "3       0                4.6               3.1                1.5   \n",
       "4       0                5.0               3.6                1.4   \n",
       "5       0                5.4               3.9                1.7   \n",
       "6       0                4.6               3.4                1.4   \n",
       "7       0                5.0               3.4                1.5   \n",
       "8       0                4.4               2.9                1.4   \n",
       "9       0                4.9               3.1                1.5   \n",
       "\n",
       "   petal width (cm)  \n",
       "0               0.2  \n",
       "1               0.2  \n",
       "2               0.2  \n",
       "3               0.2  \n",
       "4               0.2  \n",
       "5               0.4  \n",
       "6               0.3  \n",
       "7               0.2  \n",
       "8               0.2  \n",
       "9               0.1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = pd.DataFrame(data=iris_data, index=iris_label)\n",
    "iris_df.index.name = 'target'\n",
    "iris_df.columns = iris.feature_names\n",
    "iris_df.reset_index(inplace=True)\n",
    "\n",
    "iris_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) train / test 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - train_test_split() \n",
    "     - test_size : test set의 비율을 지정하는 옵션\n",
    "     - random_state : seed를 유지시켜 몇번을 반복하더라도 train / test 가 변하지 않고 유지되게하는 옵션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(iris_data,   # Feature data 입력 \n",
    "                                                    iris_label,  # Target data 입력\n",
    "                                                    test_size    = 0.2,  # test set의 비율을 지정하는 옵션\n",
    "                                                    random_state = 123)  # np.random.seed()와 같은 기능의 옵션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set\n",
      "x_train의 길이 : 120\n",
      "y_train의 길이 : 120\n",
      "\n",
      "test_set\n",
      "x_test의 길이 : 30\n",
      "y_test의 길이 : 30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('train_set')\n",
    "print('x_train의 길이 :', len(x_train))\n",
    "print('y_train의 길이 :', len(y_train))\n",
    "print()\n",
    "\n",
    "print('test_set')\n",
    "print('x_test의 길이 :', len(x_test))\n",
    "print('y_test의 길이 :', len(y_test))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Machine Learning 학습하기\n",
    "   - DecisionTreeClasiifier라는 머신러닝의 한 종류를 사용하여 위에서 train/test로 나눈 iris데이터를 학습시켜보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=20)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dtc = DecisionTreeClassifier(random_state=20)  # DecisionTreeClassifier() 모델을 불러온다\n",
    "iris_dtc.fit(x_train, y_train)   # train_set을 사용하여 DecisionTreeClassifier() 모델을 학습시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Machine Learning 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 값 : [1 2 2 1 0 1 1 0 0 1 2 0 1 2 2 2 0 0 1 0 0 2 0 2 0 0 0 2 2 0]\n",
      "실제 값 : [1 2 2 1 0 2 1 0 0 1 2 0 1 2 2 2 0 0 1 0 0 2 0 2 0 0 0 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "prediction = iris_dtc.predict(x_test)\n",
    "print('예측 값 :', prediction)\n",
    "print('실제 값 :', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) 예측 정확도 평가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 :  0.9666666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('예측 정확도 : ', (accuracy_score(y_test, prediction)) )\n",
    "\n",
    "# 함수 사용하지 않고 정확도 구현하기\n",
    "sum( prediction == y_test ) / len(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 위에서 만든 `iris_df` 데이터프레임을 사용하여 위 과정을 다시한번 진행해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2\n",
       "5                5.4               3.9                1.7               0.4\n",
       "6                4.6               3.4                1.4               0.3\n",
       "7                5.0               3.4                1.5               0.2\n",
       "8                4.4               2.9                1.4               0.2\n",
       "9                4.9               3.1                1.5               0.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    0\n",
       "9    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_data = iris_df.iloc[ :, 1:]\n",
    "display(feature_df.head(10))\n",
    "\n",
    "y_data = iris_df['target']\n",
    "display(y_data[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) train / test 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set\n",
      "x_train의 길이 : 120\n",
      "y_train의 길이 : 120\n",
      "\n",
      "test_set\n",
      "x_test의 길이 : 30\n",
      "y_test의 길이 : 30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data,   # Feature data 입력 \n",
    "                                                    y_data,  # Target data 입력\n",
    "                                                    test_size    = 0.2,  # test set의 비율을 지정하는 옵션\n",
    "                                                    random_state = 123)  # np.random.seed()와 같은 기능의 옵션\n",
    "print('train_set')\n",
    "print('x_train의 길이 :', len(x_train))\n",
    "print('y_train의 길이 :', len(y_train))\n",
    "print()\n",
    "\n",
    "print('test_set')\n",
    "print('x_test의 길이 :', len(x_test))\n",
    "print('y_test의 길이 :', len(y_test))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (7) Machine Learnin 학습 / 예측 / 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 값 : [1 2 2 1 0 1 1 0 0 1 2 0 1 2 2 2 0 0 1 0 0 2 0 2 0 0 0 2 2 0]\n",
      "실제 값 : [1 2 2 1 0 2 1 0 0 1 2 0 1 2 2 2 0 0 1 0 0 2 0 2 0 0 0 2 2 0]\n",
      "\n",
      "\n",
      "예측 정확도 :  0.9666666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습\n",
    "iris_dtc = DecisionTreeClassifier(random_state=20)  # DecisionTreeClassifier() 모델을 불러온다\n",
    "iris_dtc.fit(x_train, y_train)   # train_set을 사용하여 DecisionTreeClassifier() 모델을 학습시킨다.\n",
    "\n",
    "# 예측\n",
    "prediction = iris_dtc.predict(x_test)\n",
    "print('예측 값 :', prediction)\n",
    "print('실제 값 :', np.array(y_test))\n",
    "print()\n",
    "print()\n",
    "\n",
    "# 평가\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('예측 정확도 : ', (accuracy_score(y_test, prediction)) )\n",
    "\n",
    "# 함수 사용하지 않고 정확도 구현하기\n",
    "sum( prediction == y_test ) / len(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습을 시킬때 테스트 데이터를 이용하지 않고 학습데이터 세트로만 학습하고 예측한다면?\n",
    "   - 학습시킨 데이터를 재사용하여 예측하면, 모의고사를 본 시험지로 재시험을 치르는 것과 같다.\n",
    "   - 학습시킨 데이터를 재사용하는 것은 말이 되지 않는다.\n",
    "   - 한번 나쁜 예를 실습해보자\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris   # iris 데이터셋을 가져오겠다\n",
    "from sklearn.tree import DecisionTreeClassifier   # DecisionTree의 모듈을 가져오겠다\n",
    "from sklearn.model_selection import train_test_split    # train / test 를 분리해주는 함수\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_iris = load_iris()\n",
    "train_data = iris.data\n",
    "train_label = iris.target\n",
    "\n",
    "bad_iris_clf = DecisionTreeClassifier()\n",
    "bad_iris_clf.fit(train_data, train_label)       # 학습데이터(train_data)와\n",
    "bad_predict = bad_iris_clf.predict(train_data)  # 예측데이터(train_data)가 같다..\n",
    "                                                # 절대 일어나면 안되는 일\n",
    "\n",
    "sum( train_label == bad_predict ) / len(train_label)  # 예측정확도가 1이 나온것을 볼 수있다.\n",
    "                                                       # 이것은 시험을 치르기전에 \n",
    "                                                       # 시험지가 유출되서 모든 사람이 정답을 알고 있는것과 같은원리\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - `1.` 에서 Data set을 train / test로 나누어서 예측을 시행했던 방식을 **Hold Out Validation** 방식이라고 한다.\n",
    " - **Hold Out Validation**은 train / test 로나누기도 하지만, 보통 train / test / validation 세가지로 나누어 진행한다.\n",
    " - **K-Fold Cross Validation**은 주어진 데이터 셋을 train / test / validation으로 나눈 **Hold Out**방식을 `K`번 시행하는 것을 말한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris   # iris 데이터셋을 가져오겠다\n",
    "from sklearn.tree import DecisionTreeClassifier   # DecisionTree의 모듈을 가져오겠다\n",
    "from sklearn.model_selection import train_test_split, KFold    # train / test 를 분리해주는 함수\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `iris`데이터를 이용하여 5-Fold Cross Validation을 실습해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris 데이터 불러오기\n",
    "fold_iris = load_iris()\n",
    "features = fold_iris.data   # 설명변수(X) 데이터\n",
    "label = fold_iris.target    # 종속변수(Y) 데이터\n",
    "\n",
    "\n",
    "# DecisionTreeClassifier() 모델 생성\n",
    "fold_df_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### (1) KFold()\n",
    "     - n_split=5 : Fold를 5개로 나누는 옵션\n",
    "     - shuffle = [boolean]\n",
    "         - True : train / test 인덱스를 무작위로 부여한다\n",
    "         - False : 데이터프레임의 인덱스 순서를 유지한체로 5등분하여 그 5등분의 data set을 K-fold set으로 사용하는 것이다.\n",
    "         \n",
    "##### 말로 설명하기 너무어렵다..\n",
    "##### shuffle= True / False의 차이점을 이해하기 위해 아래의 결과를 한번 보라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 fold\n",
      "train_set의 인덱스\n",
      "[ 75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92\n",
      "  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110\n",
      " 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128\n",
      " 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146\n",
      " 147 148 149]\n",
      "\n",
      "test_set의 인덱스\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74]\n",
      "\n",
      "****************************************************************************************************\n",
      "2 번째 fold\n",
      "train_set의 인덱스\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74]\n",
      "\n",
      "test_set의 인덱스\n",
      "[ 75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92\n",
      "  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110\n",
      " 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128\n",
      " 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146\n",
      " 147 148 149]\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "kfold01 = KFold(n_splits=2, shuffle=False)\n",
    "\n",
    "k = 1\n",
    "for train_idx, test_idx in kfold01.split(features):\n",
    "    print(k, '번째 fold')\n",
    "    print('train_set의 인덱스')\n",
    "    print(train_idx)\n",
    "    print()\n",
    "    print('test_set의 인덱스')\n",
    "    print(test_idx)\n",
    "    print()\n",
    "    print('*'*100)\n",
    "    \n",
    "    k += 1\n",
    "    \n",
    "    \n",
    "### fold의 인덱스가 무작위로 선정되지 않음을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 fold\n",
      "train_set의 인덱스\n",
      "[  0   2   3   6   8   9  12  13  15  19  20  21  22  25  26  27  28  31\n",
      "  32  33  34  36  40  41  42  45  46  47  49  51  53  59  60  62  63  64\n",
      "  66  68  69  75  76  79  80  83  84  86  90  93  94  95  97  98  99 100\n",
      " 101 103 106 109 111 118 119 121 123 124 127 128 129 132 136 138 139 141\n",
      " 143 145 147]\n",
      "\n",
      "test_set의 인덱스\n",
      "[  1   4   5   7  10  11  14  16  17  18  23  24  29  30  35  37  38  39\n",
      "  43  44  48  50  52  54  55  56  57  58  61  65  67  70  71  72  73  74\n",
      "  77  78  81  82  85  87  88  89  91  92  96 102 104 105 107 108 110 112\n",
      " 113 114 115 116 117 120 122 125 126 130 131 133 134 135 137 140 142 144\n",
      " 146 148 149]\n",
      "\n",
      "****************************************************************************************************\n",
      "2 번째 fold\n",
      "train_set의 인덱스\n",
      "[  1   4   5   7  10  11  14  16  17  18  23  24  29  30  35  37  38  39\n",
      "  43  44  48  50  52  54  55  56  57  58  61  65  67  70  71  72  73  74\n",
      "  77  78  81  82  85  87  88  89  91  92  96 102 104 105 107 108 110 112\n",
      " 113 114 115 116 117 120 122 125 126 130 131 133 134 135 137 140 142 144\n",
      " 146 148 149]\n",
      "\n",
      "test_set의 인덱스\n",
      "[  0   2   3   6   8   9  12  13  15  19  20  21  22  25  26  27  28  31\n",
      "  32  33  34  36  40  41  42  45  46  47  49  51  53  59  60  62  63  64\n",
      "  66  68  69  75  76  79  80  83  84  86  90  93  94  95  97  98  99 100\n",
      " 101 103 106 109 111 118 119 121 123 124 127 128 129 132 136 138 139 141\n",
      " 143 145 147]\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "kfold02 = KFold(n_splits=2, shuffle=True)\n",
    "\n",
    "\n",
    "k = 1\n",
    "for train_idx, test_idx in kfold02.split(features):\n",
    "    print(k, '번째 fold')\n",
    "    print('train_set의 인덱스')\n",
    "    print(train_idx)\n",
    "    print()\n",
    "    print('test_set의 인덱스')\n",
    "    print(test_idx)\n",
    "    print()\n",
    "    print('*'*100)\n",
    "    \n",
    "    k += 1\n",
    "    \n",
    "    \n",
    "## fold의 인덱스가 무작위로 선정되었음을 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이제 iris 데에터에 KFold를 본격적으로 적용해보자\n",
    "   - shuffle = True로하여 Train와 Test의 인덱스를 무작위로 부여할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris shape 150\n"
     ]
    }
   ],
   "source": [
    "# Kfold를 나눌 인덱스를 생성\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# feature data\n",
    "print('iris shape', features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 Fold\n",
      "1 번째 Fold의 real y : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2]\n",
      "1 번째 Fold의 pred y : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2]\n",
      "1 번째 Fold의 accuracy : 1.0\n",
      "****************************************************************************************************\n",
      "\n",
      "2 번째 Fold\n",
      "2 번째 Fold의 real y : [0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2]\n",
      "2 번째 Fold의 pred y : [0 0 0 0 0 0 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 1 2 1 2 1 1 2 2 2]\n",
      "2 번째 Fold의 accuracy : 0.8333333333333334\n",
      "****************************************************************************************************\n",
      "\n",
      "3 번째 Fold\n",
      "3 번째 Fold의 real y : [0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "3 번째 Fold의 pred y : [0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "3 번째 Fold의 accuracy : 0.9666666666666667\n",
      "****************************************************************************************************\n",
      "\n",
      "4 번째 Fold\n",
      "4 번째 Fold의 real y : [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n",
      "4 번째 Fold의 pred y : [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 2 1 1 1 2 2 2 2 2 2 2 2 2 2]\n",
      "4 번째 Fold의 accuracy : 0.9666666666666667\n",
      "****************************************************************************************************\n",
      "\n",
      "5 번째 Fold\n",
      "5 번째 Fold의 real y : [0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2]\n",
      "5 번째 Fold의 pred y : [0 0 0 0 0 0 0 0 0 1 1 1 1 1 2 1 1 1 1 2 2 2 2 2 2 2 2 2 2 1]\n",
      "5 번째 Fold의 accuracy : 0.9333333333333333\n",
      "****************************************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 각각의 K-fold set으로 부터 나오는 정확도를 담을 리스트\n",
    "cv_accuracy = []\n",
    "\n",
    "k = 1\n",
    "for train_idx, test_idx in kfold.split(features): # features라는 데이터의 K-fold를 시행하기위해 train, test 인덱스를 생성하겠다!\n",
    "    x_train = features[train_idx]\n",
    "    y_train = label[train_idx]\n",
    "    \n",
    "    x_test = features[test_idx]\n",
    "    y_test = label[test_idx]\n",
    "    \n",
    "    \n",
    "    # K번째 fold의 학습을 진행\n",
    "    fold_df_clf.fit(x_train, y_train)\n",
    "    \n",
    "    # K번째 fold의 예측을 진행\n",
    "    y_pred = fold_df_clf.predict(x_test)\n",
    "    \n",
    "    # k번째 fold의 정확도를 기록\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "    print(k, '번째 Fold')\n",
    "    print(k, '번째 Fold의 real y :', y_test)\n",
    "    print(k, '번째 Fold의 pred y :', y_pred)\n",
    "    print(k, '번째 Fold의 accuracy :', accuracy)\n",
    "    print('*'*100)\n",
    "    print()\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5-Fold Cross Validation 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold Cross Validation의 평균결과 :  0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "print('5-Fold Cross Validation의 평균결과 : ', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Stratified K Fold\n",
    "   - KFold() 함수는 shuffle=True 이든지 False이든지, 일정한 규칙에 따라 train / test 인덱스를 부여하고 있다.\n",
    "   - Straified KFold() 함수는 레이블의 분포를 먼저 고려하여 train / test 인덱스를 부여하는 방법이다\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여기서 잠깐..!\n",
    "##### 기존 KFold()함수의 단점을 짚고 넘어가자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold_iris_data = load_iris()\n",
    "\n",
    "kfold_iris_df = pd.DataFrame(data    =  kfold_iris_data.data, \n",
    "                             columns =  kfold_iris_data.feature_names)\n",
    "\n",
    "kfold_iris_df['target'] = kfold_iris_data.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 Fold\n",
      "1 번째 Fold의 y_train target :\n",
      " 2    50\n",
      "1    50\n",
      "Name: target, dtype: int64\n",
      "\n",
      "1 번째 Fold의 y_test target :\n",
      " 0    50\n",
      "Name: target, dtype: int64\n",
      "\n",
      "1 번째 Fold의 accuracy : 0.0\n",
      "****************************************************************************************************\n",
      "\n",
      "2 번째 Fold\n",
      "2 번째 Fold의 y_train target :\n",
      " 2    50\n",
      "0    50\n",
      "Name: target, dtype: int64\n",
      "\n",
      "2 번째 Fold의 y_test target :\n",
      " 1    50\n",
      "Name: target, dtype: int64\n",
      "\n",
      "2 번째 Fold의 accuracy : 0.0\n",
      "****************************************************************************************************\n",
      "\n",
      "3 번째 Fold\n",
      "3 번째 Fold의 y_train target :\n",
      " 1    50\n",
      "0    50\n",
      "Name: target, dtype: int64\n",
      "\n",
      "3 번째 Fold의 y_test target :\n",
      " 2    50\n",
      "Name: target, dtype: int64\n",
      "\n",
      "3 번째 Fold의 accuracy : 0.0\n",
      "****************************************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfold_iris = KFold(n_splits=3)\n",
    "k = 1\n",
    "\n",
    "for train_idx, test_idx in kfold_iris.split(kfold_iris_df): # features라는 데이터의 K-fold를 시행하기위해 train, test 인덱스를 생성하겠다!\n",
    "    x_train = kfold_iris_df.loc[train_idx, : ].drop(['target'], axis=1, inplace=False)\n",
    "    y_train = kfold_iris_df.loc[train_idx,  'target']\n",
    "    \n",
    "    x_test = kfold_iris_df.loc[test_idx, : ].drop(['target'], axis=1, inplace=False)\n",
    "    y_test = kfold_iris_df.loc[test_idx,  'target']\n",
    "    \n",
    "    \n",
    "    # K번째 fold의 학습을 진행\n",
    "    fold_df_clf.fit(np.array(x_train), np.array(y_train))\n",
    "    \n",
    "    # K번째 fold의 예측을 진행\n",
    "    y_pred = fold_df_clf.predict(np.array(x_test))\n",
    "    \n",
    "    # k번째 fold의 정확도를 기록\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "    print(k, '번째 Fold')\n",
    "    print(k, '번째 Fold의 y_train target :\\n', y_train.value_counts())\n",
    "    print()\n",
    "    print(k, '번째 Fold의 y_test target :\\n', y_test.value_counts())\n",
    "    print()\n",
    "    print(k, '번째 Fold의 accuracy :', accuracy)\n",
    "    print('*'*100)\n",
    "    print()\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 위 결과를 잘 보면, 모든 Fold에서 정확도가 0이다..!\n",
    "   - 1-Fold의 경우\n",
    "       - Train set의 target값은 1과 2만을 가진다.\n",
    "       - Test set의 target값은 0의 값을 가진다\n",
    "           ##### 이 경우 test set의 target값인 0을 할습할 수 없기 때문에 정확도가 0이 나온다!\n",
    "   - 2-Fold의 경우 / 3-Fold의 경우 \n",
    "       - **Test set의 target값을 가지고 있지않아 학습을 할 수없기 때문에, 정확도가 0으로 나타나게 된다!!**\n",
    "       \n",
    "       \n",
    "       \n",
    "### 그래서 이러한 문제점을 방지하기 위해...\n",
    "   - **Stratified K Fold**를 사용하여 위의 문제점을 방지한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 Fold\n",
      "1 번째 Fold의 y_train target :\n",
      " 2    34\n",
      "1    33\n",
      "0    33\n",
      "Name: target, dtype: int64\n",
      "\n",
      "1 번째 Fold의 y_test target :\n",
      " 1    17\n",
      "0    17\n",
      "2    16\n",
      "Name: target, dtype: int64\n",
      "\n",
      "1 번째 Fold의 accuracy : 0.98\n",
      "****************************************************************************************************\n",
      "\n",
      "2 번째 Fold\n",
      "2 번째 Fold의 y_train target :\n",
      " 1    34\n",
      "2    33\n",
      "0    33\n",
      "Name: target, dtype: int64\n",
      "\n",
      "2 번째 Fold의 y_test target :\n",
      " 2    17\n",
      "0    17\n",
      "1    16\n",
      "Name: target, dtype: int64\n",
      "\n",
      "2 번째 Fold의 accuracy : 0.94\n",
      "****************************************************************************************************\n",
      "\n",
      "3 번째 Fold\n",
      "3 번째 Fold의 y_train target :\n",
      " 0    34\n",
      "2    33\n",
      "1    33\n",
      "Name: target, dtype: int64\n",
      "\n",
      "3 번째 Fold의 y_test target :\n",
      " 2    17\n",
      "1    17\n",
      "0    16\n",
      "Name: target, dtype: int64\n",
      "\n",
      "3 번째 Fold의 accuracy : 0.96\n",
      "****************************************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 레이블 값의 분포를 반영해주지 못하는 문제를 해결하기위해서\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf_iris = StratifiedKFold(n_splits=3)\n",
    "k = 1\n",
    "\n",
    "for train_idx, test_idx in skf_iris.split(kfold_iris_df, kfold_iris_df['target']):# 이부분에서 label값이 들어간다는게 KFold()함수와의 차이점\n",
    "    x_train = kfold_iris_df.loc[train_idx, : ].drop(['target'], axis=1, inplace=False)\n",
    "    y_train = kfold_iris_df.loc[train_idx,  'target']\n",
    "    \n",
    "    x_test = kfold_iris_df.loc[test_idx, : ].drop(['target'], axis=1, inplace=False)\n",
    "    y_test = kfold_iris_df.loc[test_idx,  'target']\n",
    "    \n",
    "    \n",
    "    # K번째 fold의 학습을 진행\n",
    "    fold_df_clf.fit(np.array(x_train), np.array(y_train))\n",
    "    \n",
    "    # K번째 fold의 예측을 진행\n",
    "    y_pred = fold_df_clf.predict(np.array(x_test))\n",
    "    \n",
    "    # k번째 fold의 정확도를 기록\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "    print(k, '번째 Fold')\n",
    "    print(k, '번째 Fold의 y_train target :\\n', y_train.value_counts())\n",
    "    print()\n",
    "    print(k, '번째 Fold의 y_test target :\\n', y_test.value_counts())\n",
    "    print()\n",
    "    print(k, '번째 Fold의 accuracy :', accuracy)\n",
    "    print('*'*100)\n",
    "    print()\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stratified K Fold는 y_train과 y_test의 target값[0, 1, 2] 이 골고루 들어가 있음을 볼 수 있다!\n",
    "\n",
    "### 참고로... `Stratified K Fold`는 분류(Classification)에서만 적용할 수 있다.\n",
    "### 회귀에서는 적용할 수 없다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습\n",
    "   - iris 데이터에서 Stratified KFold를 적용하여 3Fold 교차검증을 진행하고, 평균 정확도를 확인하라\n",
    "   - `random_state = 100`으로 세팅한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  y\n",
       "0                5.1               3.5                1.4               0.2  0\n",
       "1                4.9               3.0                1.4               0.2  0\n",
       "2                4.7               3.2                1.3               0.2  0\n",
       "3                4.6               3.1                1.5               0.2  0\n",
       "4                5.0               3.6                1.4               0.2  0\n",
       "5                5.4               3.9                1.7               0.4  0\n",
       "6                4.6               3.4                1.4               0.3  0\n",
       "7                5.0               3.4                1.5               0.2  0\n",
       "8                4.4               2.9                1.4               0.2  0\n",
       "9                4.9               3.1                1.5               0.1  0"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "iris_data = load_iris()\n",
    "x_data = iris_data.data\n",
    "y_data = iris_data.target\n",
    "\n",
    "# 데이터프레임만들기\n",
    "iris_df = pd.DataFrame(data=x_data, columns=iris_data.feature_names)\n",
    "iris_df['y'] = y_data\n",
    "\n",
    "iris_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 예측값 :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2\n",
      " 2 2 2 1 2 2 2 2 2 2 2 2 2]\n",
      "1 번째 실제값 :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "1 번째 정확도 :  0.98\n",
      "****************************************************************************************************\n",
      "\n",
      "2 번째 예측값 :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 2 2 2 1\n",
      " 2 2 2 2 2 2 2 2 2 1 2 2 2]\n",
      "2 번째 실제값 :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "2 번째 정확도 :  0.92\n",
      "****************************************************************************************************\n",
      "\n",
      "3 번째 예측값 :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
      " 2 1 2 2 2 2 2 2 2 2 2 2 2]\n",
      "3 번째 실제값 :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "3 번째 정확도 :  0.96\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "\n",
      "전체정확도 : [0.98, 0.92, 0.96]\n",
      "3-fold cv의 평균정확도 : 0.9533333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lan41\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# stratifiedKFold 불러오기\n",
    "kfold = StratifiedKFold(n_splits=3, random_state=100)\n",
    "\n",
    "# DecisionTreeClassifier() 모델 생성\n",
    "model = DecisionTreeClassifier(random_state=100)\n",
    "\n",
    "# 각각의 fold의 accuracy를 담는 리스트\n",
    "K_accuracy = []\n",
    "K = 1\n",
    "\n",
    "for train_idx, test_idx in kfold.split(iris_df, iris_df['y']):\n",
    "    x_train, y_train = iris_df.loc[train_idx, :].drop(['y'], axis=1, inplace=False), iris_df.loc[train_idx, 'y']\n",
    "    x_test, y_test = iris_df.loc[test_idx, :].drop(['y'], axis=1, inplace=False), iris_df.loc[test_idx, 'y']\n",
    "    \n",
    "    model.fit(np.array(x_train), np.array(y_train))\n",
    "    y_pred = model.predict(np.array(x_test))\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    K_accuracy.append(accuracy)\n",
    "    \n",
    "    print(K, '번째 예측값 : ', np.array(y_pred))\n",
    "    print(K, '번째 실제값 : ', np.array(y_test))\n",
    "    print(K, '번째 정확도 : ', accuracy)\n",
    "    print('*'* 100)\n",
    "    print()\n",
    "    K += 1\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print('전체정확도 :', K_accuracy)\n",
    "print('3-fold cv의 평균정확도 :', np.mean(K_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
