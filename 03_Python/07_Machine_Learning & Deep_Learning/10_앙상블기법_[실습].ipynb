{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbF-faswqHpS"
   },
   "source": [
    "###### 2020-11-04 수요일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 본 실습은.. 데이터의 크기가 커서 코랩을 통해 진행하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNBbhQ7yqKtz"
   },
   "source": [
    "# 10_앙상블기법_[실습]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fz65IwNRi9g8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEzvZz2C9VKY"
   },
   "source": [
    "### 데이터 설명\n",
    "     - Kaggle 경진대회에서 진행했던 `Standard Customer Satisfacion`데이터 셋이다.\n",
    "     - 이 데이터셋은 최종 Test set의 결과를 제출해야 하기에, Test set에는 target값(Y)이 없어 최종예측결과의 성능을 비교할 수 없다\n",
    "     - 그러므로 train set을 temp_train set과 temp_test set으로 나누어서 예측을 진행하고 temp_test set에 대하여 예측을 진행한 후 성능을 비교해보자\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5eE6WIoti10Z"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/실습데이터/santander-customer-satisfaction/train.csv')\n",
    "test = pd.read_csv('/실습데이터/santander-customer-satisfaction/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BGQ7KwbAi14x"
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(['TARGET'], axis=1, inplace=False)\n",
    "y_train = train['TARGET']\n",
    "\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3yZJHIhQi18z"
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2SbUQnErA-W"
   },
   "outputs": [],
   "source": [
    "def model_eval(y_test, y_pred):\n",
    "    print('Confusion Matrix : \\n', confusion_matrix(y_test, y_pred))\n",
    "    print('accuracy         : ', accuracy_score(y_test, y_pred))\n",
    "    print('precision        : ', precision_score(y_test, y_pred))\n",
    "    print('recall           : ', recall_score(y_test, y_pred))\n",
    "    print('f1               : ', f1_score(y_test, y_pred))\n",
    "    print('AUC              : ', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_M0wygAp9n6"
   },
   "source": [
    "## 1. 데이터 전처리 없이 XGBoost를 이용한 예측을 시행하라\n",
    "    - 제공받은 데이터의 Test set에는 Target값이 나타나지 않아 성능을 예측할 수 없다. (실제 데이터나 현업 데이터는 모두 이러한 형식이다.)\n",
    "    - 그러므로 제공받은 Train set을 임시 Train set과 임시 Test set으로 나누어 성능을 비교해보자\n",
    "    - 우선은 하이퍼파라미터 튜닝없이 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ff0NcOeesYpE"
   },
   "outputs": [],
   "source": [
    "temp_X_train, temp_X_test, temp_y_train, temp_y_test = train_test_split(X_train, y_train,\n",
    "                                                                        test_size = 0.2,\n",
    "                                                                        random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uihGcVhHi2Fd"
   },
   "outputs": [],
   "source": [
    "xgboost = XGBClassifier(random_state=123)\n",
    "xgboost.fit(temp_X_train, temp_y_train)\n",
    "temp_y_pred = xgboost.predict(temp_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1w8YjT2Ei2MG"
   },
   "outputs": [],
   "source": [
    "model_eval(temp_y_test, temp_y_pred)\n",
    "\n",
    "## 이게 정녕.. 결과란 말인가..?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzlxrgNIqQRm"
   },
   "source": [
    "## 2. 성능평가를 early stopping을 통해 조기중단하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OjSdtM-Di2Uu"
   },
   "outputs": [],
   "source": [
    "xgboost = XGBClassifier(random_state=123)\n",
    "\n",
    "xgboost.fit(temp_X_train, temp_y_train,\n",
    "            eval_metric                  = 'logloss',\n",
    "            early_stopping_rounds        = 50,\n",
    "            eval_set                     = [(temp_X_test, temp_y_test)],\n",
    "            verbose                      = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLIFk4Hai2Yt"
   },
   "outputs": [],
   "source": [
    "temp_y_pred = xgboost.predict(temp_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4KJm1yG8i2br"
   },
   "outputs": [],
   "source": [
    "model_eval(temp_y_test, temp_y_pred)\n",
    "\n",
    "## 위 결과와 다를바가 없다...\n",
    "## 파라미터 튜닝이 필요해보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zt4iXIAYqYL-"
   },
   "source": [
    "## 3. GridSearchCV함수와 Train set을 이용해 하이퍼 파라미터를 튜닝하고 Test set을 예측하라\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3VDHsxli2Sw"
   },
   "outputs": [],
   "source": [
    "xgboost = XGBClassifier(random_state=123)\n",
    "\n",
    "params = {\n",
    "    'booster' : ['gbtree'],\n",
    "    'learning_rate' : [0.1, 0.2],\n",
    "    'max_depth' : [2, 3],\n",
    "    'n_estimators' : [200, 300]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = 3)\n",
    "\n",
    "grid_xgb = GridSearchCV(xgboost,\n",
    "                        cv            = kfold,\n",
    "                        param_grid    = params,\n",
    "                        scoring       = 'roc_auc',\n",
    "                        n_jobs        = -1,\n",
    "                        verbose       = True)\n",
    "\n",
    "grid_xgb.fit(temp_X_train, temp_y_train)\n",
    "\n",
    "print('최적의 하이퍼 파라미터는? ', grid_xgb.best_params_)\n",
    "print('최적의 하이퍼 파라미터 일때 AUC는? ', grid_xgb.best_score_)\n",
    "\n",
    "\n",
    "# 1. \n",
    "# 최적의 하이퍼 파라미터는?  {'booster': 'gbtree', 'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 100}\n",
    "# 최적의 하이퍼 파라미터 일때 AUC는?  0.8390561147467664\n",
    "\n",
    "# 2.\n",
    "# 최적의 하이퍼 파라미터는?  {'booster': 'gbtree', 'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 100}\n",
    "# 최적의 하이퍼 파라미터 일때 AUC는?  0.8390561147467664\n",
    "\n",
    "# 3.\n",
    "# 최적의 하이퍼 파라미터는?  {'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 200}\n",
    "# 최적의 하이퍼 파라미터 일때 AUC는?  0.8392216606483257\n",
    "\n",
    "# 4. \n",
    "# 최적의 하이퍼 파라미터는?  {'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 200}\n",
    "# 최적의 하이퍼 파라미터 일때 AUC는?  0.8392216606483257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Iyk8APei1_t"
   },
   "outputs": [],
   "source": [
    "best_model = grid_xgb.best_estimator_\n",
    "temp_y_pred = best_model.predict(temp_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CzpZjRii17f"
   },
   "outputs": [],
   "source": [
    "print('최적의 하이퍼파라미터의 예측 결과는?')\n",
    "model_eval(temp_y_test, temp_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzSzA0nCqfpq"
   },
   "source": [
    "## 4. 변수중요도를 시각화하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aY1PoD3_i12t"
   },
   "outputs": [],
   "source": [
    "feature_importance = best_model.feature_importances_\n",
    "top20 = pd.Series(feature_importance, index=X_train.columns).sort_values(ascending=False)[0:20]\n",
    "\n",
    "sns.barplot(x=top20, y=top20.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtKa8JVJqp4o"
   },
   "source": [
    "## 5. Cross Validation을 적용한 Stacking을 적용해 보라"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_xPZtlA358k"
   },
   "source": [
    "- 데이터의 크기가 크기 때문에, 파라미터 튜닝 없이 DecisionTree와 LogisticRegression을 기본모델로 사용하고, 위에서 찾은 최적의 하이퍼파라미터를 가진 XGBoost를 Stacking의 최종모델로 사용하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LYQM4q8V3cc1"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_qukWnOj3cjK"
   },
   "outputs": [],
   "source": [
    "\n",
    "def stacking(model, X_train, y_train, X_test, cv):\n",
    "    \n",
    "    k = 0\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits = cv)\n",
    "    stacking_X_train = np.zeros((X_train.shape[0], 1))\n",
    "    stacking_X_test = np.zeros((X_test.shape[0], cv))\n",
    "\n",
    "    for train_idx, validation_idx in kfold.split(X_train, y_train):\n",
    "        \n",
    "        X_train_cv = X_train[train_idx]\n",
    "        y_train_cv = y_train[train_idx]\n",
    "\n",
    "        X_validation = X_train[validation_idx]\n",
    "\n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "        stacking_X_train[validation_idx, :] = model.predict(X_validation).reshape(-1,1)\n",
    "        stacking_X_test[:, k] = model.predict(X_test)\n",
    "\n",
    "        k += 1\n",
    "    \n",
    "    stacking_X_test = stacking_X_test.mean(axis=1).reshape(-1, 1)\n",
    "    return stacking_X_train, stacking_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_Ak08pq3co2"
   },
   "outputs": [],
   "source": [
    "decision = DecisionTreeClassifier(random_state = 123)\n",
    "logistic = LogisticRegression(random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WgONvhp47qIb"
   },
   "outputs": [],
   "source": [
    "decision_train, decision_test = stacking(decision, temp_X_train, temp_y_train, temp_X_test, 3)\n",
    "logistic_train, logistic_test = stacking(logistic, temp_X_train, temp_y_train, temp_X_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_08FgqMqRla"
   },
   "outputs": [],
   "source": [
    "stacking_X_train = np.concatenate([decision_train, logistic_train], axis=1)\n",
    "stacking_X_test = np.concatenate([decision_test, logistic_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t3joaRtj3cnL"
   },
   "outputs": [],
   "source": [
    "best_model.fit(stacking_X_train, temp_y_train)\n",
    "stacking_y_pred = best_model.predict(stacking_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HlWDWd0Kobp7"
   },
   "outputs": [],
   "source": [
    "model_eval(temp_y_test, stacking_y_pred)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "10_앙상블기법_[실습].ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
