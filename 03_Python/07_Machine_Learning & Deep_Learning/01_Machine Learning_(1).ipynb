{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2020-10-26 월요일\n",
    "###### 2020-10-27 화요일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워닝옵션 제거\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_Machine Learning_(1)\n",
    "   - Machine Learning(기계학습)이란?\n",
    "       - 사람의 학습방식을 기계에 적용시킨 방법이다.\n",
    "       - 수능의 예를 들어 사람의 학습방식을 설명하겠다\n",
    "       - 수능을 잘 보기위해 정답이 존재하는 수많은 모의고사와 수많은 학습지를 통해 학습하여 수능을 치르는것 처럼, 기계에게도 사람이 학습하는 것 처럼 예측하고자 하는 분야를 학습시키고 예측을 수행하는 방법을 뜻한다 (이해가 될까유..?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 목차\n",
    "\n",
    "#### 1. Machine Learning 체험 (Hold Out Validation)\n",
    "\n",
    "#### 2. K-Fold Cross Validation\n",
    "\n",
    "#### 3. Cross_val_score()\n",
    "\n",
    "#### 4. Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Machine Learning 체험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris   # iris 데이터셋을 가져오겠다\n",
    "from sklearn.tree import DecisionTreeClassifier   # DecisionTree의 모듈을 가져오겠다\n",
    "from sklearn.model_selection import train_test_split    # train / test 를 분리해주는 함수\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "# scikit-learn 버전확인\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 간단한 머신러닝을 구현하여 실습해보자\n",
    "   - DesicionTree를 사용할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - scikit-learn으로 부터 불러들인 'iris'데이터는 DataFrame형태가 아닌 Bunch형태이다.\n",
    " - 그러므로 데이터의 타입을 확인하는 작업이 항상 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "print(type(iris))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - scikit-learn으로 부터 불러들인 Bunch는 key값들을 가지고 있다.\n",
    "     - data : X 변수들 (설명변수)\n",
    "     - target : Y 변수 (종속변수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "keys = iris.keys()\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - iris의 key값들에 접근해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "\n",
      "key target\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "\n",
      "key feature_names\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "\n",
      "key target_names\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "\n",
      "key DESCR\n",
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "****************************************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('key data')\n",
    "display( iris.data[0:10] )\n",
    "print('*' * 100)\n",
    "print()\n",
    "\n",
    "print('key target')\n",
    "display( iris.target[0:10] )\n",
    "print('*' * 100)\n",
    "print()\n",
    "\n",
    "print('key feature_names')\n",
    "display( iris.feature_names )\n",
    "print('*' * 100)\n",
    "print()\n",
    "\n",
    "print('key target_names')\n",
    "display( iris.target_names )\n",
    "print('*' * 100)\n",
    "print()\n",
    "\n",
    "print('key DESCR')\n",
    "print( iris.DESCR )\n",
    "print('*' * 100)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Feature data set을 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = iris.data\n",
    "iris_data[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### label (target) data set을 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_label = iris.target\n",
    "iris_label[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 위의 `iris_data`와 `iris_label`을 이용하여 `iris_df` DataFrame으로 만들어보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "0       0                5.1               3.5                1.4   \n",
       "1       0                4.9               3.0                1.4   \n",
       "2       0                4.7               3.2                1.3   \n",
       "3       0                4.6               3.1                1.5   \n",
       "4       0                5.0               3.6                1.4   \n",
       "5       0                5.4               3.9                1.7   \n",
       "6       0                4.6               3.4                1.4   \n",
       "7       0                5.0               3.4                1.5   \n",
       "8       0                4.4               2.9                1.4   \n",
       "9       0                4.9               3.1                1.5   \n",
       "\n",
       "   petal width (cm)  \n",
       "0               0.2  \n",
       "1               0.2  \n",
       "2               0.2  \n",
       "3               0.2  \n",
       "4               0.2  \n",
       "5               0.4  \n",
       "6               0.3  \n",
       "7               0.2  \n",
       "8               0.2  \n",
       "9               0.1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = pd.DataFrame(data=iris_data, index=iris_label)\n",
    "iris_df.index.name = 'target'\n",
    "iris_df.columns = iris.feature_names\n",
    "iris_df.reset_index(inplace=True)\n",
    "\n",
    "iris_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) train / test 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - train_test_split() \n",
    "     - test_size : test set의 비율을 지정하는 옵션\n",
    "     - random_state : seed를 유지시켜 몇번을 반복하더라도 train / test 가 변하지 않고 유지되게하는 옵션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(iris_data,   # Feature data 입력 \n",
    "                                                    iris_label,  # Target data 입력\n",
    "                                                    test_size    = 0.2,  # test set의 비율을 지정하는 옵션\n",
    "                                                    random_state = 123)  # np.random.seed()와 같은 기능의 옵션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set\n",
      "x_train의 길이 : 120\n",
      "y_train의 길이 : 120\n",
      "\n",
      "test_set\n",
      "x_test의 길이 : 30\n",
      "y_test의 길이 : 30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('train_set')\n",
    "print('x_train의 길이 :', len(x_train))\n",
    "print('y_train의 길이 :', len(y_train))\n",
    "print()\n",
    "\n",
    "print('test_set')\n",
    "print('x_test의 길이 :', len(x_test))\n",
    "print('y_test의 길이 :', len(y_test))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Machine Learning 학습하기\n",
    "   - DecisionTreeClasiifier라는 머신러닝의 한 종류를 사용하여 위에서 train/test로 나눈 iris데이터를 학습시켜보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dtc = DecisionTreeClassifier(random_state=20)  # DecisionTreeClassifier() 모델을 불러온다\n",
    "iris_dtc.fit(x_train, y_train)   # train_set을 사용하여 DecisionTreeClassifier() 모델을 학습시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Machine Learning 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 값 : [1 2 2 1 0 1 1 0 0 1 2 0 1 2 2 2 0 0 1 0 0 2 0 2 0 0 0 2 2 0]\n",
      "실제 값 : [1 2 2 1 0 2 1 0 0 1 2 0 1 2 2 2 0 0 1 0 0 2 0 2 0 0 0 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "prediction = iris_dtc.predict(x_test)\n",
    "print('예측 값 :', prediction)\n",
    "print('실제 값 :', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) 예측 정확도 평가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 :  0.9666666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('예측 정확도 : ', (accuracy_score(y_test, prediction)) )\n",
    "\n",
    "# 함수 사용하지 않고 정확도 구현하기\n",
    "sum( prediction == y_test ) / len(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 위에서 만든 `iris_df` 데이터프레임을 사용하여 위 과정을 다시한번 진행해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2\n",
       "5                5.4               3.9                1.7               0.4\n",
       "6                4.6               3.4                1.4               0.3\n",
       "7                5.0               3.4                1.5               0.2\n",
       "8                4.4               2.9                1.4               0.2\n",
       "9                4.9               3.1                1.5               0.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    0\n",
       "9    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_data = iris_df.iloc[ :, 1:]\n",
    "display(x_data.head(10))\n",
    "\n",
    "y_data = iris_df['target']\n",
    "display(y_data[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) train / test 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set\n",
      "x_train의 길이 : 120\n",
      "y_train의 길이 : 120\n",
      "\n",
      "test_set\n",
      "x_test의 길이 : 30\n",
      "y_test의 길이 : 30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data,   # Feature data 입력 \n",
    "                                                    y_data,  # Target data 입력\n",
    "                                                    test_size    = 0.2,  # test set의 비율을 지정하는 옵션\n",
    "                                                    random_state = 123)  # np.random.seed()와 같은 기능의 옵션\n",
    "print('train_set')\n",
    "print('x_train의 길이 :', len(x_train))\n",
    "print('y_train의 길이 :', len(y_train))\n",
    "print()\n",
    "\n",
    "print('test_set')\n",
    "print('x_test의 길이 :', len(x_test))\n",
    "print('y_test의 길이 :', len(y_test))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (7) Machine Learnin 학습 / 예측 / 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 값 : [1 2 2 1 0 1 1 0 0 1 2 0 1 2 2 2 0 0 1 0 0 2 0 2 0 0 0 2 2 0]\n",
      "실제 값 : [1 2 2 1 0 2 1 0 0 1 2 0 1 2 2 2 0 0 1 0 0 2 0 2 0 0 0 2 2 0]\n",
      "\n",
      "\n",
      "예측 정확도 :  0.9666666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습\n",
    "iris_dtc = DecisionTreeClassifier(random_state=20)  # DecisionTreeClassifier() 모델을 불러온다\n",
    "iris_dtc.fit(x_train, y_train)   # train_set을 사용하여 DecisionTreeClassifier() 모델을 학습시킨다.\n",
    "\n",
    "# 예측\n",
    "prediction = iris_dtc.predict(x_test)\n",
    "print('예측 값 :', prediction)\n",
    "print('실제 값 :', np.array(y_test))\n",
    "print()\n",
    "print()\n",
    "\n",
    "# 평가\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('예측 정확도 : ', (accuracy_score(y_test, prediction)) )\n",
    "\n",
    "# 함수 사용하지 않고 정확도 구현하기\n",
    "sum( prediction == y_test ) / len(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습을 시킬때 테스트 데이터를 이용하지 않고 학습데이터 세트로만 학습하고 예측한다면?\n",
    "   - 학습시킨 데이터를 재사용하여 예측하면, 모의고사를 본 시험지로 재시험을 치르는 것과 같다.\n",
    "   - 학습시킨 데이터를 재사용하는 것은 말이 되지 않는다.\n",
    "   - 한번 나쁜 예를 실습해보자\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris   # iris 데이터셋을 가져오겠다\n",
    "from sklearn.tree import DecisionTreeClassifier   # DecisionTree의 모듈을 가져오겠다\n",
    "from sklearn.model_selection import train_test_split    # train / test 를 분리해주는 함수\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_iris = load_iris()\n",
    "train_data = iris.data\n",
    "train_label = iris.target\n",
    "\n",
    "bad_iris_clf = DecisionTreeClassifier()\n",
    "bad_iris_clf.fit(train_data, train_label)       # 학습데이터(train_data)와\n",
    "bad_predict = bad_iris_clf.predict(train_data)  # 예측데이터(train_data)가 같다..\n",
    "                                                # 절대 일어나면 안되는 일\n",
    "\n",
    "sum( train_label == bad_predict ) / len(train_label)  # 예측정확도가 1이 나온것을 볼 수있다.\n",
    "                                                       # 이것은 시험을 치르기전에 \n",
    "                                                       # 시험지가 유출되서 모든 사람이 정답을 알고 있는것과 같은원리\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - `1.` 에서 Data set을 train / test로 나누어서 예측을 시행했던 방식을 **Hold Out Validation** 방식이라고 한다.\n",
    " - **Hold Out Validation**은 train / test 로나누기도 하지만, 보통 train / test / validation 세가지로 나누어 진행한다.\n",
    " - **K-Fold Cross Validation**은 주어진 데이터 셋을 train / test / validation으로 나눈 **Hold Out**방식을 `K`번 시행하는 것을 말한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris   # iris 데이터셋을 가져오겠다\n",
    "from sklearn.tree import DecisionTreeClassifier   # DecisionTree의 모듈을 가져오겠다\n",
    "from sklearn.model_selection import train_test_split, KFold    # train / test 를 분리해주는 함수\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `iris`데이터를 이용하여 5-Fold Cross Validation을 실습해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris 데이터 불러오기\n",
    "fold_iris = load_iris()\n",
    "features = fold_iris.data   # 설명변수(X) 데이터\n",
    "label = fold_iris.target    # 종속변수(Y) 데이터\n",
    "\n",
    "\n",
    "# DecisionTreeClassifier() 모델 생성\n",
    "fold_df_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### (1) KFold()\n",
    "     - n_split=5 : Fold를 5개로 나누는 옵션\n",
    "     - shuffle = [boolean]\n",
    "         - True : train / test 인덱스를 무작위로 부여한다\n",
    "         - False : 데이터프레임의 인덱스 순서를 유지한체로 5등분하여 그 5등분의 data set을 K-fold set으로 사용하는 것이다.\n",
    "         \n",
    "##### 말로 설명하기 너무어렵다..\n",
    "##### shuffle= True / False의 차이점을 이해하기 위해 아래의 결과를 한번 보라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 fold\n",
      "train_set의 인덱스\n",
      "[ 75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92\n",
      "  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110\n",
      " 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128\n",
      " 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146\n",
      " 147 148 149]\n",
      "\n",
      "test_set의 인덱스\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74]\n",
      "\n",
      "****************************************************************************************************\n",
      "2 번째 fold\n",
      "train_set의 인덱스\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74]\n",
      "\n",
      "test_set의 인덱스\n",
      "[ 75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92\n",
      "  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110\n",
      " 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128\n",
      " 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146\n",
      " 147 148 149]\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "kfold01 = KFold(n_splits=2, shuffle=False)\n",
    "\n",
    "k = 1\n",
    "for train_idx, test_idx in kfold01.split(features):\n",
    "    print(k, '번째 fold')\n",
    "    print('train_set의 인덱스')\n",
    "    print(train_idx)\n",
    "    print()\n",
    "    print('test_set의 인덱스')\n",
    "    print(test_idx)\n",
    "    print()\n",
    "    print('*'*100)\n",
    "    \n",
    "    k += 1\n",
    "    \n",
    "    \n",
    "### fold의 인덱스가 무작위로 선정되지 않음을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 fold\n",
      "train_set의 인덱스\n",
      "[  2   4   5   6   9  11  13  16  17  19  24  26  31  32  35  36  37  40\n",
      "  41  42  43  44  46  47  55  56  57  59  60  61  67  69  70  73  74  75\n",
      "  76  79  80  81  83  86  87  88  91  92  93  95  96  97  99 101 102 104\n",
      " 105 108 110 111 113 117 120 121 122 123 124 127 129 132 134 136 138 142\n",
      " 144 148 149]\n",
      "\n",
      "test_set의 인덱스\n",
      "[  0   1   3   7   8  10  12  14  15  18  20  21  22  23  25  27  28  29\n",
      "  30  33  34  38  39  45  48  49  50  51  52  53  54  58  62  63  64  65\n",
      "  66  68  71  72  77  78  82  84  85  89  90  94  98 100 103 106 107 109\n",
      " 112 114 115 116 118 119 125 126 128 130 131 133 135 137 139 140 141 143\n",
      " 145 146 147]\n",
      "\n",
      "****************************************************************************************************\n",
      "2 번째 fold\n",
      "train_set의 인덱스\n",
      "[  0   1   3   7   8  10  12  14  15  18  20  21  22  23  25  27  28  29\n",
      "  30  33  34  38  39  45  48  49  50  51  52  53  54  58  62  63  64  65\n",
      "  66  68  71  72  77  78  82  84  85  89  90  94  98 100 103 106 107 109\n",
      " 112 114 115 116 118 119 125 126 128 130 131 133 135 137 139 140 141 143\n",
      " 145 146 147]\n",
      "\n",
      "test_set의 인덱스\n",
      "[  2   4   5   6   9  11  13  16  17  19  24  26  31  32  35  36  37  40\n",
      "  41  42  43  44  46  47  55  56  57  59  60  61  67  69  70  73  74  75\n",
      "  76  79  80  81  83  86  87  88  91  92  93  95  96  97  99 101 102 104\n",
      " 105 108 110 111 113 117 120 121 122 123 124 127 129 132 134 136 138 142\n",
      " 144 148 149]\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "kfold02 = KFold(n_splits=2, shuffle=True)\n",
    "\n",
    "\n",
    "k = 1\n",
    "for train_idx, test_idx in kfold02.split(features):\n",
    "    print(k, '번째 fold')\n",
    "    print('train_set의 인덱스')\n",
    "    print(train_idx)\n",
    "    print()\n",
    "    print('test_set의 인덱스')\n",
    "    print(test_idx)\n",
    "    print()\n",
    "    print('*'*100)\n",
    "    \n",
    "    k += 1\n",
    "    \n",
    "    \n",
    "## fold의 인덱스가 무작위로 선정되었음을 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이제 iris 데에터에 KFold를 본격적으로 적용해보자\n",
    "   - shuffle = True로하여 Train와 Test의 인덱스를 무작위로 부여할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris shape 150\n"
     ]
    }
   ],
   "source": [
    "# Kfold를 나눌 인덱스를 생성\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# feature data\n",
    "print('iris shape', features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 Fold\n",
      "1 번째 Fold의 real y : [0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "1 번째 Fold의 pred y : [0 0 0 0 0 0 0 1 1 1 1 2 1 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "1 번째 Fold의 accuracy : 0.9333333333333333\n",
      "****************************************************************************************************\n",
      "\n",
      "2 번째 Fold\n",
      "2 번째 Fold의 real y : [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n",
      "2 번째 Fold의 pred y : [0 0 0 0 0 0 0 0 0 0 0 0 1 2 1 1 1 1 1 1 2 1 2 2 2 2 2 2 2 2]\n",
      "2 번째 Fold의 accuracy : 0.9333333333333333\n",
      "****************************************************************************************************\n",
      "\n",
      "3 번째 Fold\n",
      "3 번째 Fold의 real y : [0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]\n",
      "3 번째 Fold의 pred y : [0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 2 1 2 2 2 2]\n",
      "3 번째 Fold의 accuracy : 0.9333333333333333\n",
      "****************************************************************************************************\n",
      "\n",
      "4 번째 Fold\n",
      "4 번째 Fold의 real y : [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2]\n",
      "4 번째 Fold의 pred y : [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 1 2 1 2 2 2]\n",
      "4 번째 Fold의 accuracy : 0.9333333333333333\n",
      "****************************************************************************************************\n",
      "\n",
      "5 번째 Fold\n",
      "5 번째 Fold의 real y : [0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2]\n",
      "5 번째 Fold의 pred y : [0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2]\n",
      "5 번째 Fold의 accuracy : 1.0\n",
      "****************************************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 각각의 K-fold set으로 부터 나오는 정확도를 담을 리스트\n",
    "cv_accuracy = []\n",
    "\n",
    "k = 1\n",
    "for train_idx, test_idx in kfold.split(features): # features라는 데이터의 K-fold를 시행하기위해 train, test 인덱스를 생성하겠다!\n",
    "    x_train = features[train_idx]\n",
    "    y_train = label[train_idx]\n",
    "    \n",
    "    x_test = features[test_idx]\n",
    "    y_test = label[test_idx]\n",
    "    \n",
    "    \n",
    "    # K번째 fold의 학습을 진행\n",
    "    fold_df_clf.fit(x_train, y_train)\n",
    "    \n",
    "    # K번째 fold의 예측을 진행\n",
    "    y_pred = fold_df_clf.predict(x_test)\n",
    "    \n",
    "    # k번째 fold의 정확도를 기록\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "    print(k, '번째 Fold')\n",
    "    print(k, '번째 Fold의 real y :', y_test)\n",
    "    print(k, '번째 Fold의 pred y :', y_pred)\n",
    "    print(k, '번째 Fold의 accuracy :', accuracy)\n",
    "    print('*'*100)\n",
    "    print()\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5-Fold Cross Validation 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold Cross Validation의 평균결과 :  0.9466666666666667\n"
     ]
    }
   ],
   "source": [
    "print('5-Fold Cross Validation의 평균결과 : ', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Stratified K Fold\n",
    "   - KFold() 함수는 shuffle=True이면 Target이 균등하든 안하든, 무작위로 인덱스를 선정하여 Train / Test를 나누고 shuffle=False이면, 일정한 규칙에 따라 무작위로 인덱스를 선정하여 Train / Test를 나누는 방법이다.\n",
    "   - Straified KFold() 함수는 KFold() 함수와는 다르게 레이블의 분포를 먼저 고려하여 train / test 인덱스를 부여하는 방법이다\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여기서 잠깐..!\n",
    "##### 기존 KFold()함수의 단점을 짚고 넘어가자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_iris_data = load_iris()\n",
    "\n",
    "kfold_iris_df = pd.DataFrame(data    =  kfold_iris_data.data, \n",
    "                             columns =  kfold_iris_data.feature_names)\n",
    "\n",
    "kfold_iris_df['target'] = kfold_iris_data.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 Fold\n",
      "1 번째 Fold의 y_train target :\n",
      " 2    50\n",
      "1    50\n",
      "Name: target, dtype: int64\n",
      "\n",
      "1 번째 Fold의 y_test target :\n",
      " 0    50\n",
      "Name: target, dtype: int64\n",
      "\n",
      "1 번째 Fold의 accuracy : 0.0\n",
      "****************************************************************************************************\n",
      "\n",
      "2 번째 Fold\n",
      "2 번째 Fold의 y_train target :\n",
      " 2    50\n",
      "0    50\n",
      "Name: target, dtype: int64\n",
      "\n",
      "2 번째 Fold의 y_test target :\n",
      " 1    50\n",
      "Name: target, dtype: int64\n",
      "\n",
      "2 번째 Fold의 accuracy : 0.0\n",
      "****************************************************************************************************\n",
      "\n",
      "3 번째 Fold\n",
      "3 번째 Fold의 y_train target :\n",
      " 1    50\n",
      "0    50\n",
      "Name: target, dtype: int64\n",
      "\n",
      "3 번째 Fold의 y_test target :\n",
      " 2    50\n",
      "Name: target, dtype: int64\n",
      "\n",
      "3 번째 Fold의 accuracy : 0.0\n",
      "****************************************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfold_iris = KFold(n_splits=3)\n",
    "k = 1\n",
    "\n",
    "for train_idx, test_idx in kfold_iris.split(kfold_iris_df): # features라는 데이터의 K-fold를 시행하기위해 train, test 인덱스를 생성하겠다!\n",
    "    x_train = kfold_iris_df.loc[train_idx, : ].drop(['target'], axis=1, inplace=False)\n",
    "    y_train = kfold_iris_df.loc[train_idx,  'target']\n",
    "    \n",
    "    x_test = kfold_iris_df.loc[test_idx, : ].drop(['target'], axis=1, inplace=False)\n",
    "    y_test = kfold_iris_df.loc[test_idx,  'target']\n",
    "    \n",
    "    \n",
    "    # K번째 fold의 학습을 진행\n",
    "    fold_df_clf.fit(np.array(x_train), np.array(y_train))\n",
    "    \n",
    "    # K번째 fold의 예측을 진행\n",
    "    y_pred = fold_df_clf.predict(np.array(x_test))\n",
    "    \n",
    "    # k번째 fold의 정확도를 기록\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "    print(k, '번째 Fold')\n",
    "    print(k, '번째 Fold의 y_train target :\\n', y_train.value_counts())\n",
    "    print()\n",
    "    print(k, '번째 Fold의 y_test target :\\n', y_test.value_counts())\n",
    "    print()\n",
    "    print(k, '번째 Fold의 accuracy :', accuracy)\n",
    "    print('*'*100)\n",
    "    print()\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 위 결과를 잘 보면, 모든 Fold에서 정확도가 0이다..!\n",
    "   - 1-Fold의 경우\n",
    "       - Train set의 target값은 1과 2만을 가진다.\n",
    "       - Test set의 target값은 0의 값을 가진다\n",
    "           ##### 이 경우 test set의 target값인 0을 할습할 수 없기 때문에 정확도가 0이 나온다!\n",
    "   - 2-Fold의 경우 / 3-Fold의 경우 \n",
    "       - **Test set의 target값을 가지고 있지않아 학습을 할 수없기 때문에, 정확도가 0으로 나타나게 된다!!**\n",
    "       \n",
    "       \n",
    "       \n",
    "### 그래서 이러한 문제점을 방지하기 위해...\n",
    "   - **Stratified K Fold**를 사용하여 위의 문제점을 방지한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 Fold\n",
      "1 번째 Fold의 y_train target :\n",
      " 2    34\n",
      "1    33\n",
      "0    33\n",
      "Name: target, dtype: int64\n",
      "\n",
      "1 번째 Fold의 y_test target :\n",
      " 1    17\n",
      "0    17\n",
      "2    16\n",
      "Name: target, dtype: int64\n",
      "\n",
      "1 번째 Fold의 accuracy : 0.98\n",
      "****************************************************************************************************\n",
      "\n",
      "2 번째 Fold\n",
      "2 번째 Fold의 y_train target :\n",
      " 1    34\n",
      "2    33\n",
      "0    33\n",
      "Name: target, dtype: int64\n",
      "\n",
      "2 번째 Fold의 y_test target :\n",
      " 2    17\n",
      "0    17\n",
      "1    16\n",
      "Name: target, dtype: int64\n",
      "\n",
      "2 번째 Fold의 accuracy : 0.92\n",
      "****************************************************************************************************\n",
      "\n",
      "3 번째 Fold\n",
      "3 번째 Fold의 y_train target :\n",
      " 0    34\n",
      "2    33\n",
      "1    33\n",
      "Name: target, dtype: int64\n",
      "\n",
      "3 번째 Fold의 y_test target :\n",
      " 2    17\n",
      "1    17\n",
      "0    16\n",
      "Name: target, dtype: int64\n",
      "\n",
      "3 번째 Fold의 accuracy : 1.0\n",
      "****************************************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 레이블 값의 분포를 반영해주지 못하는 문제를 해결하기위해서\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf_iris = StratifiedKFold(n_splits=3)\n",
    "k = 1\n",
    "\n",
    "for train_idx, test_idx in skf_iris.split(kfold_iris_df, kfold_iris_df['target']):# 이부분에서 label값이 들어간다는게 KFold()함수와의 차이점\n",
    "    x_train = kfold_iris_df.loc[train_idx, : ].drop(['target'], axis=1, inplace=False)\n",
    "    y_train = kfold_iris_df.loc[train_idx,  'target']\n",
    "    \n",
    "    x_test = kfold_iris_df.loc[test_idx, : ].drop(['target'], axis=1, inplace=False)\n",
    "    y_test = kfold_iris_df.loc[test_idx,  'target']\n",
    "    \n",
    "    \n",
    "    # K번째 fold의 학습을 진행\n",
    "    fold_df_clf.fit(np.array(x_train), np.array(y_train))\n",
    "    \n",
    "    # K번째 fold의 예측을 진행\n",
    "    y_pred = fold_df_clf.predict(np.array(x_test))\n",
    "    \n",
    "    # k번째 fold의 정확도를 기록\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "    print(k, '번째 Fold')\n",
    "    print(k, '번째 Fold의 y_train target :\\n', y_train.value_counts())\n",
    "    print()\n",
    "    print(k, '번째 Fold의 y_test target :\\n', y_test.value_counts())\n",
    "    print()\n",
    "    print(k, '번째 Fold의 accuracy :', accuracy)\n",
    "    print('*'*100)\n",
    "    print()\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stratified K Fold는 y_train과 y_test의 target값[0, 1, 2] 이 골고루 들어가 있음을 볼 수 있다!\n",
    "\n",
    "### 참고로... `Stratified K Fold`는 분류(Classification)에서만 적용할 수 있다.\n",
    "### 회귀에서는 적용할 수 없다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습\n",
    "   - iris 데이터에서 Stratified KFold를 적용하여 3Fold 교차검증을 진행하고, 평균 정확도를 확인하라\n",
    "   - `random_state = 100`으로 세팅한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  y\n",
       "0                5.1               3.5                1.4               0.2  0\n",
       "1                4.9               3.0                1.4               0.2  0\n",
       "2                4.7               3.2                1.3               0.2  0\n",
       "3                4.6               3.1                1.5               0.2  0\n",
       "4                5.0               3.6                1.4               0.2  0\n",
       "5                5.4               3.9                1.7               0.4  0\n",
       "6                4.6               3.4                1.4               0.3  0\n",
       "7                5.0               3.4                1.5               0.2  0\n",
       "8                4.4               2.9                1.4               0.2  0\n",
       "9                4.9               3.1                1.5               0.1  0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "iris_data = load_iris()\n",
    "x_data = iris_data.data\n",
    "y_data = iris_data.target\n",
    "\n",
    "# 데이터프레임만들기\n",
    "iris_df = pd.DataFrame(data=x_data, columns=iris_data.feature_names)\n",
    "iris_df['y'] = y_data\n",
    "\n",
    "iris_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 Fold 예측값 : \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2\n",
      " 2 2 2 1 2 2 2 2 2 2 2 2 2]\n",
      "1 번째 Fold 실제값 : \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "1 번째 Fold 정확도 : \n",
      " 0.98\n",
      "****************************************************************************************************\n",
      "\n",
      "2 번째 Fold 예측값 : \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 2 2 2 1\n",
      " 2 2 2 2 2 2 2 2 2 1 2 2 2]\n",
      "2 번째 Fold 실제값 : \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "2 번째 Fold 정확도 : \n",
      " 0.92\n",
      "****************************************************************************************************\n",
      "\n",
      "3 번째 Fold 예측값 : \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
      " 2 1 2 2 2 2 2 2 2 2 2 2 2]\n",
      "3 번째 Fold 실제값 : \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "3 번째 Fold 정확도 : \n",
      " 0.96\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "\n",
      "전체정확도 : [0.98, 0.92, 0.96]\n",
      "3-fold cv의 평균정확도 : 0.9533333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# stratifiedKFold 불러오기\n",
    "kfold = StratifiedKFold(n_splits=3, random_state=100)\n",
    "\n",
    "# DecisionTreeClassifier() 모델 생성\n",
    "model = DecisionTreeClassifier(random_state=100)\n",
    "\n",
    "# 각각의 fold의 accuracy를 담는 리스트\n",
    "K_accuracy = []\n",
    "K = 1\n",
    "\n",
    "for train_idx, test_idx in kfold.split(iris_df, iris_df['y']):\n",
    "    x_train, y_train = iris_df.loc[train_idx, :].drop(['y'], axis=1, inplace=False), iris_df.loc[train_idx, 'y']\n",
    "    x_test, y_test = iris_df.loc[test_idx, :].drop(['y'], axis=1, inplace=False), iris_df.loc[test_idx, 'y']\n",
    "    \n",
    "    model.fit(np.array(x_train), np.array(y_train))\n",
    "    y_pred = model.predict(np.array(x_test))\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    K_accuracy.append(accuracy)\n",
    "    \n",
    "    print(K, '번째 Fold 예측값 : \\n', np.array(y_pred))\n",
    "    print(K, '번째 Fold 실제값 : \\n', np.array(y_test))\n",
    "    print(K, '번째 Fold 정확도 : \\n', accuracy)\n",
    "    print('*'* 100)\n",
    "    print()\n",
    "    K += 1\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print('전체정확도 :', K_accuracy)\n",
    "print('3-fold cv의 평균정확도 :', np.mean(K_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. cross_val_score() / cross_validate()\n",
    "   - 지금까지 k-Fold cv를 loop를 구현하여 실습해보았다.\n",
    "   - 지금부터는 함수를 적용하여 K-fold cv를 실습해보자.\n",
    "   - cross_val_score(`머신러닝`, `Feature`, `Y`, `(F1 score와 같은 평가지표)`, `cv`)\n",
    "   - cross_val_score()는 Cross Validation을 수행하기 위해 KFold()를 사용하는 것이 아니라 StratifiedKFold()방식을 사용한다.\n",
    "   - cross_val_score()과 cross_validate()의 차이점은 각각의 Fold가 처리된 수행시간을 출력하느냐 아니냐의 차이이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris   # iris 데이터셋을 가져오겠다\n",
    "from sklearn.tree import DecisionTreeClassifier   # DecisionTree의 모듈을 가져오겠다\n",
    "from sklearn.model_selection import cross_val_score, cross_validate  # 지금하는 함수!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross_val_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98, 0.92, 1.  ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터불러오기\n",
    "csv_iris = load_iris()\n",
    "csv_iris_feature =  csv_iris.data\n",
    "csv_iris_label   =  csv_iris.target\n",
    "\n",
    "# 머신러닝 가져오기\n",
    "csv_iris_dtc = DecisionTreeClassifier(random_state=200)\n",
    "\n",
    "# cross_val_score() 함수 사용하여 K-fold cv 수행하기\n",
    "scoring = cross_val_score(csv_iris_dtc, csv_iris_feature, csv_iris_label, scoring='accuracy', cv=3)\n",
    "# scoring = cross_validate(csv_iris_dtc, csv_iris_feature, csv_iris_label, scoring='accuracy', cv=3)  < 나중에 이걸로도 해보세요\n",
    "scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00099802, 0.00199389, 0.        ]),\n",
       " 'score_time': array([0.        , 0.        , 0.00099707]),\n",
       " 'test_score': array([0.98, 0.92, 1.  ])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터불러오기\n",
    "csv_iris = load_iris()\n",
    "csv_iris_feature =  csv_iris.data\n",
    "csv_iris_label   =  csv_iris.target\n",
    "\n",
    "# 머신러닝 가져오기\n",
    "csv_iris_dtc = DecisionTreeClassifier(random_state=200)\n",
    "\n",
    "# cross_validate() 함수 사용하여 K-fold cv 수행하기\n",
    "scoring = cross_validate(csv_iris_dtc, csv_iris_feature, csv_iris_label, scoring='accuracy', cv=3)\n",
    "scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyper Parameter Tuning\n",
    "   - 머신러닝의 내부 알고리즘을 일일이 설명할 수 없지만, 머신러닝 내부에는 알고리즘적으로 수치를 필수적으로 동반한다.\n",
    "   - 이러한 수치를 변화시켜 데이터의 학습정도나, 학습방법을 사용자가 직접 설정할 수 있다.\n",
    "   - 하지만, 데이터마다 최적의 Hyper Parameter가 모두 다르기 때문에, 최적의 예측을 수행하기 위해서는 Hyper Parameter를 찾는 작업이 데이터분석 과정에서 필연적으로 동반된다.\n",
    "   - Hyper Parameter를 찾는 방법중에 대표적인 방법은 **GridSearch**이다.\n",
    "   - **GridSearch**는 Hyper Parameter값들에 넣고자 하는 값들을 여러가지 입력하면, 차례대로 입력 값을 입력하여 예측을 수행하고 성능이 가장 좋은 Hyper Parameter를 선택하는 방법이다\n",
    "   - 파이썬은 **GridSearch**와 **CrossValidation**을 함께 수행해주는 함수가 존재한다\n",
    "   \n",
    "   \n",
    "   - `GridSearchCV()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree Parameter\n",
    "   > 의사결정나무의 Hyper Parameter를 간단히 알아보자\n",
    "   - paramater critetion : 노드를 분리하는 기준(gini계수, entropy)\n",
    "   - parameter splitter : 노드를 분리하는 방법(random, best)\n",
    "   - parameter max_depth : 트리모형의 깊이를의미\n",
    "   - parameter min_samples_split : 브랜치 노드에서 분리가 일어나기 위한 샘플 수\n",
    "   - parameter min_samples_leaf : 노드에 필요한 최소한의 샘플 수\n",
    "   - parameter max_features : 노드를 분리할 때, 고려하는 속성의 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV()\n",
    "   - 백번 이론보다 한번 실습이 더 이해가 빠르다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris   # iris 데이터셋을 가져오겠다\n",
    "from sklearn.tree import DecisionTreeClassifier   # DecisionTree의 모듈을 가져오겠다\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train 길이 : 120\n",
      "y_train 길이 : 120\n",
      "x_test 길이 : 30\n",
      "y_test 길이 : 30\n"
     ]
    }
   ],
   "source": [
    "# iris 데이터 불러오기\n",
    "gscv_iris = load_iris()\n",
    "x_train, x_test, y_train, y_test = train_test_split(gscv_iris.data, \n",
    "                                                    gscv_iris.target,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 120)\n",
    "\n",
    "print('x_train 길이 :', len(x_train))\n",
    "print('y_train 길이 :', len(y_train))\n",
    "print('x_test 길이 :', len(x_test))\n",
    "print('y_test 길이 :', len(y_test))\n",
    "\n",
    "\n",
    "\n",
    "# 트리 모델 불러오기\n",
    "gscv_tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 찾고샂하는 Hyper Parameter 지정하기\n",
    "params = {\n",
    "    'criterion'         : ['gini', 'entropy'],\n",
    "    'splitter'          : ['random', 'best'],\n",
    "    'max_depth'         : [1, 2, 3],\n",
    "    'min_samples_split' : [2, 3]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# GridSeachCV사용하기 : Hyper Parameter 찾고, Cross Validation 수행하기위한 준비\n",
    "grid_gscv_tree = GridSearchCV(gscv_tree, \n",
    "                              param_grid = params, \n",
    "                              cv         = 3, \n",
    "                              refit      = True)  # 최적의 Hyper Parameter를 찾고 재학습을 하겠다는 의미\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00099699, 0.00066487, 0.0006632 , 0.00066431, 0.00066503,\n",
       "        0.00033251, 0.00033228, 0.00066447, 0.00066487, 0.00033299,\n",
       "        0.00100255, 0.00099929, 0.00066574, 0.        , 0.00100851,\n",
       "        0.00099754, 0.00066638, 0.00099683, 0.00100764, 0.00033212,\n",
       "        0.00066614, 0.0006756 , 0.00065335, 0.        ]),\n",
       " 'std_fit_time': array([4.89903609e-07, 4.70134691e-04, 4.68955642e-04, 4.69740766e-04,\n",
       "        4.70246478e-04, 4.70246438e-04, 4.69909263e-04, 4.69853319e-04,\n",
       "        4.70134086e-04, 4.70920787e-04, 8.21415985e-04, 4.51249109e-06,\n",
       "        4.70752291e-04, 0.00000000e+00, 1.58484107e-05, 5.15042996e-07,\n",
       "        4.71204672e-04, 7.01885292e-07, 1.71620900e-05, 4.69684480e-04,\n",
       "        4.71033340e-04, 4.77901159e-04, 4.62195281e-04, 0.00000000e+00]),\n",
       " 'mean_score_time': array([0.00033243, 0.00033267, 0.00033236, 0.0003341 , 0.00033251,\n",
       "        0.00033251, 0.00033275, 0.00033124, 0.00033267, 0.00066447,\n",
       "        0.00065955, 0.00067329, 0.        , 0.00066487, 0.        ,\n",
       "        0.        , 0.00033267, 0.00066638, 0.00033259, 0.        ,\n",
       "        0.00066431, 0.00033077, 0.        , 0.        ]),\n",
       " 'std_score_time': array([0.00047013, 0.00047047, 0.00047002, 0.00047249, 0.00047025,\n",
       "        0.00047025, 0.00047058, 0.00046845, 0.00047047, 0.00046985,\n",
       "        0.00046642, 0.00047662, 0.        , 0.00047013, 0.        ,\n",
       "        0.        , 0.00047047, 0.0004712 , 0.00047036, 0.        ,\n",
       "        0.00046974, 0.00046777, 0.        , 0.        ]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 1, 1, 1, 1, 2, 2,\n",
       "                    2, 2, 3, 3, 3, 3],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[2, 2, 3, 3, 2, 2, 3, 3, 2, 2, 3, 3, 2, 2, 3, 3, 2, 2,\n",
       "                    3, 3, 2, 2, 3, 3],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_splitter': masked_array(data=['random', 'best', 'random', 'best', 'random', 'best',\n",
       "                    'random', 'best', 'random', 'best', 'random', 'best',\n",
       "                    'random', 'best', 'random', 'best', 'random', 'best',\n",
       "                    'random', 'best', 'random', 'best', 'random', 'best'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_split': 3,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_split': 3,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_split': 3,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_split': 3,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'splitter': 'best'}],\n",
       " 'split0_test_score': array([0.65 , 0.675, 0.675, 0.675, 0.875, 0.95 , 0.925, 0.95 , 0.9  ,\n",
       "        0.95 , 0.975, 0.95 , 0.675, 0.675, 0.675, 0.675, 0.875, 0.95 ,\n",
       "        0.875, 0.95 , 0.9  , 0.95 , 0.95 , 0.95 ]),\n",
       " 'split1_test_score': array([0.65 , 0.675, 0.675, 0.675, 0.925, 0.9  , 0.75 , 0.9  , 0.85 ,\n",
       "        0.875, 0.825, 0.875, 0.65 , 0.675, 0.675, 0.675, 0.825, 0.9  ,\n",
       "        0.65 , 0.9  , 0.8  , 0.9  , 0.975, 0.9  ]),\n",
       " 'split2_test_score': array([0.65 , 0.65 , 0.65 , 0.65 , 0.85 , 0.875, 0.925, 0.875, 0.85 ,\n",
       "        0.975, 0.875, 0.975, 0.65 , 0.65 , 0.65 , 0.65 , 0.7  , 0.875,\n",
       "        0.875, 0.875, 0.775, 0.975, 0.875, 0.975]),\n",
       " 'mean_test_score': array([0.65      , 0.66666667, 0.66666667, 0.66666667, 0.88333333,\n",
       "        0.90833333, 0.86666667, 0.90833333, 0.86666667, 0.93333333,\n",
       "        0.89166667, 0.93333333, 0.65833333, 0.66666667, 0.66666667,\n",
       "        0.66666667, 0.8       , 0.90833333, 0.8       , 0.90833333,\n",
       "        0.825     , 0.94166667, 0.93333333, 0.94166667]),\n",
       " 'std_test_score': array([0.        , 0.01178511, 0.01178511, 0.01178511, 0.03118048,\n",
       "        0.03118048, 0.08249579, 0.03118048, 0.02357023, 0.04249183,\n",
       "        0.06236096, 0.04249183, 0.01178511, 0.01178511, 0.01178511,\n",
       "        0.01178511, 0.07359801, 0.03118048, 0.10606602, 0.03118048,\n",
       "        0.05400617, 0.03118048, 0.04249183, 0.03118048]),\n",
       " 'rank_test_score': array([24, 17, 17, 17, 11,  6, 12,  6, 12,  3, 10,  3, 23, 17, 17, 17, 15,\n",
       "         6, 15,  6, 14,  1,  3,  1])}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 수행 : Grid Search / Cross Validation 수행\n",
    "grid_gscv_tree.fit(x_train, y_train)\n",
    "\n",
    "# 학습 결과 출력\n",
    "grid_gscv_tree.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 근데 위 결과 보기가좀.. 힘들지 않음?\n",
    "##### 쉽게보게 해줄게여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_splitter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000997</td>\n",
       "      <td>4.899036e-07</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000665</td>\n",
       "      <td>4.701347e-04</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.011785</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000663</td>\n",
       "      <td>4.689556e-04</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.011785</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000664</td>\n",
       "      <td>4.697408e-04</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.011785</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000665</td>\n",
       "      <td>4.702465e-04</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.031180</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.000997  4.899036e-07         0.000332        0.000470   \n",
       "1       0.000665  4.701347e-04         0.000333        0.000470   \n",
       "2       0.000663  4.689556e-04         0.000332        0.000470   \n",
       "3       0.000664  4.697408e-04         0.000334        0.000472   \n",
       "4       0.000665  4.702465e-04         0.000333        0.000470   \n",
       "\n",
       "  param_criterion param_max_depth param_min_samples_split param_splitter  \\\n",
       "0            gini               1                       2         random   \n",
       "1            gini               1                       2           best   \n",
       "2            gini               1                       3         random   \n",
       "3            gini               1                       3           best   \n",
       "4            gini               2                       2         random   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'criterion': 'gini', 'max_depth': 1, 'min_sam...              0.650   \n",
       "1  {'criterion': 'gini', 'max_depth': 1, 'min_sam...              0.675   \n",
       "2  {'criterion': 'gini', 'max_depth': 1, 'min_sam...              0.675   \n",
       "3  {'criterion': 'gini', 'max_depth': 1, 'min_sam...              0.675   \n",
       "4  {'criterion': 'gini', 'max_depth': 2, 'min_sam...              0.875   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0              0.650               0.65         0.650000        0.000000   \n",
       "1              0.675               0.65         0.666667        0.011785   \n",
       "2              0.675               0.65         0.666667        0.011785   \n",
       "3              0.675               0.65         0.666667        0.011785   \n",
       "4              0.925               0.85         0.883333        0.031180   \n",
       "\n",
       "   rank_test_score  \n",
       "0               24  \n",
       "1               17  \n",
       "2               17  \n",
       "3               17  \n",
       "4               11  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_df = pd.DataFrame(grid_gscv_tree.cv_results_)\n",
    "display(score_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'min_...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'min_...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'min_...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3, 'min_sam...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3, 'min_sam...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3, 'min_sam...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3, 'min_sam...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'min_...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  rank_test_score  \\\n",
       "23  {'criterion': 'entropy', 'max_depth': 3, 'min_...                1   \n",
       "21  {'criterion': 'entropy', 'max_depth': 3, 'min_...                1   \n",
       "22  {'criterion': 'entropy', 'max_depth': 3, 'min_...                3   \n",
       "9   {'criterion': 'gini', 'max_depth': 3, 'min_sam...                3   \n",
       "11  {'criterion': 'gini', 'max_depth': 3, 'min_sam...                3   \n",
       "5   {'criterion': 'gini', 'max_depth': 2, 'min_sam...                6   \n",
       "7   {'criterion': 'gini', 'max_depth': 2, 'min_sam...                6   \n",
       "19  {'criterion': 'entropy', 'max_depth': 2, 'min_...                6   \n",
       "17  {'criterion': 'entropy', 'max_depth': 2, 'min_...                6   \n",
       "10  {'criterion': 'gini', 'max_depth': 3, 'min_sam...               10   \n",
       "4   {'criterion': 'gini', 'max_depth': 2, 'min_sam...               11   \n",
       "6   {'criterion': 'gini', 'max_depth': 2, 'min_sam...               12   \n",
       "8   {'criterion': 'gini', 'max_depth': 3, 'min_sam...               12   \n",
       "20  {'criterion': 'entropy', 'max_depth': 3, 'min_...               14   \n",
       "18  {'criterion': 'entropy', 'max_depth': 2, 'min_...               15   \n",
       "16  {'criterion': 'entropy', 'max_depth': 2, 'min_...               15   \n",
       "1   {'criterion': 'gini', 'max_depth': 1, 'min_sam...               17   \n",
       "14  {'criterion': 'entropy', 'max_depth': 1, 'min_...               17   \n",
       "13  {'criterion': 'entropy', 'max_depth': 1, 'min_...               17   \n",
       "2   {'criterion': 'gini', 'max_depth': 1, 'min_sam...               17   \n",
       "3   {'criterion': 'gini', 'max_depth': 1, 'min_sam...               17   \n",
       "15  {'criterion': 'entropy', 'max_depth': 1, 'min_...               17   \n",
       "12  {'criterion': 'entropy', 'max_depth': 1, 'min_...               23   \n",
       "0   {'criterion': 'gini', 'max_depth': 1, 'min_sam...               24   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \n",
       "23              0.950              0.900              0.975  \n",
       "21              0.950              0.900              0.975  \n",
       "22              0.950              0.975              0.875  \n",
       "9               0.950              0.875              0.975  \n",
       "11              0.950              0.875              0.975  \n",
       "5               0.950              0.900              0.875  \n",
       "7               0.950              0.900              0.875  \n",
       "19              0.950              0.900              0.875  \n",
       "17              0.950              0.900              0.875  \n",
       "10              0.975              0.825              0.875  \n",
       "4               0.875              0.925              0.850  \n",
       "6               0.925              0.750              0.925  \n",
       "8               0.900              0.850              0.850  \n",
       "20              0.900              0.800              0.775  \n",
       "18              0.875              0.650              0.875  \n",
       "16              0.875              0.825              0.700  \n",
       "1               0.675              0.675              0.650  \n",
       "14              0.675              0.675              0.650  \n",
       "13              0.675              0.675              0.650  \n",
       "2               0.675              0.675              0.650  \n",
       "3               0.675              0.675              0.650  \n",
       "15              0.675              0.675              0.650  \n",
       "12              0.675              0.650              0.650  \n",
       "0               0.650              0.650              0.650  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 성능이 가장 좋은 결과부터 출력\n",
    "score_df[ ['params', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score'] ].sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 더 간단히 최적의 경우만 보고싶다면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 하이퍼 파라미터는 ? {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "최적의 하이퍼 파라미터일 때의 정확도는 ? 0.9416666666666668\n"
     ]
    }
   ],
   "source": [
    "print('최적의 하이퍼 파라미터는 ?', grid_gscv_tree.best_params_)\n",
    "print('최적의 하이퍼 파라미터일 때의 정확도는 ?', grid_gscv_tree.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최적의 하이퍼파라매터를 이용하여 최종 test set 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set의 실제 y 값 [1 2 1 1 2 0 2 1 1 2 0 1 0 1 1 0 0 0 0 0 2 0 2 0 1 2 1 0 0 0]\n",
      "test set의 예측 y 값 [1 2 1 1 2 0 2 1 1 2 0 1 0 1 1 0 0 0 0 0 2 0 2 0 1 2 1 0 0 0]\n",
      "최종 Test set 예측에 대한 정확도는? 1.0\n"
     ]
    }
   ],
   "source": [
    "estimator = grid_gscv_tree.best_estimator_\n",
    "y_pred = estimator.predict(x_test)\n",
    "\n",
    "print('test set의 실제 y 값', y_test)\n",
    "print('test set의 예측 y 값', y_pred)\n",
    "print('최종 Test set 예측에 대한 정확도는?', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [실습]\n",
    "   1. `breast_cancer`데이터를 불러오고 데이터프레임으로 만들어라\n",
    "   2. train과 test로 나누어라(7:3)\n",
    "   3. 학습과 예측을 수행해보아라\n",
    "   4. 학습 결과에 대한 평가도 해보아라\n",
    "   5. 교차검을을 수행하라(cv)\n",
    "   6. GridSearch를 동반한 교차검증을 수행하라\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. breast_cancer데이터를 불러오고 데이터프레임으로 만들어라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.5 KB\n"
     ]
    }
   ],
   "source": [
    "cancer_df = pd.DataFrame(data    = cancer.data,\n",
    "                         columns = cancer.feature_names)\n",
    "cancer_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. train과 test로 나누어라(7:3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train 크기 : 398\n",
      "y_train 크기 : 398\n",
      "x_test 크기 : 171\n",
      "y_test 크기 : 171\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(np.array(cancer_df), \n",
    "                                                    cancer.target, \n",
    "                                                    test_size = 0.3)\n",
    "\n",
    "print('x_train 크기 :', len(x_train))\n",
    "print('y_train 크기 :', len(y_train))\n",
    "print('x_test 크기 :', len(x_test))\n",
    "print('y_test 크기 :', len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. 학습과 예측을 수행해보아라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "decisionTree = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "# 학습\n",
    "decisionTree.fit(x_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = decisionTree.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. 학습 결과에 대한 평가도 해보아라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train과 test 비율을 7:3으로 시행한 결과의 정확도는? 0.9239766081871345\n"
     ]
    }
   ],
   "source": [
    "print('train과 test 비율을 7:3으로 시행한 결과의 정확도는?',  accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. 교차검을을 수행하라(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 Fold의 accuracy는? 0.9122807017543859\n",
      "2 번째 Fold의 accuracy는? 0.9298245614035088\n",
      "3 번째 Fold의 accuracy는? 0.9298245614035088\n",
      "4 번째 Fold의 accuracy는? 0.9122807017543859\n",
      "5 번째 Fold의 accuracy는? 0.8938053097345132\n",
      "\n",
      "5-Fold Cross Validation의 평균 accuracy는? 0.9156031672100605\n"
     ]
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "decisionTree = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "# KFold를 수행하기위해 StratifiedKFold방식을 이용해 인덱스 부여\n",
    "k = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# 5-Fold Cross Validation 수행\n",
    "k_fold_accuracy = []\n",
    "cnt = 1\n",
    "for train_idx, test_idx in k.split(cancer.data, cancer.target):\n",
    "    x_train, x_test = cancer.data[train_idx], cancer.data[test_idx]\n",
    "    y_train, y_test = cancer.target[train_idx], cancer.target[test_idx]\n",
    "    \n",
    "    decisionTree.fit(x_train, y_train)\n",
    "    y_pred = decisionTree.predict(x_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    k_fold_accuracy.append(accuracy)\n",
    "    \n",
    "    print(cnt,'번째 Fold의 accuracy는?', accuracy)\n",
    "    cnt += 1\n",
    "\n",
    "print()\n",
    "print('5-Fold Cross Validation의 평균 accuracy는?', np.mean(k_fold_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. GridSearch를 동반한 교차검증을 수행하라 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 나누기\n",
    "x_train, x_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 8, 'min_...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.951648</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.945055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.949451</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 6, 'min_...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.940659</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.956044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 6, 'min_...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 6, 'min_...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'min_sam...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.936264</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.934066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.978022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.931868</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.901099</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.978022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.931868</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.967033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.929670</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.956044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  rank_test_score  \\\n",
       "28  {'criterion': 'entropy', 'max_depth': 8, 'min_...                1   \n",
       "34  {'criterion': 'entropy', 'max_depth': 10, 'min...                2   \n",
       "18  {'criterion': 'entropy', 'max_depth': 6, 'min_...                3   \n",
       "22  {'criterion': 'entropy', 'max_depth': 6, 'min_...                4   \n",
       "20  {'criterion': 'entropy', 'max_depth': 6, 'min_...                4   \n",
       "0   {'criterion': 'gini', 'max_depth': 6, 'min_sam...                6   \n",
       "30  {'criterion': 'entropy', 'max_depth': 10, 'min...                7   \n",
       "16  {'criterion': 'gini', 'max_depth': 10, 'min_sa...                8   \n",
       "12  {'criterion': 'gini', 'max_depth': 10, 'min_sa...                8   \n",
       "32  {'criterion': 'entropy', 'max_depth': 10, 'min...               10   \n",
       "\n",
       "    mean_test_score  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "28         0.951648           0.945055           0.923077           0.978022   \n",
       "34         0.949451           0.945055           0.923077           0.978022   \n",
       "18         0.940659           0.945055           0.923077           0.923077   \n",
       "22         0.938462           0.945055           0.923077           0.923077   \n",
       "20         0.938462           0.945055           0.923077           0.923077   \n",
       "0          0.936264           0.934066           0.945055           0.923077   \n",
       "30         0.934066           0.934066           0.923077           0.912088   \n",
       "16         0.931868           0.923077           0.901099           0.912088   \n",
       "12         0.931868           0.934066           0.912088           0.912088   \n",
       "32         0.929670           0.934066           0.923077           0.912088   \n",
       "\n",
       "    split3_test_score  split4_test_score  \n",
       "28           0.967033           0.945055  \n",
       "34           0.956044           0.945055  \n",
       "18           0.956044           0.956044  \n",
       "22           0.956044           0.945055  \n",
       "20           0.956044           0.945055  \n",
       "0            0.945055           0.934066  \n",
       "30           0.923077           0.978022  \n",
       "16           0.945055           0.978022  \n",
       "12           0.934066           0.967033  \n",
       "32           0.923077           0.956044  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 하이퍼 파라매터는? {'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "최적의 하이퍼 파라매터의 정확도 결과는? 0.9516483516483516\n"
     ]
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "decisionTree = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "# GridSearch를 수행할 Parameter 지정하기\n",
    "params = {\n",
    "    'criterion'         : ['gini', 'entropy'],\n",
    "    'splitter'          : ['random', 'best'],\n",
    "    'max_depth'         : [6, 8, 10],\n",
    "    'min_samples_split' : [3, 4, 5]\n",
    "}\n",
    "\n",
    "\n",
    "# GridSearchCV함수 준비하기\n",
    "\n",
    "grid_cv_decision = GridSearchCV(decisionTree, \n",
    "                                param_grid = params,\n",
    "                                cv         = 5,\n",
    "                                refit      = True)\n",
    "\n",
    "\n",
    "# GridSearchCV함수 실행하기\n",
    "grid_cv_decision.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# 결과 데이터프레임에 저장하기\n",
    "temp_df = pd.DataFrame(grid_cv_decision.cv_results_)\n",
    "result_df = temp_df[ ['params', 'rank_test_score', 'mean_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score'] ]\n",
    "display(result_df.sort_values(by='rank_test_score').head(10))\n",
    "\n",
    "\n",
    "# 간단히 GridSearchCV 결과 출력하기\n",
    "print('최적의 하이퍼 파라매터는?', grid_cv_decision.best_params_)\n",
    "print('최적의 하이퍼 파라매터의 정확도 결과는?', grid_cv_decision.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 복습\n",
    "   - `np.hstack`\n",
    "   - `np.vstack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 5 6]\n",
      " [3 4 7 8]]\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]\n",
      " [7 8]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array( [[1, 2], [3, 4]] )\n",
    "b = np.array( [[5, 6], [7, 8]] )\n",
    "\n",
    "c = np.hstack([ a, b ])\n",
    "d = np.vstack([ a, b ])\n",
    "\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. StandardScaler & 불순도검사\n",
    "   - 데이터 셋마다 다르지만, 정규화를 수행하여 모델의 성능이 높아지는 경우가 있다.\n",
    "   - 우리는 `평균과 표준편차를 이용한 정규화 : StandardScaler()`를 실습해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(criterion_iris.data, criterion_iris.target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# x_train 평균, 표준편차를 구하기 위해서 표준화\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)   ## x_train의 평균, 표준편차를 기준으로 표준화를 시행하기위한 준비단계\n",
    "\n",
    "x_train_std = sc.transform(x_train)  ## x_train 표준화\n",
    "x_test_std = sc.transform(x_test)    ## x_test 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 테스트 개수 : 45, 오류개수 : 1\n",
      "정확도 : 0.98\n"
     ]
    }
   ],
   "source": [
    "decisionTree = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
    "\n",
    "decisionTree.fit(x_train_std, y_train)\n",
    "y_pred = decisionTree.predict(x_test_std)\n",
    "\n",
    "print('총 테스트 개수 : %d, 오류개수 : %d' %( len(y_test), sum(y_test != y_pred) ))\n",
    "print('정확도 : %.2f' %accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 불순도검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불순도plot\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "\n",
    "    # 마커와 컬러맵을 설정합니다.\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # 결정 경계를 그립니다.\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=cl, \n",
    "                    edgecolor='black')\n",
    "\n",
    "    # 테스트 샘플을 부각하여 그립니다.\n",
    "    if test_idx:\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        plt.scatter(X_test[:, 0],\n",
    "                    X_test[:, 1],\n",
    "                    facecolors='none',\n",
    "                    edgecolor='black',\n",
    "                    alpha=1.0,\n",
    "                    linewidth=1,\n",
    "                    marker='o',\n",
    "                    s=100, \n",
    "                    label='test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 4 and input n_features is 2 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-2e266f1ddb5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_combind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# print(y_combind)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplot_decision_regions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_combind_std\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_combind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecisionTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m105\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-107-c1ce7c14e088>\u001b[0m in \u001b[0;36mplot_decision_regions\u001b[1;34m(X, y, classifier, test_idx, resolution)\u001b[0m\n\u001b[0;32m     17\u001b[0m     xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n\u001b[0;32m     18\u001b[0m                            np.arange(x2_min, x2_max, resolution))\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxx1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxx2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontourf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    425\u001b[0m         \"\"\"\n\u001b[0;32m    426\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    397\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 4 and input n_features is 2 "
     ]
    }
   ],
   "source": [
    "x_combind_std = np.vstack((x_train_std, x_test_std))\n",
    "# print(x_combind_std)\n",
    "y_combind = np.hstack((y_train, y_test))\n",
    "# print(y_combind)\n",
    "plot_decision_regions(X=x_combind_std , y=y_combind, classifier=decisionTree, test_idx=range(105,150))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
