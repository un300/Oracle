{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2020-11-10 화요일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02_Spark_(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 스파크에 대한 기본 함수를 사용하여 실습해보았습니다. \n",
    "\n",
    "\n",
    "\n",
    "### 목차\n",
    "\n",
    "#### 1. 스파크 데이터프레임 함수들\n",
    "\n",
    "#### 2. Titanic 데이셋을 이용한 실습\n",
    "\n",
    "#### 3. Spark데이터프레임 + SQL구문 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 스파크 데이터프레임 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 아래 코드는 여러번 실행하면 오류가 뜹니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=sparkApp, master=local) created by __init__ at <ipython-input-2-0d4d90c6c2ee>:2 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-86d1c748062c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mconf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetMaster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'local'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetAppName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'today_sparkApp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mspark\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    131\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    339\u001b[0m                         \u001b[1;34m\" created by %s at %s:%s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[1;32m--> 341\u001b[1;33m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[0;32m    342\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=sparkApp, master=local) created by __init__ at <ipython-input-2-0d4d90c6c2ee>:2 "
     ]
    }
   ],
   "source": [
    "conf = SparkConf().setMaster('local').setAppName('sparkApp')\n",
    "spark = SparkContext(conf=conf)\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x1f9e4ef1988>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlCtx = SQLContext(spark)\n",
    "sqlCtx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 스파크를 이용해 CSV파일을 스파크데이터프레임으로 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = sqlCtx.read.csv('./실습데이터/orders.csv', \n",
    "                         header      = True, \n",
    "                         inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- OrderID: integer (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- EmployeeID: integer (nullable = true)\n",
      " |-- OrderDate: string (nullable = true)\n",
      " |-- ShipperID: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+---------+---------+\n",
      "|OrderID|CustomerID|EmployeeID|OrderDate|ShipperID|\n",
      "+-------+----------+----------+---------+---------+\n",
      "|  10248|        90|         5| 7/4/1996|      3.0|\n",
      "|  10249|        81|         6| 7/5/1996|      1.0|\n",
      "|  10250|        34|         4| 7/8/1996|      2.0|\n",
      "|  10251|        84|         3| 7/8/1996|      1.0|\n",
      "|  10252|        76|         4| 7/9/1996|      2.0|\n",
      "|  10253|        34|         3|7/10/1996|      2.0|\n",
      "|  10254|        14|         5|7/11/1996|      2.0|\n",
      "|  10255|        68|         9|7/12/1996|      3.0|\n",
      "|  10256|        88|         3|7/15/1996|      2.0|\n",
      "|  10257|        35|         4|7/16/1996|      3.0|\n",
      "|  10258|        20|         1|7/17/1996|      1.0|\n",
      "|  10259|        13|         4|7/18/1996|      3.0|\n",
      "|  10260|        55|         4|7/19/1996|      1.0|\n",
      "|  10261|        61|         4|7/19/1996|      2.0|\n",
      "|  10262|        65|         8|7/22/1996|      3.0|\n",
      "|  10263|        20|         9|7/23/1996|      3.0|\n",
      "|  10264|        24|         6|7/24/1996|      3.0|\n",
      "|  10265|         7|         2|7/25/1996|      1.0|\n",
      "|  10266|        87|         3|7/26/1996|      3.0|\n",
      "|  10267|        25|         4|7/29/1996|      1.0|\n",
      "+-------+----------+----------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OrderID', 'CustomerID', 'EmployeeID', 'OrderDate', 'ShipperID']\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(orders.columns)\n",
    "print(type(orders))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 스파크데이터프레임 통계요약 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+---------+------------------+\n",
      "|summary|          OrderID|        CustomerID|        EmployeeID|OrderDate|         ShipperID|\n",
      "+-------+-----------------+------------------+------------------+---------+------------------+\n",
      "|  count|              196|               196|               196|      196|               196|\n",
      "|   mean|          10345.5| 48.64795918367347|4.3520408163265305|     null|2.0714285714285716|\n",
      "| stddev|56.72448031200168|25.621776513566466|  2.41651283366105|     null|0.7877263614433762|\n",
      "|    min|            10248|                 2|                 1| 1/1/1997|               1.0|\n",
      "|    max|            10443|                91|                 9| 9/9/1996|               3.0|\n",
      "+-------+-----------------+------------------+------------------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+---------+------------------+\n",
      "|summary|          OrderID|        CustomerID|        EmployeeID|OrderDate|         ShipperID|\n",
      "+-------+-----------------+------------------+------------------+---------+------------------+\n",
      "|  count|              196|               196|               196|      196|               196|\n",
      "|   mean|          10345.5| 48.64795918367347|4.3520408163265305|     null|2.0714285714285716|\n",
      "| stddev|56.72448031200168|25.621776513566466|  2.41651283366105|     null|0.7877263614433762|\n",
      "|    min|            10248|                 2|                 1| 1/1/1997|               1.0|\n",
      "|    25%|            10296|                25|                 2|     null|               1.0|\n",
      "|    50%|            10345|                51|                 4|     null|               2.0|\n",
      "|    75%|            10394|                69|                 6|     null|               3.0|\n",
      "|    max|            10443|                91|                 9| 9/9/1996|               3.0|\n",
      "+-------+-----------------+------------------+------------------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 데이터프래임 첫행 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(OrderID=10248, CustomerID=90, EmployeeID=5, OrderDate='7/4/1996', ShipperID=3.0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 스파크데이터프레임에서 임의의 열을 선택하여  출력해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|OrderID|\n",
      "+-------+\n",
      "|  10248|\n",
      "|  10249|\n",
      "|  10250|\n",
      "|  10251|\n",
      "|  10252|\n",
      "|  10253|\n",
      "|  10254|\n",
      "|  10255|\n",
      "|  10256|\n",
      "|  10257|\n",
      "|  10258|\n",
      "|  10259|\n",
      "|  10260|\n",
      "|  10261|\n",
      "|  10262|\n",
      "|  10263|\n",
      "|  10264|\n",
      "|  10265|\n",
      "|  10266|\n",
      "|  10267|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.select('OrderID').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|OrderID|CustomerID|\n",
      "+-------+----------+\n",
      "|  10248|        90|\n",
      "|  10249|        81|\n",
      "|  10250|        34|\n",
      "|  10251|        84|\n",
      "|  10252|        76|\n",
      "|  10253|        34|\n",
      "|  10254|        14|\n",
      "|  10255|        68|\n",
      "|  10256|        88|\n",
      "|  10257|        35|\n",
      "|  10258|        20|\n",
      "|  10259|        13|\n",
      "|  10260|        55|\n",
      "|  10261|        61|\n",
      "|  10262|        65|\n",
      "|  10263|        20|\n",
      "|  10264|        24|\n",
      "|  10265|         7|\n",
      "|  10266|        87|\n",
      "|  10267|        25|\n",
      "+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.select(['OrderID', 'CustomerID']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### withColumn()\n",
    "- 스파크데이터프레임에 새로운 칼럼을 추가하거나, 기존에 존재하는 컬름을 업데이터 하는 경우 사용된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+---------+---------+\n",
      "|OrderID|CustomerID|EmployeeID|OrderDate|ShipperID|\n",
      "+-------+----------+----------+---------+---------+\n",
      "|  10248|        90|         5| 7/4/1996|      3.0|\n",
      "|  10249|        81|         6| 7/5/1996|      1.0|\n",
      "|  10250|        34|         4| 7/8/1996|      2.0|\n",
      "|  10251|        84|         3| 7/8/1996|      1.0|\n",
      "|  10252|        76|         4| 7/9/1996|      2.0|\n",
      "|  10253|        34|         3|7/10/1996|      2.0|\n",
      "|  10254|        14|         5|7/11/1996|      2.0|\n",
      "|  10255|        68|         9|7/12/1996|      3.0|\n",
      "|  10256|        88|         3|7/15/1996|      2.0|\n",
      "|  10257|        35|         4|7/16/1996|      3.0|\n",
      "|  10258|        20|         1|7/17/1996|      1.0|\n",
      "|  10259|        13|         4|7/18/1996|      3.0|\n",
      "|  10260|        55|         4|7/19/1996|      1.0|\n",
      "|  10261|        61|         4|7/19/1996|      2.0|\n",
      "|  10262|        65|         8|7/22/1996|      3.0|\n",
      "|  10263|        20|         9|7/23/1996|      3.0|\n",
      "|  10264|        24|         6|7/24/1996|      3.0|\n",
      "|  10265|         7|         2|7/25/1996|      1.0|\n",
      "|  10266|        87|         3|7/26/1996|      3.0|\n",
      "|  10267|        25|         4|7/29/1996|      1.0|\n",
      "+-------+----------+----------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+---------+---------+----------+\n",
      "|OrderID|CustomerID|EmployeeID|OrderDate|ShipperID|newOrderID|\n",
      "+-------+----------+----------+---------+---------+----------+\n",
      "|  10248|        90|         5| 7/4/1996|      3.0|     10250|\n",
      "|  10249|        81|         6| 7/5/1996|      1.0|     10251|\n",
      "|  10250|        34|         4| 7/8/1996|      2.0|     10252|\n",
      "|  10251|        84|         3| 7/8/1996|      1.0|     10253|\n",
      "|  10252|        76|         4| 7/9/1996|      2.0|     10254|\n",
      "|  10253|        34|         3|7/10/1996|      2.0|     10255|\n",
      "|  10254|        14|         5|7/11/1996|      2.0|     10256|\n",
      "|  10255|        68|         9|7/12/1996|      3.0|     10257|\n",
      "|  10256|        88|         3|7/15/1996|      2.0|     10258|\n",
      "|  10257|        35|         4|7/16/1996|      3.0|     10259|\n",
      "|  10258|        20|         1|7/17/1996|      1.0|     10260|\n",
      "|  10259|        13|         4|7/18/1996|      3.0|     10261|\n",
      "|  10260|        55|         4|7/19/1996|      1.0|     10262|\n",
      "|  10261|        61|         4|7/19/1996|      2.0|     10263|\n",
      "|  10262|        65|         8|7/22/1996|      3.0|     10264|\n",
      "|  10263|        20|         9|7/23/1996|      3.0|     10265|\n",
      "|  10264|        24|         6|7/24/1996|      3.0|     10266|\n",
      "|  10265|         7|         2|7/25/1996|      1.0|     10267|\n",
      "|  10266|        87|         3|7/26/1996|      3.0|     10268|\n",
      "|  10267|        25|         4|7/29/1996|      1.0|     10269|\n",
      "+-------+----------+----------+---------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.withColumn('newOrderID', orders['OrderID']+2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### withColumnRenamed()\n",
    "    - 칼럼의 이름을 수정하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+---------+---------+\n",
      "|OrderID|CustomerID|EmployeeID|OrderDate|ShipperID|\n",
      "+-------+----------+----------+---------+---------+\n",
      "|  10248|        90|         5| 7/4/1996|      3.0|\n",
      "|  10249|        81|         6| 7/5/1996|      1.0|\n",
      "|  10250|        34|         4| 7/8/1996|      2.0|\n",
      "|  10251|        84|         3| 7/8/1996|      1.0|\n",
      "|  10252|        76|         4| 7/9/1996|      2.0|\n",
      "|  10253|        34|         3|7/10/1996|      2.0|\n",
      "|  10254|        14|         5|7/11/1996|      2.0|\n",
      "|  10255|        68|         9|7/12/1996|      3.0|\n",
      "|  10256|        88|         3|7/15/1996|      2.0|\n",
      "|  10257|        35|         4|7/16/1996|      3.0|\n",
      "|  10258|        20|         1|7/17/1996|      1.0|\n",
      "|  10259|        13|         4|7/18/1996|      3.0|\n",
      "|  10260|        55|         4|7/19/1996|      1.0|\n",
      "|  10261|        61|         4|7/19/1996|      2.0|\n",
      "|  10262|        65|         8|7/22/1996|      3.0|\n",
      "|  10263|        20|         9|7/23/1996|      3.0|\n",
      "|  10264|        24|         6|7/24/1996|      3.0|\n",
      "|  10265|         7|         2|7/25/1996|      1.0|\n",
      "|  10266|        87|         3|7/26/1996|      3.0|\n",
      "|  10267|        25|         4|7/29/1996|      1.0|\n",
      "+-------+----------+----------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+----------+---------+---------+\n",
      "|renameOrderID|CustomerID|EmployeeID|OrderDate|ShipperID|\n",
      "+-------------+----------+----------+---------+---------+\n",
      "|        10248|        90|         5| 7/4/1996|      3.0|\n",
      "|        10249|        81|         6| 7/5/1996|      1.0|\n",
      "|        10250|        34|         4| 7/8/1996|      2.0|\n",
      "|        10251|        84|         3| 7/8/1996|      1.0|\n",
      "|        10252|        76|         4| 7/9/1996|      2.0|\n",
      "|        10253|        34|         3|7/10/1996|      2.0|\n",
      "|        10254|        14|         5|7/11/1996|      2.0|\n",
      "|        10255|        68|         9|7/12/1996|      3.0|\n",
      "|        10256|        88|         3|7/15/1996|      2.0|\n",
      "|        10257|        35|         4|7/16/1996|      3.0|\n",
      "|        10258|        20|         1|7/17/1996|      1.0|\n",
      "|        10259|        13|         4|7/18/1996|      3.0|\n",
      "|        10260|        55|         4|7/19/1996|      1.0|\n",
      "|        10261|        61|         4|7/19/1996|      2.0|\n",
      "|        10262|        65|         8|7/22/1996|      3.0|\n",
      "|        10263|        20|         9|7/23/1996|      3.0|\n",
      "|        10264|        24|         6|7/24/1996|      3.0|\n",
      "|        10265|         7|         2|7/25/1996|      1.0|\n",
      "|        10266|        87|         3|7/26/1996|      3.0|\n",
      "|        10267|        25|         4|7/29/1996|      1.0|\n",
      "+-------------+----------+----------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.withColumnRenamed('OrderID', 'renameOrderID').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### groupby()\n",
    "   - SQL과 pandas에서 했던 groupby와 같은 함수이다!\n",
    "   - `CustomerID`를 이용해 그룹을지어 개수를 세어보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|CustomerID|count|\n",
      "+----------+-----+\n",
      "|        31|    1|\n",
      "|        85|    2|\n",
      "|        65|    7|\n",
      "|        34|    2|\n",
      "|        81|    2|\n",
      "|        28|    2|\n",
      "|        76|    2|\n",
      "|        27|    1|\n",
      "|        44|    3|\n",
      "|        91|    1|\n",
      "|        47|    1|\n",
      "|        52|    1|\n",
      "|        13|    1|\n",
      "|        86|    4|\n",
      "|        16|    1|\n",
      "|         3|    1|\n",
      "|        20|   10|\n",
      "|        54|    1|\n",
      "|        48|    2|\n",
      "|         5|    3|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.groupby('CustomerID').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cospi = sqlCtx.read.csv('./실습데이터/cospi.csv',\n",
    "                        header      = True,\n",
    "                        inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: integer (nullable = true)\n",
      " |-- High: integer (nullable = true)\n",
      " |-- Low: integer (nullable = true)\n",
      " |-- Close: integer (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cospi.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+-------+-------+------+\n",
      "|      Date|   Open|   High|    Low|  Close|Volume|\n",
      "+----------+-------+-------+-------+-------+------+\n",
      "|2016-02-26|1180000|1187000|1172000|1172000|176906|\n",
      "|2016-02-25|1172000|1187000|1172000|1179000|128321|\n",
      "|2016-02-24|1178000|1179000|1161000|1172000|140407|\n",
      "|2016-02-23|1179000|1189000|1173000|1181000|147578|\n",
      "|2016-02-22|1190000|1192000|1166000|1175000|174075|\n",
      "|2016-02-19|1187000|1195000|1174000|1190000|175889|\n",
      "|2016-02-18|1203000|1203000|1178000|1187000|211795|\n",
      "|2016-02-17|1179000|1201000|1169000|1185000|245929|\n",
      "|2016-02-16|1158000|1179000|1157000|1168000|179087|\n",
      "|2016-02-15|1154000|1160000|1144000|1154000|182471|\n",
      "|2016-02-12|1130000|1151000|1122000|1130000|254115|\n",
      "|2016-02-11|1118000|1137000|1118000|1130000|304899|\n",
      "|2016-02-05|1156000|1169000|1156000|1164000|183280|\n",
      "|2016-02-04|1150000|1161000|1148000|1156000|236429|\n",
      "|2016-02-03|1150000|1152000|1137000|1146000|174381|\n",
      "|2016-02-02|1161000|1166000|1147000|1156000|165420|\n",
      "|2016-02-01|1152000|1163000|1151000|1163000|258194|\n",
      "|2016-01-29|1140000|1150000|1116000|1150000|426238|\n",
      "|2016-01-28|1164000|1168000|1139000|1145000|314154|\n",
      "|2016-01-27|1126000|1175000|1126000|1175000|273707|\n",
      "+----------+-------+-------+-------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cospi.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### filter(`조건식`)\n",
    "   - 조건식에 만족하는 행을 골라내는 함수이다\n",
    "\n",
    "\n",
    "\n",
    "**날짜가 2월인 데이터만 필터링 한다면?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+-------+-------+------+\n",
      "|      Date|   Open|   High|    Low|  Close|Volume|\n",
      "+----------+-------+-------+-------+-------+------+\n",
      "|2016-02-26|1180000|1187000|1172000|1172000|176906|\n",
      "|2016-02-25|1172000|1187000|1172000|1179000|128321|\n",
      "|2016-02-24|1178000|1179000|1161000|1172000|140407|\n",
      "|2016-02-23|1179000|1189000|1173000|1181000|147578|\n",
      "|2016-02-22|1190000|1192000|1166000|1175000|174075|\n",
      "|2016-02-19|1187000|1195000|1174000|1190000|175889|\n",
      "|2016-02-18|1203000|1203000|1178000|1187000|211795|\n",
      "|2016-02-17|1179000|1201000|1169000|1185000|245929|\n",
      "|2016-02-16|1158000|1179000|1157000|1168000|179087|\n",
      "|2016-02-15|1154000|1160000|1144000|1154000|182471|\n",
      "|2016-02-12|1130000|1151000|1122000|1130000|254115|\n",
      "|2016-02-11|1118000|1137000|1118000|1130000|304899|\n",
      "|2016-02-05|1156000|1169000|1156000|1164000|183280|\n",
      "|2016-02-04|1150000|1161000|1148000|1156000|236429|\n",
      "|2016-02-03|1150000|1152000|1137000|1146000|174381|\n",
      "|2016-02-02|1161000|1166000|1147000|1156000|165420|\n",
      "|2016-02-01|1152000|1163000|1151000|1163000|258194|\n",
      "+----------+-------+-------+-------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cospi.filter(cospi['Date'] >= '2016-02-01').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**종가(close)가 1200000이상인 데이터만 필터링 한다면?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+-------+-------+------+\n",
      "|      Date|   Open|   High|    Low|  Close|Volume|\n",
      "+----------+-------+-------+-------+-------+------+\n",
      "|2016-01-05|1202000|1218000|1186000|1208000|207947|\n",
      "|2016-01-04|1260000|1260000|1205000|1205000|304050|\n",
      "|2015-12-30|1260000|1272000|1254000|1260000|203349|\n",
      "|2015-12-29|1265000|1266000|1241000|1254000|231802|\n",
      "|2015-12-28|1285000|1289000|1266000|1266000|225997|\n",
      "|2015-12-24|1295000|1300000|1285000|1285000|151322|\n",
      "|2015-12-23|1292000|1299000|1282000|1295000|162043|\n",
      "|2015-12-22|1280000|1292000|1267000|1292000|203938|\n",
      "|2015-12-21|1278000|1285000|1261000|1280000|157354|\n",
      "|2015-12-18|1265000|1288000|1264000|1278000|167721|\n",
      "|2015-12-17|1301000|1308000|1275000|1290000|167390|\n",
      "|2015-12-16|1278000|1310000|1278000|1299000|207688|\n",
      "|2015-12-15|1261000|1280000|1260000|1277000|175253|\n",
      "|2015-12-14|1273000|1273000|1255000|1261000|222512|\n",
      "|2015-12-11|1283000|1295000|1272000|1284000|204812|\n",
      "|2015-12-10|1263000|1293000|1263000|1283000|302978|\n",
      "|2015-12-09|1262000|1275000|1262000|1263000|181328|\n",
      "|2015-12-08|1262000|1272000|1262000|1262000|133328|\n",
      "|2015-12-07|1269000|1275000|1262000|1262000|195237|\n",
      "|2015-12-04|1275000|1280000|1267000|1269000|189638|\n",
      "+----------+-------+-------+-------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cospi.filter(cospi['Close'] >= 1200000).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 종가(Close)가 1200000이상 1250000이하인 경우를 필터링하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+-------+-------+------+\n",
      "|      Date|   Open|   High|    Low|  Close|Volume|\n",
      "+----------+-------+-------+-------+-------+------+\n",
      "|2016-01-05|1202000|1218000|1186000|1208000|207947|\n",
      "|2016-01-04|1260000|1260000|1205000|1205000|304050|\n",
      "|2015-07-30|1258000|1260000|1215000|1215000|307189|\n",
      "|2015-07-28|1224000|1251000|1219000|1230000|252036|\n",
      "|2015-07-27|1229000|1247000|1228000|1230000|198204|\n",
      "|2015-07-24|1227000|1238000|1224000|1229000|194869|\n",
      "|2015-07-23|1244000|1253000|1234000|1234000|198639|\n",
      "|2015-07-15|1225000|1238000|1224000|1235000|166863|\n",
      "|2015-07-14|1265000|1270000|1221000|1225000|367936|\n",
      "|2015-07-08|1240000|1251000|1232000|1239000|215303|\n",
      "|2015-07-07|1220000|1259000|1220000|1240000|236882|\n",
      "|2015-07-06|1253000|1260000|1223000|1230000|195947|\n",
      "+----------+-------+-------+-------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cospi.filter( (cospi['Close'] >= 1200000) & (cospi['Close'] <= 1250000) ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Volume이 300000이하인 경우를 필터링하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+-------+-------+------+\n",
      "|      Date|   Open|   High|    Low|  Close|Volume|\n",
      "+----------+-------+-------+-------+-------+------+\n",
      "|2016-02-26|1180000|1187000|1172000|1172000|176906|\n",
      "|2016-02-25|1172000|1187000|1172000|1179000|128321|\n",
      "|2016-02-24|1178000|1179000|1161000|1172000|140407|\n",
      "|2016-02-23|1179000|1189000|1173000|1181000|147578|\n",
      "|2016-02-22|1190000|1192000|1166000|1175000|174075|\n",
      "|2016-02-19|1187000|1195000|1174000|1190000|175889|\n",
      "|2016-02-18|1203000|1203000|1178000|1187000|211795|\n",
      "|2016-02-17|1179000|1201000|1169000|1185000|245929|\n",
      "|2016-02-16|1158000|1179000|1157000|1168000|179087|\n",
      "|2016-02-15|1154000|1160000|1144000|1154000|182471|\n",
      "|2016-02-12|1130000|1151000|1122000|1130000|254115|\n",
      "|2016-02-05|1156000|1169000|1156000|1164000|183280|\n",
      "|2016-02-04|1150000|1161000|1148000|1156000|236429|\n",
      "|2016-02-03|1150000|1152000|1137000|1146000|174381|\n",
      "|2016-02-02|1161000|1166000|1147000|1156000|165420|\n",
      "|2016-02-01|1152000|1163000|1151000|1163000|258194|\n",
      "|2016-01-27|1126000|1175000|1126000|1175000|273707|\n",
      "|2016-01-26|1155000|1157000|1136000|1137000|151638|\n",
      "|2016-01-25|1172000|1176000|1156000|1162000|159769|\n",
      "|2016-01-22|1145000|1168000|1145000|1168000|146591|\n",
      "+----------+-------+-------+-------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cospi.filter( cospi['Volume'] <= 300000 ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 날짜가 2월 26일인 경우를 필터링하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+-------+-------+------+\n",
      "|      Date|   Open|   High|    Low|  Close|Volume|\n",
      "+----------+-------+-------+-------+-------+------+\n",
      "|2016-02-26|1180000|1187000|1172000|1172000|176906|\n",
      "+----------+-------+-------+-------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cospi.filter( cospi['Date'] == '2016-02-26' ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Titanic 데이셋을 이용한 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = sqlCtx.read.csv('./실습데이터/titanic_train.csv',\n",
    "                          header     = True,\n",
    "                         inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[PassengerId: int, Survived: int, Pclass: int, Name: string, Sex: string, Age: double, SibSp: int, Parch: int, Ticket: string, Fare: double, Cabin: string, Embarked: string]>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### titanic 스파크 데이터프레임에서 PassengerId와 Name 칼럼을 선택하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|PassengerId|                Name|\n",
      "+-----------+--------------------+\n",
      "|          1|Braund, Mr. Owen ...|\n",
      "|          2|Cumings, Mrs. Joh...|\n",
      "|          3|Heikkinen, Miss. ...|\n",
      "|          4|Futrelle, Mrs. Ja...|\n",
      "|          5|Allen, Mr. Willia...|\n",
      "|          6|    Moran, Mr. James|\n",
      "|          7|McCarthy, Mr. Tim...|\n",
      "|          8|Palsson, Master. ...|\n",
      "|          9|Johnson, Mrs. Osc...|\n",
      "|         10|Nasser, Mrs. Nich...|\n",
      "|         11|Sandstrom, Miss. ...|\n",
      "|         12|Bonnell, Miss. El...|\n",
      "|         13|Saundercock, Mr. ...|\n",
      "|         14|Andersson, Mr. An...|\n",
      "|         15|Vestrom, Miss. Hu...|\n",
      "|         16|Hewlett, Mrs. (Ma...|\n",
      "|         17|Rice, Master. Eugene|\n",
      "|         18|Williams, Mr. Cha...|\n",
      "|         19|Vander Planke, Mr...|\n",
      "|         20|Masselmani, Mrs. ...|\n",
      "+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic.select(['PassengerId', 'Name']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 성별이 여성인 PassengerId, Name, Sex, Survived 칼럼만 선택하여 출력하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+------+--------+\n",
      "|PassengerId|                Name|   Sex|Survived|\n",
      "+-----------+--------------------+------+--------+\n",
      "|          2|Cumings, Mrs. Joh...|female|       1|\n",
      "|          3|Heikkinen, Miss. ...|female|       1|\n",
      "|          4|Futrelle, Mrs. Ja...|female|       1|\n",
      "|          9|Johnson, Mrs. Osc...|female|       1|\n",
      "|         10|Nasser, Mrs. Nich...|female|       1|\n",
      "|         11|Sandstrom, Miss. ...|female|       1|\n",
      "|         12|Bonnell, Miss. El...|female|       1|\n",
      "|         15|Vestrom, Miss. Hu...|female|       0|\n",
      "|         16|Hewlett, Mrs. (Ma...|female|       1|\n",
      "|         19|Vander Planke, Mr...|female|       0|\n",
      "|         20|Masselmani, Mrs. ...|female|       1|\n",
      "|         23|\"McGowan, Miss. A...|female|       1|\n",
      "|         25|Palsson, Miss. To...|female|       0|\n",
      "|         26|Asplund, Mrs. Car...|female|       1|\n",
      "|         29|\"O'Dwyer, Miss. E...|female|       1|\n",
      "|         32|Spencer, Mrs. Wil...|female|       1|\n",
      "|         33|Glynn, Miss. Mary...|female|       1|\n",
      "|         39|Vander Planke, Mi...|female|       0|\n",
      "|         40|Nicola-Yarred, Mi...|female|       1|\n",
      "|         41|Ahlin, Mrs. Johan...|female|       0|\n",
      "+-----------+--------------------+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic.filter(titanic['Sex'] == 'female').select(['PassengerId', 'Name', 'Sex', 'Survived']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 여성 중에서 살아있는 사람의 행만 출력해보라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+--------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|    Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+--------+-----+--------+\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599| 71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|   7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|    53.1| C123|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742| 11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736| 30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|    16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|   26.55| C103|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|    16.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|   7.225| null|       C|\n",
      "|         23|       1|     3|\"McGowan, Miss. A...|female|15.0|    0|    0|          330923|  8.0292| null|       Q|\n",
      "|         26|       1|     3|Asplund, Mrs. Car...|female|38.0|    1|    5|          347077| 31.3875| null|       S|\n",
      "|         29|       1|     3|\"O'Dwyer, Miss. E...|female|null|    0|    0|          330959|  7.8792| null|       Q|\n",
      "|         32|       1|     1|Spencer, Mrs. Wil...|female|null|    1|    0|        PC 17569|146.5208|  B78|       C|\n",
      "|         33|       1|     3|Glynn, Miss. Mary...|female|null|    0|    0|          335677|    7.75| null|       Q|\n",
      "|         40|       1|     3|Nicola-Yarred, Mi...|female|14.0|    1|    0|            2651| 11.2417| null|       C|\n",
      "|         44|       1|     2|Laroche, Miss. Si...|female| 3.0|    1|    2|   SC/Paris 2123| 41.5792| null|       C|\n",
      "|         45|       1|     3|Devaney, Miss. Ma...|female|19.0|    0|    0|          330958|  7.8792| null|       Q|\n",
      "|         48|       1|     3|O'Driscoll, Miss....|female|null|    0|    0|           14311|    7.75| null|       Q|\n",
      "|         53|       1|     1|Harper, Mrs. Henr...|female|49.0|    1|    0|        PC 17572| 76.7292|  D33|       C|\n",
      "|         54|       1|     2|Faunthorpe, Mrs. ...|female|29.0|    1|    0|            2926|    26.0| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+--------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic.filter( (titanic['Sex'] == 'female') & (titanic['Survived'] == 1) ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 선실등급(Pclass) 별  요금평균을 확인한다면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|Pclass|         avg(Fare)|\n",
      "+------+------------------+\n",
      "|     1| 84.15468749999992|\n",
      "|     3|13.675550101832997|\n",
      "|     2| 20.66218315217391|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic.groupby('Pclass').agg({'Fare' : 'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------------------+\n",
      "|Pclass|avg(Pclass)|         avg(Fare)|\n",
      "+------+-----------+------------------+\n",
      "|     1|        1.0| 84.15468749999992|\n",
      "|     3|        3.0|13.675550101832997|\n",
      "|     2|        2.0| 20.66218315217391|\n",
      "+------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic[['Pclass', 'Fare']].groupby('Pclass').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------------------+\n",
      "|Pclass|avg(Pclass)|         avg(Fare)|\n",
      "+------+-----------+------------------+\n",
      "|     1|        1.0| 84.15468749999992|\n",
      "|     3|        3.0|13.675550101832997|\n",
      "|     2|        2.0| 20.66218315217391|\n",
      "+------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic.select(['Pclass', 'Fare']).groupby('Pclass').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.createOrReplaceTempView('titanicView')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spark데이터프레임 + SQL구문 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = {'PassengerId':{0:1, 1:2, 2:3, 3:4, 4:5},\n",
    "         'Name' : {0:'Owen', 1:'Florence', 2:'Laina', 3:'Lily', 4:\"William\"},\n",
    "         'sex' : {0: 'male', 1: 'female', 2:'female', 3:'female', 4:'male'},\n",
    "         'Survived': {0:0, 1:1, 2:1, 3:1, 4:0}\n",
    "        }\n",
    "\n",
    "data2 = {'PassengerId':{0:1, 1:2, 2:3, 3:4, 4:5},\n",
    "         'Age' : {0: 22, 1: 38, 2: 33, 3: 35, 4: 35},\n",
    "         'Fare' : {0: 7.3, 1: 71.3, 2:7.9, 3:53.1, 4:8.0},\n",
    "         'Pclass': {0:3, 1:1, 2:3, 3:1, 4:3}\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['PassengerId', 'Name', 'sex', 'Survived'])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df01 = pd.DataFrame(data1)\n",
    "sample_df02 = pd.DataFrame(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Name</th>\n",
       "      <th>sex</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Owen</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Florence</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Lily</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>William</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId      Name     sex  Survived\n",
       "0            1      Owen    male         0\n",
       "1            2  Florence  female         1\n",
       "2            3     Laina  female         1\n",
       "3            4      Lily  female         1\n",
       "4            5   William    male         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>7.3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>71.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>53.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Age  Fare  Pclass\n",
       "0            1   22   7.3       3\n",
       "1            2   38  71.3       1\n",
       "2            3   33   7.9       3\n",
       "3            4   35  53.1       1\n",
       "4            5   35   8.0       3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sample_df01)\n",
    "display(sample_df02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df01 = sqlCtx.createDataFrame(sample_df01)\n",
    "spark_df02 = sqlCtx.createDataFrame(sample_df02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(sample_df01))\n",
    "print(type(spark_df01))\n",
    "print(type(sample_df02))\n",
    "print(type(spark_df02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df01.createOrReplaceTempView('titanic01')\n",
    "spark_df02.createOrReplaceTempView('titanic02')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spark SQL SELECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------+\n",
      "|PassengerId|    Name|   sex|Survived|\n",
      "+-----------+--------+------+--------+\n",
      "|          1|    Owen|  male|       0|\n",
      "|          2|Florence|female|       1|\n",
      "|          3|   Laina|female|       1|\n",
      "|          4|    Lily|female|       1|\n",
      "|          5| William|  male|       0|\n",
      "+-----------+--------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlCtx.sql('select * from titanic01').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sql 구문을 이용하여 성별에 따른 승객 수를 구해본다면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|   sex|cnt|\n",
      "+------+---+\n",
      "|female|  3|\n",
      "|  male|  2|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    SELECT      sex, COUNT(Survived) AS cnt\n",
    "    FROM        titanic01\n",
    "    GROUP BY    sex\n",
    "\"\"\"\n",
    "\n",
    "sqlCtx.sql(sql).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sql구문을 이용하여 `titanic01`테이블과 `titanic02`테이블을 `PassengerId`를 기준으로 조인하고\n",
    "##### 선실등급(Pclass)과 성별(sex)에 따른 요금의 평균을 구하여라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---------+\n",
      "|Pclass|   sex|avg(Fare)|\n",
      "+------+------+---------+\n",
      "|     3|female|      7.9|\n",
      "|     3|  male|     7.65|\n",
      "|     1|female|     62.2|\n",
      "+------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "join = \"\"\"\n",
    "    SELECT       Pclass, sex, AVG(Fare)\n",
    "    FROM         titanic01\n",
    "    LEFT JOIN    titanic02   USING(PassengerId)\n",
    "    GROUP BY     Pclass, sex\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "sqlCtx.sql(join).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
