

## 1. 모델정보

```python
model = Sequential()
model.add(Embedding(vocab_size+1, embedding_dim, input_length=comment_len))
model.add(Bidirectional(LSTM(128, return_sequences=True)))
model.add(Bidirectional(LSTM(64, return_sequences=False)))
model.add(Dense(1, activation='sigmoid'))


model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])
```

```python
# 성능의 변화가 없을때 멈추는 기능
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)

# 지금까지 가장 좋은 성능이 나왔을때, 노드의 가중치를 저장하는 함수
mc = ModelCheckpoint('erase_label_1.h5', monitor= 'val_loss', mode='min', save_best_only=True)
```

```python
history = model.fit(train_over, y_train_over, 
                    callbacks        = [es, mc],
                    epochs           = 10, 
                    batch_size       = 512, 
                    validation_data  = [test, y_test])
```



## 2. 학습결과

```powershell
Epoch 1/10
181/181 [==============================] - 2676s 15s/step - loss: 0.4312 - acc: 0.7979 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00
Epoch 2/10
181/181 [==============================] - 2641s 15s/step - loss: 0.3074 - acc: 0.8742 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00
Epoch 3/10
181/181 [==============================] - 2622s 14s/step - loss: 0.2667 - acc: 0.8936 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00
Epoch 4/10
181/181 [==============================] - 2647s 15s/step - loss: 0.2236 - acc: 0.9133 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00
Epoch 5/10
181/181 [==============================] - 2643s 15s/step - loss: 0.1988 - acc: 0.9229 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00
Epoch 00005: early stopping
```

```python
recall :  0.20097161851188955
precision :  0.6447908121410992
f1_score :  0.3064327485380117
roc_auc_score :  0.7377006468581259
```



##### confusion Matrix (Threshold = 0.5)

```powershell
array([[10537,   660],
       [ 1031,   559]])
```

