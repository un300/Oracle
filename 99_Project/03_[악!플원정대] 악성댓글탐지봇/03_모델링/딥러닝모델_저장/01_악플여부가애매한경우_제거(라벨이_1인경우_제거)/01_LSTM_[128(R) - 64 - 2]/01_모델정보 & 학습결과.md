## 1. 모델정보

```python
model = Sequential()
model.add(Embedding(vocab_size+1, embedding_dim, input_length=comment_len))
model.add(Bidirectional(LSTM(128, return_sequences=True)))
model.add(Bidirectional(LSTM(64, return_sequences=False)))
model.add(Dense(2, activation='sigmoid'))


model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])

```

```python
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)
mc = ModelCheckpoint('erase_label_1.h5', monitor= 'val_acc', mode='max', save_best_only=True)
```

```python
history = model.fit(train_over, y_train_over, 
                    callbacks        = [es, mc],
                    epochs           = 5, 
                    batch_size       = 512, 
                    validation_data  = [test, y_test])
```

## 2. 학습결과

```powershell
Epoch 1/5
181/181 [==============================] - 2619s 14s/step - loss: 0.5117 - acc: 0.7425 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00
Epoch 2/5
181/181 [==============================] - 2557s 14s/step - loss: 0.3520 - acc: 0.8475 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00
Epoch 3/5
181/181 [==============================] - 2551s 14s/step - loss: 0.2675 - acc: 0.8915 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00
Epoch 4/5
181/181 [==============================] - 2549s 14s/step - loss: 0.2167 - acc: 0.9152 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00
Epoch 5/5
181/181 [==============================] - 2546s 14s/step - loss: 0.1850 - acc: 0.9284 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00
Epoch 00005: early stopping
```



##### Confusion Matrix

```powershell
array([[9196,  486],
       [2372,  733]])
```

