## 1. 모델구조

LSTM128(R) - LSTM128 - 5

```python
def get_model():
    model = Sequential()
    model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))
    model.add(Bidirectional(LSTM(128, return_sequences=True)))
    model.add(Bidirectional(LSTM(128, return_sequences=False)))
    model.add(Dense(n_class, activation = 'softmax'))

    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])

    return model
```

```python
history = LSTM.fit(x_train, y,
                   callbacks        = [es, mc],
                   epochs           = 15,
                   batch_size       = 64,
                   validation_split = 0.3)
                  
```





## 2. 모델 학습과정

```powershell
Epoch 1/15
601/601 [==============================] - 3558s 6s/step - loss: 1.0349 - accuracy: 0.5843 - val_loss: 0.7906 - val_accuracy: 0.7041
Epoch 2/15
601/601 [==============================] - 3596s 6s/step - loss: 0.5950 - accuracy: 0.7820 - val_loss: 0.7266 - val_accuracy: 0.7309
Epoch 3/15
601/601 [==============================] - 3581s 6s/step - loss: 0.4322 - accuracy: 0.8433 - val_loss: 0.7605 - val_accuracy: 0.7271
Epoch 4/15
601/601 [==============================] - 3630s 6s/step - loss: 0.3447 - accuracy: 0.8772 - val_loss: 0.8614 - val_accuracy: 0.7187
Epoch 5/15
601/601 [==============================] - 3573s 6s/step - loss: 0.3025 - accuracy: 0.8924 - val_loss: 0.9328 - val_accuracy: 0.7198
Epoch 6/15
601/601 [==============================] - 3606s 6s/step - loss: 0.2551 - accuracy: 0.9078 - val_loss: 0.9557 - val_accuracy: 0.7173
Epoch 00006: early stopping
```

