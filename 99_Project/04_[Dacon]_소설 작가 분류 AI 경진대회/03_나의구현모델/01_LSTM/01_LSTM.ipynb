{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01_LSTM","private_outputs":true,"provenance":[],"collapsed_sections":[],"mount_file_id":"1bEB3v_HX5mTTj5IXsHJ6Hy23-6_i_9ZV","authorship_tag":"ABX9TyMMJHIDk9IGVTn3j1HYy810"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"cphd3sYA-6nn"},"source":["import warnings \n","warnings.filterwarnings(action='ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p8MY65sF_BXr"},"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import re\n","import os\n","\n","from matplotlib import rcParams, pyplot as plt\n","from pathlib import Path\n","from sklearn.metrics import accuracy_score, log_loss\n","from sklearn.model_selection import StratifiedKFold\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, LSTM, GlobalMaxPooling1D, Conv1D, Dropout, Bidirectional\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","from tensorflow.keras.utils import plot_model, to_categorical\n","from tensorflow.keras.optimizers import Adam"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hOaprRqu0mVy"},"source":["## 1. 데이터불러오기"]},{"cell_type":"code","metadata":{"id":"nnj2Hivj_BVS"},"source":["# 데이터 불러오기\n","\n","raw_train = pd.read_csv('/content/drive/MyDrive/[데이콘] 소설 작가 분류 AI 경진대회/data/train.csv')\n","raw_test = pd.read_csv('/content/drive/MyDrive/[데이콘] 소설 작가 분류 AI 경진대회/data/test_x.csv')\n","sample_submission = pd.read_csv('/content/drive/MyDrive/[데이콘] 소설 작가 분류 AI 경진대회/data/sample_submission.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ingTeaIk_BTR"},"source":["train = raw_train.copy()\n","test = raw_test.copy()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5YLhf2nh0o0w"},"source":["## 2. 텍스트전처리(토큰화 + 패딩화)"]},{"cell_type":"code","metadata":{"id":"o_57vEP7_BRO"},"source":["def alpha_num(text):\n","    return re.sub(r'[^A-Za-z0-9 ]', '', text)\n","\n","\n","def remove_stopwords(text):\n","    final_text = []\n","    for i in text.split():\n","        if i.strip().lower() not in stopwords:\n","            final_text.append(i.strip())\n","    return \" \".join(final_text)\n","\n","\n","stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \n","             \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \n","             \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \n","             \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \n","             \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \n","             \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \n","             \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \n","             \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \n","             \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \n","             \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \n","             \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ss7e8Rb8_BO2"},"source":["train['text'] = train['text'].str.lower().apply(alpha_num).apply(remove_stopwords)\n","test['text'] = test['text'].str.lower().apply(alpha_num).apply(remove_stopwords)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PbsF4kht_BMm"},"source":["X_train = train['text'].values\n","X_test = test['text'].values\n","y = train['author'].values.reshape(-1, 1)\n","print(X_train.shape, X_test.shape, y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"it4-xAzGEAUc"},"source":["vocab_size = 20000\n","padding_type='post'\n","max_length = 500"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_7Fuy9dY_BH0"},"source":["tokenizer = Tokenizer(num_words = vocab_size)\n","tokenizer.fit_on_texts(X_train)\n","word_index = tokenizer.word_index\n","\n","train_sequences = tokenizer.texts_to_sequences(X_train)\n","test_sequences = tokenizer.texts_to_sequences(X_test)\n","\n","x_train = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length)\n","x_test = pad_sequences(test_sequences, padding=padding_type, maxlen=max_length)\n","print(x_train.shape, x_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"srIqi-DB0uP4"},"source":["## 3. LSTM 모델 학습\n","\n"]},{"cell_type":"code","metadata":{"id":"Tj5BuqxH_BCc"},"source":["target_col = 'author'\n","n_class = 5\n","seed = 42\n","embedding_dim = 128"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P6aX5yHn_pjC"},"source":["def get_model():\n","    model = Sequential()\n","    model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n","    model.add(Bidirectional(LSTM(128, return_sequences=True)))\n","    model.add(Bidirectional(LSTM(64, return_sequences=False)))\n","    model.add(Dense(n_class, activation = 'softmax'))\n","\n","    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0JN24Ik5CCB9"},"source":["es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n","mc = ModelCheckpoint('LSTM_best.h5', monitor='val_loss', mode='min', save_best_only=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QgmzTaK8DN97"},"source":["LSTM = get_model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GvtQjOo8_A-m"},"source":["history = LSTM.fit(x_train, y,\n","                   callbacks        = [es, mc],\n","                   epochs           = 10,\n","                   batch_size       = 128,\n","                   validation_split = 0.3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XQTQPhfx0xMP"},"source":["## 4. Test set 예측 및 제출결과저장"]},{"cell_type":"code","metadata":{"id":"fe809EEh_A8G"},"source":["loaded_model = load_model('LSTM_best.h5')\n","y_pred = loaded_model.predict(x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JrWIqvan_A55"},"source":["sample_submission[['0','1','2','3','4']] = y_pred\n","sample_submission.to_csv('/content/drive/MyDrive/[데이콘] 소설 작가 분류 AI 경진대회/02_나의코드/01_LSTM/Test예측결과/submission.csv', index = False, encoding = 'utf-8')"],"execution_count":null,"outputs":[]}]}