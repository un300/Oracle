## 1. 모델구조

LSTM128(R) - LSTM64 - 5

```python
def get_model():
    model = Sequential()
    model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))
    model.add(Bidirectional(LSTM(128, return_sequences=True)))
    model.add(Bidirectional(LSTM(64, return_sequences=False)))
    model.add(Dense(n_class, activation = 'softmax'))

    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])

    return model
```

```python
history = LSTM.fit(x_train, y,
                   callbacks        = [es, mc],
                   epochs           = 10,
                   batch_size       = 128,
                   validation_split = 0.3)
                  
```





## 2. 모델 학습과정

```powershell
Epoch 1/10
301/301 [==============================] - 2024s 7s/step - loss: 1.0493 - accuracy: 0.5766 - val_loss: 0.7658 - val_accuracy: 0.7133
Epoch 2/10
301/301 [==============================] - 1966s 7s/step - loss: 0.5815 - accuracy: 0.7898 - val_loss: 0.7255 - val_accuracy: 0.7397
Epoch 3/10
301/301 [==============================] - 1957s 7s/step - loss: 0.4265 - accuracy: 0.8464 - val_loss: 0.7777 - val_accuracy: 0.7332
Epoch 4/10
301/301 [==============================] - 1956s 6s/step - loss: 0.3497 - accuracy: 0.8742 - val_loss: 0.8343 - val_accuracy: 0.7265
Epoch 5/10
301/301 [==============================] - 1952s 6s/step - loss: 0.3001 - accuracy: 0.8938 - val_loss: 0.8922 - val_accuracy: 0.7249
Epoch 6/10
301/301 [==============================] - 1965s 7s/step - loss: 0.2581 - accuracy: 0.9086 - val_loss: 0.9469 - val_accuracy: 0.7218
Epoch 00006: early stopping
```

