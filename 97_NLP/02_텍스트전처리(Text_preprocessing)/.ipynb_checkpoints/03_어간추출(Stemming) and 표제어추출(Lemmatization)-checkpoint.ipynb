{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2020-10-25 일요일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 표제어추출(Lemmatization) and 어간추출(Stemming)\n",
    "   - 이번 챕터는 정규화 기법 중 코퍼스에 있는 단어의 개수를 줄일 수 있는 방법을 배울 것이다\n",
    "   - 그 중 `어간추출(Stemming)`과 `표제어추출(Lemmatizaion)`에 대해 알아보자\n",
    "   - 이 두작업의 의미는 눈으로 봤을땐, 서로 다른 단어이지만, 하나의 단어로 일반화할 수 있는 단어라면 일반화하여 단어의 수를 줄이겠다는 것이다.\n",
    "   - 이러한 방법들은 단어의 빈도수를 기반으로 문제를 풀고자하는 `Bag of Words(BoW)`표현을 사용하는 자연어 처리 문제에서 주로 사용된다.(`BoW`표현은 4장에서 다룬다.)\n",
    "   - 자연어에서 전처리가 가지는 지향점은 가지고있는 코퍼스(말뭉치, 텍스트데이터)로 부터 복잡성을 줄이는 것이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 목차\n",
    "\n",
    "#### 3-1 표제어 추출(Lemmatization)\n",
    "\n",
    "#### 3-2 어간추출(Stemming)\n",
    "\n",
    "#### 3-3 한국어에서의 어간추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1 표제어 추출(Lemmatization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - 표제어(Lemma) 추출은 단어들로부터 표제어를 찾아가는 과정이다.\n",
    "   - 비슷한 의미의 단어를 일반화 하는 과정이라고 생각하면 된다.\n",
    "   - 예를들어 `am`, `are`, `is`등의 단어는 `be`로 일반화 하는것과 같다\n",
    "   \n",
    "   \n",
    "   - 표제어를 추출하는 가장 섬세한 방법은 단어의 형태학적 파싱을 먼저 진행하는 것이다\n",
    "   - 형태학이란 '의미를 가진 가장 작은 단위'를 뜻하는 형태소로 부터 단어들을 만들어가는 학문을 뜻한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 어간(stem)\n",
    "   - 단어의 의미를 담고 있는 단어의 핵심부분\n",
    "   \n",
    "   \n",
    "   \n",
    "### (2) 접사(affix)\n",
    "   - 단어의 추가적인 의미를 주는 부분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 형태학적 파싱은 이 두 가지 구성 요소를 분리하는 작업을 말한다.\n",
    "   - 예를들어 `cats`라는 단어에 형태학적 파싱을 수행한다면, 결과로 `cat(어간)` + `-s(접사)`로 분리된다.\n",
    "   - `NLTK`에서 표제어 추출을 위한 도구인 `WordNetLemmatizer`를 지원한다. 이것을 통해 표제어추출을 실습해보도록 하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lan41\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "n = WordNetLemmatizer()\n",
    "print([n.lemmatize(w) for w in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - `WordNetLemmatizer`는 **표제어추출**을 위한 도구이다. 잠시후 배우게 될 **어간추출(Stemming)**과는 다르게 표제어추출은 단어의 형태가 적절히 보존됨을 볼 수 있다.\n",
    " - 하지만, 위 결과에서 `dy`나 `ha`와 같은 의미를 알 수 없는 단어들을 출력하고 있다.\n",
    " - 왜냐하면 **표제어추출기(Lemmatizer)**는 **본래 단어의 품사 정보를 알아야만** 정확한 결과를 얻을 수 있기 떄문이다\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### 그렇다면 위 `WordNetLemmatizer`의 결과에서 본래 의미가 회손된 단어인 `dy`와 `has`를 동사라는 품사를 명시하여 다시 입력해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['dies', 'has']\n",
    "n = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dies\n",
      "품사를 지정해 주었을때 : die\n",
      "품사를 지정해 주지 않았을때 : dy\n",
      "\n",
      "has\n",
      "품사를 지정해 주었을때 : have\n",
      "품사를 지정해 주지 않았을때 : ha\n"
     ]
    }
   ],
   "source": [
    "print('dies')\n",
    "print('품사를 지정해 주었을때 :', n.lemmatize(words[0], 'v'))\n",
    "print('품사를 지정해 주지 않았을때 :', n.lemmatize(words[0]))\n",
    "print()\n",
    "print('has')\n",
    "print('품사를 지정해 주었을때 :', n.lemmatize(words[1], 'v'))\n",
    "print('품사를 지정해 주지 않았을때 :', n.lemmatize(words[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 어간 추출을 들어가기 전에!!..\n",
    "   - 어간 추출에 대해 본격적으로 언급하기 전에 **표제어추출**과 **어간추출**의 차이점에 대하여 미리 언급하고자 한다.\n",
    "   1. **표제어추출**은..\n",
    "       - 문맥을 고려한다.\n",
    "       - 수행 결과는 **품사정보**룰 보존한다. (PDS태그를 보존한다고 할 수 있다.)\n",
    "   2. **어간추출**은..\n",
    "       - **품사정보**가 보존되지 않는다. (POS태그를 보존하지 않는다.)\n",
    "       - 다시말해 **어간추출**의 결과는 사전에 존재하지 않는 단어일 경우가 많다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2 어간추출(Stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - 어간(Stem)을 추출하는 작업을 어간추출(Stemming)이라고 한다.\n",
    "   - 어간 추출은 어떻게 보면 **형태학적 분석**을 단순화한 버전이라고 볼 수 있다.\n",
    "   - 또한, 정해진 규칙만 보고 단어의 어미를 자르는 어림짐작의 작업이라고 볼 수도 있다.\n",
    "   - 다시말해 이 작업은 섬세한 작업이 아니기에, **어간 추출 후에 나오는 결과는 사전에 존재하지 않는 단어일 가능성이 매우 크다.**\n",
    "   \n",
    "   \n",
    "##### 설명이 매우 어려울 수도 있는데, 예제를 보면 쉽게 이해가 될 것이다.\n",
    "##### 어간추출 알고리즘 하나인 `포터알고리즘(Poter Algorithm)`로 실습해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', 'Bones', \"'s\", 'chest', ',', 'but', 'an', 'accurate', 'copy', ',', 'complete', 'in', 'all', 'things', '--', 'names', 'and', 'heights', 'and', 'soundings', '--', 'with', 'the', 'single', 'exception', 'of', 'the', 'red', 'crosses', 'and', 'the', 'written', 'notes', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer   ## 어간 추출 알고리즘인 포터알고리즘\n",
    "from nltk.tokenize import word_tokenize  ## 단어 토큰화를 위해\n",
    "s = PorterStemmer()\n",
    "\n",
    "# 'text'를 단어로 토큰화 한다,\n",
    "words = word_tokenize(text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'billi', 'bone', \"'s\", 'chest', ',', 'but', 'an', 'accur', 'copi', ',', 'complet', 'in', 'all', 'thing', '--', 'name', 'and', 'height', 'and', 'sound', '--', 'with', 'the', 'singl', 'except', 'of', 'the', 'red', 'cross', 'and', 'the', 'written', 'note', '.']\n"
     ]
    }
   ],
   "source": [
    "# 토큰화된 단어들로부터 어간추출을 시행한다.\n",
    "print( [s.stem(w) for w in words] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 위 결과에서는 사전에 없는 단어들도 포함되어 있다.\n",
    " - **어간추출**은 단순 규칙에 기반하여 이루어지기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['formal', 'allow', 'electric']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "s = PorterStemmer()\n",
    "\n",
    "words=['formalize', 'allowance', 'electricical']\n",
    "print([s.stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **어간추출**의 속도는 **표제어추출**보다 일반적으로 빠르다.\n",
    " - **어간추출** 중, **포터 어간 추출기**는 정말하게 설계가 되어있어, 엉어 자연어 처리를 한다면 **포터어간추출기**는 준수한 선택이 아닐 수 없다.\n",
    " - `NLTK`는 포터알고리즘 외에도 **랭커스터 스태머(Lancaster Stemmer)** 알고리즘을 지원하고 있다.\n",
    " - 이번에는 **포터 알고리즘**과 **랭커스터 스태머 알고리즘**으로 각각 **어간추출**을 진행하였을때, 둘의 결과를 비교해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화된 단어들을 임의로 넣어보자\n",
    "\n",
    "words=['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "포터알고리즘에의한 어간추출\n",
      "['polici', 'do', 'organ', 'have', 'go', 'love', 'live', 'fli', 'die', 'watch', 'ha', 'start']\n",
      "\n",
      "랭커스터알고리즘에의한 어간추출\n",
      "['policy', 'doing', 'org', 'hav', 'going', 'lov', 'liv', 'fly', 'die', 'watch', 'has', 'start']\n"
     ]
    }
   ],
   "source": [
    "# 포터알고리즘\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "print('포터알고리즘에의한 어간추출')\n",
    "print( [ porter.stem(word) for word in words] )\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# 랭커스터 스탬 알고리즘\n",
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "print('랭커스터알고리즘에의한 어간추출')\n",
    "lancaster = LancasterStemmer()\n",
    "print( [lancaster.stem(w) for w in words] ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 위 두 어간추출기의 결과는 서로 다르다!\n",
    "   - **포터 알고리즘**과 **랭커스터 알고리즘**은 서로 다른 알고리즘을 사용하기 때문에, 결과가 다르다.\n",
    "   - 그렇기 때문에, 자신이 사용하고자 하는 방향에따라서 적절한 알고리즘을 선택하여야 한다.\n",
    "   \n",
    "   \n",
    "##### 위 결괴에서 `organization`의 결과를 보자\n",
    "   - **포터 알고리즘의 경우**\n",
    "       `organization` > `organ`\n",
    "   - **랭커스터 알고리즘의 경우**\n",
    "       `organization` > `org`\n",
    "       \n",
    "    **이 처럼 알고리즘마다 결과가 다르기 때문에 적절히 자신이 하고자하는 방향에 따라 어간추출기를 선택하자**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 마지막으로..\n",
    "##### 표제어추출 vs 어간추출 \n",
    "   - **표제어추출(Lemmatization)**\n",
    "        - `am`          >   `be`\n",
    "        - `the going`   >   `the going`\n",
    "        - `having`      >   `have`\n",
    "        \n",
    "        \n",
    "   - **어간추출(Stemming)**\n",
    "       - `am`           >   `am`\n",
    "       - `the going`    >   `the go`\n",
    "       - `having`       >   `hav`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3 한국어에서의 어간추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - 한국어에서 어간추출은 따로 실습하지 않을 것이지만, 한국어의 어간에 대해서 간략히 설명한다.\n",
    "       - 체언 : 명사, 대명사, 수사\n",
    "       - 수식언 : 관형사, 부사\n",
    "       - 관계언 : 조사\n",
    "       - 독립언 : 감탄사\n",
    "       - 용언 : **동사**, **형용사**\n",
    "   - 이 중, **용언**에 해당하는 **동사**, **형용사**는 `어간`과 `어미`의 결합으로 구성된다.\n",
    "   - 앞으로 **용언**이라고 언급하는 부분은 전부 동사와 형용사를 포함하는 개념이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 활용(conjugation)\n",
    "   - 활용(conjugation)은 인도유럽어와 한국어에서만 나타나는 언어적 특징 중 하나를 말하는 통칭적인 개념이다.\n",
    "   - 우리는 한국어에 한하여 알아보자\n",
    "   - 활용이란?\n",
    "       - 용언의 **어간(stem)**이 **어미(ending)**을 가지는 일을 말한다.\n",
    "   - **어간**이란?\n",
    "       - 용언(동사, 형용사)를 활용할 때, 원칙적으로 모양이 변하지 않는 부분을 말한다. 활용에서 어미에 선행하는 부분이며, 때로는 어미에 따라 어간의 모양이 달라질 수 있다\n",
    "       - 예 : 긋다, 긋고, 그어서, 그어라\n",
    "   - **어미**란?\n",
    "       - 용언의 어간 뒤에 붙어 활용하는 부분. 여러 문법적인 기능을 수행하기에 자주 변한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 규칙 활용\n",
    "   - 어간이 어미를 취할때, 어간의 모습은 일정한 경우가 있다.\n",
    "   - 이 경우 **어간이 어미를 취하기 전 모습과 어미가 붙은 후의 모습이 같기 때문에** 규칙적으로 단순히 어간과 어미를 분리해주면 어간추출이 된다.\n",
    "   \n",
    "   \n",
    "##### 예를들어\n",
    "   - 잡다 : 잡/어간 + 다/어미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 불규칙 활용\n",
    "   - 어간이 어미를 취할때, 어간의 모습이 변형되는 경우를 말한다.\n",
    "   - 이 경우는 단순히 어간과 어미를 분리하는 작업을 진행하는 것이 아니라, **어간이 어미를 취하기 전과 후의 어간의 모습이 바뀌기 때문에, 더 복잡한 규칙을 필요로한다.**\n",
    "   \n",
    "   \n",
    "#### 예를들어\n",
    "   - 돕다 : `돕/어간` + `다/어미`  or  `도우/어간` + `다/어미`\n",
    "   - 노랗다 : `노랗/어간` + `다/어미`  or  `누렇/어간` + `다/어미`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 링크는 다양한 불규칙 활용의 예를 보여준다\n",
    "\n",
    "링크 : https://namu.wiki/w/한국어/불규칙%20활용"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
